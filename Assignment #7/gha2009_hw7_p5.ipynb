{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Problem 5 - ML Cloud Platforms (BONUS)"
      ],
      "metadata": {
        "id": "NcDhlfqyBd6m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.1"
      ],
      "metadata": {
        "id": "-id00ye6CNLB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:**\n",
        "\n",
        "**IBM Watson Machine Learning Accelerator** - https://www.ibm.com/docs/en/wmla/2.3?topic=included-deep-learning-frameworks\n",
        "\n",
        "IBM's Watson Machine Learning platform supports several popular deep learning frameworks that are integral to building and deploying machine learning models within the Watson Machine Learning environment, such as: TensorFlow 2.7.1, PyTorch 1.10.2, XGBoost 1.5.2, OpenCV 4.5.5, Scikit-Learn 1.0.2, ONNX 1.10.2, Python 3.9.7 and many more.\n",
        "\n",
        "**Google Cloud Vertex AI** - https://cloud.google.com/vertex-ai/docs/supported-frameworks-list\n",
        "\n",
        "Google's Vertex AI, a comprehensive cloud-based machine learning platform, supports a range of popular machine learning frameworks, such as: PyTorch 1.x (stable & nightly builds), Tensorflow 2.x (stable & nightly builds), Scikit-Learn 1.1 and XGBoost 1.6, Apache Beam 3.x, Kubeflow Pipelines, and TensorFlow Extended (TFX) 1.x.\n",
        "\n",
        "**Microsoft Azure** - https://learn.microsoft.com/en-us/azure/machine-learning/data-science-virtual-machine/dsvm-tools-deep-learning-frameworks?view=azureml-api-2\n",
        "\n",
        "Azure Machine Learning supports frameworks, such as: TensorFlow 2.x (stable & nightly builds), PyTorch 1.x (stable & nightly builds), XGBoost 1.6, Scikit-learn 1.1, ONNX Runtime, CNTK, and Python.\n",
        "\n",
        "**Amazon SageMaker** - https://docs.aws.amazon.com/sagemaker/latest/dg/frameworks.html\n",
        "\n",
        "AWS SageMaker supports a wide array of deep learning frameworks including: Apache MXNet 1.x, Chainer 7.x, PyTorch 1.x (stable & nightly builds), Scikit-learn 1.x, TensorFlow 2.x (stable & nightly builds) and many more."
      ],
      "metadata": {
        "id": "TbEBvSo3ClZT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.2"
      ],
      "metadata": {
        "id": "e1D_yfneCWqL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:**\n",
        "\n",
        "**IBM** - https://www.ibm.com/cloud/gpu\n",
        "\n",
        "IBM offers a wide range of GPU's, which are integrated into their cloud services allowing for high-performance computing capabilities, such as NVIDIA GPUs on IBM Cloud and Bare Metal Servers. These include: NVIDIA Tesla\n",
        "M60, NVIDIA Tesla K80, NVIDIA Tesla P100, and NVIDIA Tesla V100.\n",
        "\n",
        "**Google** - https://cloud.google.com/vertex-ai/pricing\n",
        "\n",
        "Google Cloud provides a robust set of GPU options for machine learning workloads through its Vertex AI platform, such as:  Nvidia GPUs (A100, P100, T4), Google Cloud TPUs (v4, v4-32, v4 Pod), and CPUs (high-performance and standard)\n",
        "\n",
        "**Microsoft** - https://learn.microsoft.com/en-us/azure/machine-learning/concept-compute-target?view=azureml-api-2\n",
        "\n",
        "Azure Machine Learning, Microsoftâ€™s cloud-based service, offers a variety of GPU types for different machine learning scenarios. Azure is known for providing high-performance GPUs ((Nvidia A100, P40, V100) and CPUs (Standard, Low Priority, Burstable), including the NVIDIA series, and HPC (high performance computing)\n",
        "\n",
        "**Amazon** - https://docs.aws.amazon.com/sagemaker/latest/dg/notebooks-available-instance-types.html\n",
        "\n",
        "AWS often utilizes NVIDIA GPUs, known for their high performance in machine learning and deep learning tasks, including: CPUs (High-Performance, Standard, and Burstable), NVIDIA GPUs (NVIDIA A100), and other GPUS (P40, T4, V100, and more), and Machine Learning accelerators.\n"
      ],
      "metadata": {
        "id": "3SDulg8cCnRA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.3"
      ],
      "metadata": {
        "id": "7eXCL_NyGy2_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:**\n",
        "\n",
        "**IBM** - https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/modelops-overview.html?context=cpdaas\n",
        "\n",
        "IBM Cloud offers comprehensive tools for managing the AI lifecycle with MLOps through its Cloud Pak for Data. This platform includes IBM Knowledge Catalog, Watson Studio, Watson Machine Learning, and Watson OpenScale.\n",
        "\n",
        "**Google** - https://cloud.google.com/vertex-ai/docs/start/introduction-unified-platform\n",
        "\n",
        "Google Cloud's Vertex AI offers a comprehensive suite of tools for managing the machine learning model lifecycle. Vertex AI simplifies the process of training, deploying, and maintaining AI models, making it accessible for developers and data scientists across various skill levels. It begins with data preparation, using Vertex AI Workbench notebooks for exploratory data analysis and feature engineering, and integrates with Cloud Storage and BigQuery for data access. For large datasets, Dataproc Serverless Spark in Workbench handles Spark workloads. Model training options include no-code AutoML and custom training with your preferred ML framework, along with hyperparameter optimization using Vertex AI Vizier. Models can be registered in the Vertex AI Model Registry, which supports versioning and integrates with model evaluation and deployment tools. The platform also provides model evaluation metrics and supports real-time online predictions, batch predictions, and TensorFlow runtime optimization. Vertex AI Feature Store aids online serving for tabular models, and Vertex Explainable AI offers insights into model predictions. Model performance is monitored for training-serving skew and prediction drift, with alerts for significant data skew.\n",
        "\n",
        "**Microsoft** - https://azure.microsoft.com/en-us/products/machine-learning/mlops/#resources\n",
        "\n",
        "Azure Machine Learning (Azure ML) provides comprehensive tools for managing the entire machine learning lifecycle, streamlining the development and deployment process. Azure ML integrates with Azure DevOps and GitHub Actions for efficient management and automation of workflows. This facilitates continuous integration and delivery (CI/CD) for model training and deployment. Azure ML also allows for the creation of repeatable pipelines to automate machine learning workflows,which includes frequent model updates, testing new models, and continuous rollout of new machine learning models.\n",
        "\n",
        "**Amazon** - https://aws.amazon.com/sagemaker/mlops/?sagemaker-data-wrangler-whats-new.sort-by=item.additionalFields.postDateTime&sagemaker-data-wrangler-whats-new.sort-order=desc\n",
        "\n",
        "SageMaker Monitoring offers both real-time and historical insights into the performance of models, the usage of resources, and the health of training jobs. It utilizes CloudWatch Logs for gathering and examining application logs, aiding in debugging and problem-solving. Additionally, CloudWatch Metrics tracks the usage and performance of all SageMaker resources. Users have the flexibility to create custom dashboards in CloudWatch for visualizing specific metrics and gaining deeper insights."
      ],
      "metadata": {
        "id": "tjo-oTDxCole"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.4"
      ],
      "metadata": {
        "id": "_BuGX6EVG4uI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:**\n",
        "\n",
        "\n",
        "Each platform provides tools for detailed monitoring and logging, essential for optimizing performance and troubleshooting in machine learning workflows.\n",
        "\n",
        "**IBM** - Utilizes Watson Studio and Watson Machine Learning for logs and resource utilization monitoring, including CPU, GPU, and memory during model training and experimentation.\n",
        "\n",
        "**Google**: Vertex AI Monitoring offers extensive monitoring for training jobs and models. Integrates with Cloud Monitoring and Cloud Logging for application logs and resource usage, and supports custom metrics and TensorBoard for real-time tracking.\n",
        "\n",
        "**Microsoft**: Azure Machine Learning Insights provides metrics and visualizations for model performance and resource utilization. Application Insights and Azure Monitor offer real-time application log monitoring and comprehensive Azure resource monitoring.\n",
        "\n",
        "**Amazon**: SageMaker Monitoring delivers real-time and historical metrics for model performance and resource utilization. CloudWatch Logs and CloudWatch Metrics are used for application log analysis and resource tracking, with capabilities for custom dashboard creation.\n"
      ],
      "metadata": {
        "id": "RyQOE5AhHBxX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.5"
      ],
      "metadata": {
        "id": "7bKbdum_NYpc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:**\n",
        "\n",
        "**IBM's Watson Studio** offers fundamental visualization tools for metrics like accuracy and loss but lacks advanced training dashboards. However, details on Watson Machine Learning's visualization capabilities are not extensively documented.\n",
        "\n",
        "**Google's Vertex AI** integrates TensorBoard for detailed training metric visualizations and Cloud Monitoring for resource usage and training job health.\n",
        "\n",
        "**Microsoft's Azure Machine Learning** provides real-time training metric visualizations in Workbench and supports TensorBoard for comprehensive metric analysis.\n",
        "\n",
        "**Amazon's SageMaker Studio** allows for real-time training metric visualization in its interface, supplemented with TensorBoard for in-depth training insights, and CloudWatch for custom dashboard creation and KPI tracking."
      ],
      "metadata": {
        "id": "N943kCNcNYpc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.6"
      ],
      "metadata": {
        "id": "u1LATb1uNY0r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:**\n",
        "\n",
        "For ML model training, each platform utilizes a specific file format and essential fields:\n",
        "\n",
        "- **IBM**: Uses a YAML file containing fields like model name, framework, description, data reference, and compute configuration.\n",
        "- **Google**: Employs YAML or JSON with fields such as jobId, trainingInput, including details like runtime version and python module.\n",
        "- **Microsoft**: Prefers Azure ML SDK in Python, but also supports YAML or JSON. Key fields include Experiment Name, Environment, Compute Target, and Script Parameters.\n",
        "- **Amazon**: Utilizes JSON or Boto3, including fields like TrainingJobName, AlgorithmSpecification, ResourceConfig, and HyperParameters.\n",
        "\n",
        "Each platform requires core information like job name, framework, and training data, with specific additional parameters for detailed model configuration and resource management.\n",
        "\n",
        "*Example: Training for a sentiment analysis model using a BERT transformer on a text dataset*\n",
        "\n",
        "- **IBM**: The YAML file might specify the model name (e.g., \"bert_sentiment_analysis\"), the framework (PyTorch), the training script (e.g., \"train_bert.py\"), and resource allocation for the job.\n",
        "- **Google**: In a YAML/JSON format, we would define jobId (\"bert_sentiment_analysis\"), training script details, framework version, and compute resources like GPUs.\n",
        "- **Microsoft**: Using the Azure ML SDK, YAML, or JSON, this would include an Experiment Name (\"bert_sentiment_analysis\"), Environment details, Compute Target, and specific Script Parameters.\n",
        "- **Amazon**: In a JSON format or using Boto3, the training job file would include TrainingJobName (\"bert_sentiment_analysis\"), AlgorithmSpecification (possibly pointing to a BERT container image), ResourceConfig (like GPU types), and HyperParameters for the model.\n",
        "\n",
        "Each platform's training job file would contain fields specifying the job identifier, machine learning framework, training script, dataset location, model configuration, and compute resources that are required and needed."
      ],
      "metadata": {
        "id": "WuvDJvDwNY0r"
      }
    }
  ]
}