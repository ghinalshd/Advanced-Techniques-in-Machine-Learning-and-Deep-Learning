{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Problem 2 - Automated Feature Engineering"
      ],
      "metadata": {
        "id": "NcDhlfqyBd6m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.1"
      ],
      "metadata": {
        "id": "-id00ye6CNLB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:**\n",
        "\n",
        "Interpretability and explainability are vital for building trust in machine learning models, ensuring their reliability, improving their performance, complying with regulatory standards, and making informed decisions based on their outputs.\n",
        "\n",
        "- When models are interpretable, they are more transparent, making it easier for users to trust their predictions. Understanding how a model arrives at its conclusions builds confidence in its use, especially in critical applications like healthcare, finance, and legal decisions.\n",
        "- An interpretable model allows developers and data scientists to identify and understand the model's decision-making process. This insight is crucial for diagnosing and fixing errors, biases, or overfitting in the model, leading to more robust and accurate models.\n",
        "- In many industries, regulations require explanations for decisions made by automated systems, especially when these decisions impact human lives. Interpretability ensures compliance with such regulations and helps in maintaining ethical standards by avoiding unfair or discriminatory outcomes.\n",
        "- In domains where the stakes are high, such as healthcare, finance, or security, decisions based on model predictions can have significant consequences. Interpretability allows decision-makers to understand the rationale behind a model's prediction, enabling them to make informed decisions."
      ],
      "metadata": {
        "id": "TbEBvSo3ClZT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2"
      ],
      "metadata": {
        "id": "e1D_yfneCWqL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "TAXg827kroEb"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_diabetes\n",
        "from autofeat import FeatureSelector\n",
        "\n",
        "# Load data\n",
        "diabetes = load_diabetes()\n",
        "X, y = diabetes.data, diabetes.target"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "fs = FeatureSelector(verbose=1)\n",
        "new_X = fs.fit_transform(pd.DataFrame(X), pd.Series(y))\n",
        "\n",
        "# Check how many features were discarded\n",
        "print(\"Original feature count:\", X.shape[1])\n",
        "print(\"Selected feature count:\", new_X.shape[1])\n",
        "discarded_features = X.shape[1] - new_X.shape[1]\n",
        "print(\"Features discarded:\", discarded_features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uq6XJlXMQuHW",
        "outputId": "1d88f3cc-a793-4c12-f99f-46fadd230ba7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[featsel] Scaling data...done.\n",
            "Original feature count: 10\n",
            "Selected feature count: 6\n",
            "Features discarded: 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.3"
      ],
      "metadata": {
        "id": "7eXCL_NyGy2_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "nrQQMpW4Gy3I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6287fc97-2e09-4f85-dacf-0ba4ee5e34f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R^2 - training set: 0.5279193863361498\n",
            "R^2 - test set: 0.4526027629719195\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize and fit model\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# R² score on training and test set\n",
        "r2_train = model.score(X_train, y_train)\n",
        "r2_test = model.score(X_test, y_test)\n",
        "print(\"R^2 - training set:\", r2_train)\n",
        "print(\"R^2 - test set:\", r2_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.4"
      ],
      "metadata": {
        "id": "_BuGX6EVG4uI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ThCq_RhQG4uJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "outputId": "ec0e2571-190b-4fbe-a353-856f573ded35"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[featsel] Scaling data...done.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearRegression()"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "from autofeat import AutoFeatRegressor\n",
        "\n",
        "# Initialize and fit AutoFeatRegressor\n",
        "afreg = AutoFeatRegressor(verbose=1)\n",
        "X_train_feat = afreg.fit_transform(X_train, y_train)\n",
        "X_test_feat = afreg.transform(X_test)\n",
        "\n",
        "# Fit the model and evaluate\n",
        "model.fit(X_train_feat, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r2_train_feat = model.score(X_train_feat, y_train)\n",
        "r2_test_feat = model.score(X_test_feat, y_test)\n",
        "print(\"R^2 - training set:\", r2_train_feat)\n",
        "print(\"R^2 - test set:\", r2_test_feat)\n",
        "\n",
        "# New features generated\n",
        "X_train_df = pd.DataFrame(X_train)\n",
        "X_train_feat_df = pd.DataFrame(X_train_feat)\n",
        "\n",
        "new_features = list(X_train_feat_df.columns[10:])\n",
        "print(\"Five new features generated:\", new_features[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pXMCszksTg8t",
        "outputId": "90d79d86-df3c-4e48-bebb-bf26cb844e4e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R^2 - training set: 0.5721579622952007\n",
            "R^2 - test set: 0.5053018198487318\n",
            "Five new features generated: ['x000**3*x001', 'Abs(x008)/x008', 'exp(x002)*exp(x008)', 'exp(x002)*exp(x003)', 'x002*x003']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:**\n",
        "\n",
        "The updated output from AutoFeatRegressor reveals an improvement in both training and testing \\( $R^2$ \\) scores, suggesting that feature engineering has enhanced the model's fit. Specifically, the \\( $R^2$ \\) score for training data has risen to 0.57, a significant increase from the earlier value, and the \\( $R^2$ \\) score for test data has climbed to 0.51 from 0.45. Although this improvement suggests better model performance, it also raises concerns about overfitting, as evidenced by the widened gap between training and testing results. The added complexity from new features might be causing the model to not generalize effectively to new, unseen data.\n",
        "\n",
        "The five new features listed above are essentially transformations of one or more original features. These transformations have helped in capturing more subtle aspects of our data. However, they also have the potential to lead to overfitting by adjusting not just to the underlying patterns but also to the noise present in the data.\n"
      ],
      "metadata": {
        "id": "RyQOE5AhHBxX"
      }
    }
  ]
}