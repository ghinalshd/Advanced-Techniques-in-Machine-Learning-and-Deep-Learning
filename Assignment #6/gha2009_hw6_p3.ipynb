{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 3 - Ray Tune for Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-05 11:52:12.760326: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-12-05 11:52:18.569590: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-05 11:52:18.569626: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-05 11:52:18.585610: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-05 11:52:18.627292: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-05 11:52:25.587450: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from ray import tune\n",
    "from ray.tune.schedulers import HyperBandScheduler\n",
    "from ray.tune.search.hyperopt import HyperOptSearch\n",
    "from time import time\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "import ray\n",
    "from ray.tune.integration.keras import TuneReportCallback\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from ray.air import session\n",
    "from ray.tune.search.bayesopt import BayesOptSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-05 12:14:55,573\tINFO worker.py:1507 -- Calling ray.init() again after it has already been called.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "813b761701f9492ca28e4e399534db4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<div class=\"lm-Widget p-Widget lm-Panel p-Panel jp-Cell-outputWrapper\">\n",
       "    <div style=\"margin-left: 50px;display: flex;flex-direction: row;align-items: center\">\n",
       "        <div class=\"jp-RenderedHTMLCommon\" style=\"display: flex; flex-direction: row;\">\n",
       "  <svg viewBox=\"0 0 567 224\" fill=\"none\" xmlns=\"http://www.w3.org/2000/svg\" style=\"height: 3em;\">\n",
       "    <g clip-path=\"url(#clip0_4338_178347)\">\n",
       "        <path d=\"M341.29 165.561H355.29L330.13 129.051C345.63 123.991 354.21 112.051 354.21 94.2307C354.21 71.3707 338.72 58.1807 311.88 58.1807H271V165.561H283.27V131.661H311.8C314.25 131.661 316.71 131.501 319.01 131.351L341.25 165.561H341.29ZM283.29 119.851V70.0007H311.82C331.3 70.0007 342.34 78.2907 342.34 94.5507C342.34 111.271 331.34 119.861 311.82 119.861L283.29 119.851ZM451.4 138.411L463.4 165.561H476.74L428.74 58.1807H416L367.83 165.561H380.83L392.83 138.411H451.4ZM446.19 126.601H398L422 72.1407L446.24 126.601H446.19ZM526.11 128.741L566.91 58.1807H554.35L519.99 114.181L485.17 58.1807H472.44L514.01 129.181V165.541H526.13V128.741H526.11Z\" fill=\"var(--jp-ui-font-color0)\"/>\n",
       "        <path d=\"M82.35 104.44C84.0187 97.8827 87.8248 92.0678 93.1671 87.9146C98.5094 83.7614 105.083 81.5067 111.85 81.5067C118.617 81.5067 125.191 83.7614 130.533 87.9146C135.875 92.0678 139.681 97.8827 141.35 104.44H163.75C164.476 101.562 165.622 98.8057 167.15 96.2605L127.45 56.5605C121.071 60.3522 113.526 61.6823 106.235 60.3005C98.9443 58.9187 92.4094 54.9203 87.8602 49.0574C83.3109 43.1946 81.0609 35.8714 81.5332 28.4656C82.0056 21.0599 85.1679 14.0819 90.4252 8.8446C95.6824 3.60726 102.672 0.471508 110.08 0.0272655C117.487 -0.416977 124.802 1.86091 130.647 6.4324C136.493 11.0039 140.467 17.5539 141.821 24.8501C143.175 32.1463 141.816 39.6859 138 46.0505L177.69 85.7505C182.31 82.9877 187.58 81.4995 192.962 81.4375C198.345 81.3755 203.648 82.742 208.33 85.3976C213.012 88.0532 216.907 91.9029 219.616 96.5544C222.326 101.206 223.753 106.492 223.753 111.875C223.753 117.258 222.326 122.545 219.616 127.197C216.907 131.848 213.012 135.698 208.33 138.353C203.648 141.009 198.345 142.375 192.962 142.313C187.58 142.251 182.31 140.763 177.69 138L138 177.7C141.808 184.071 143.155 191.614 141.79 198.91C140.424 206.205 136.44 212.75 130.585 217.313C124.731 221.875 117.412 224.141 110.004 223.683C102.596 223.226 95.6103 220.077 90.3621 214.828C85.1139 209.58 81.9647 202.595 81.5072 195.187C81.0497 187.779 83.3154 180.459 87.878 174.605C92.4405 168.751 98.9853 164.766 106.281 163.401C113.576 162.035 121.119 163.383 127.49 167.19L167.19 127.49C165.664 124.941 164.518 122.182 163.79 119.3H141.39C139.721 125.858 135.915 131.673 130.573 135.826C125.231 139.98 118.657 142.234 111.89 142.234C105.123 142.234 98.5494 139.98 93.2071 135.826C87.8648 131.673 84.0587 125.858 82.39 119.3H60C58.1878 126.495 53.8086 132.78 47.6863 136.971C41.5641 141.163 34.1211 142.972 26.7579 142.059C19.3947 141.146 12.6191 137.574 7.70605 132.014C2.79302 126.454 0.0813599 119.29 0.0813599 111.87C0.0813599 104.451 2.79302 97.2871 7.70605 91.7272C12.6191 86.1673 19.3947 82.5947 26.7579 81.6817C34.1211 80.7686 41.5641 82.5781 47.6863 86.7696C53.8086 90.9611 58.1878 97.2456 60 104.44H82.35ZM100.86 204.32C103.407 206.868 106.759 208.453 110.345 208.806C113.93 209.159 117.527 208.258 120.522 206.256C123.517 204.254 125.725 201.276 126.771 197.828C127.816 194.38 127.633 190.677 126.253 187.349C124.874 184.021 122.383 181.274 119.205 179.577C116.027 177.88 112.359 177.337 108.826 178.042C105.293 178.746 102.113 180.654 99.8291 183.44C97.5451 186.226 96.2979 189.718 96.3 193.32C96.2985 195.364 96.7006 197.388 97.4831 199.275C98.2656 201.163 99.4132 202.877 100.86 204.32ZM204.32 122.88C206.868 120.333 208.453 116.981 208.806 113.396C209.159 109.811 208.258 106.214 206.256 103.219C204.254 100.223 201.275 98.0151 197.827 96.97C194.38 95.9249 190.676 96.1077 187.348 97.4873C184.02 98.8669 181.274 101.358 179.577 104.536C177.879 107.714 177.337 111.382 178.041 114.915C178.746 118.448 180.653 121.627 183.439 123.911C186.226 126.195 189.717 127.443 193.32 127.44C195.364 127.443 197.388 127.042 199.275 126.259C201.163 125.476 202.878 124.328 204.32 122.88ZM122.88 19.4205C120.333 16.8729 116.981 15.2876 113.395 14.9347C109.81 14.5817 106.213 15.483 103.218 17.4849C100.223 19.4868 98.0146 22.4654 96.9696 25.9131C95.9245 29.3608 96.1073 33.0642 97.4869 36.3922C98.8665 39.7202 101.358 42.4668 104.535 44.1639C107.713 45.861 111.381 46.4036 114.914 45.6992C118.447 44.9949 121.627 43.0871 123.911 40.301C126.195 37.515 127.442 34.0231 127.44 30.4205C127.44 28.3772 127.038 26.3539 126.255 24.4664C125.473 22.5788 124.326 20.8642 122.88 19.4205ZM19.42 100.86C16.8725 103.408 15.2872 106.76 14.9342 110.345C14.5813 113.93 15.4826 117.527 17.4844 120.522C19.4863 123.518 22.4649 125.726 25.9127 126.771C29.3604 127.816 33.0638 127.633 36.3918 126.254C39.7198 124.874 42.4664 122.383 44.1635 119.205C45.8606 116.027 46.4032 112.359 45.6988 108.826C44.9944 105.293 43.0866 102.114 40.3006 99.8296C37.5145 97.5455 34.0227 96.2983 30.42 96.3005C26.2938 96.3018 22.337 97.9421 19.42 100.86ZM100.86 100.86C98.3125 103.408 96.7272 106.76 96.3742 110.345C96.0213 113.93 96.9226 117.527 98.9244 120.522C100.926 123.518 103.905 125.726 107.353 126.771C110.8 127.816 114.504 127.633 117.832 126.254C121.16 124.874 123.906 122.383 125.604 119.205C127.301 116.027 127.843 112.359 127.139 108.826C126.434 105.293 124.527 102.114 121.741 99.8296C118.955 97.5455 115.463 96.2983 111.86 96.3005C109.817 96.299 107.793 96.701 105.905 97.4835C104.018 98.2661 102.303 99.4136 100.86 100.86Z\" fill=\"#00AEEF\"/>\n",
       "    </g>\n",
       "    <defs>\n",
       "        <clipPath id=\"clip0_4338_178347\">\n",
       "            <rect width=\"566.93\" height=\"223.75\" fill=\"white\"/>\n",
       "        </clipPath>\n",
       "    </defs>\n",
       "  </svg>\n",
       "</div>\n",
       "\n",
       "        <table class=\"jp-RenderedHTMLCommon\" style=\"border-collapse: collapse;color: var(--jp-ui-font-color1);font-size: var(--jp-ui-font-size1);\">\n",
       "    <tr>\n",
       "        <td style=\"text-align: left\"><b>Python version:</b></td>\n",
       "        <td style=\"text-align: left\"><b>3.11.5</b></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"text-align: left\"><b>Ray version:</b></td>\n",
       "        <td style=\"text-align: left\"><b>2.8.1</b></td>\n",
       "    </tr>\n",
       "    \n",
       "</table>\n",
       "\n",
       "    </div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "RayContext(dashboard_url='', python_version='3.11.5', ray_version='2.8.1', ray_commit='82a8df138fe7fcc5c42536ebf26e8c3665704fee', protocol_version=None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def train_mnist(config):\n",
    "    # Load MNIST data\n",
    "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "    x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "    # Add a channels dimension\n",
    "    x_train = x_train[..., tf.newaxis].astype(\"float32\")\n",
    "    x_test = x_test[..., tf.newaxis].astype(\"float32\")\n",
    "\n",
    "    # Define the model\n",
    "    model = Sequential([\n",
    "        Conv2D(filters=config[\"conv_filters\"], kernel_size=(3, 3), activation=\"relu\", input_shape=(28, 28, 1)),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Flatten(),\n",
    "        Dense(128, activation=\"relu\"),\n",
    "        Dropout(config[\"dropout\"]),\n",
    "        Dense(10, activation=\"softmax\")\n",
    "    ])\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=config[\"lr\"]),\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(\n",
    "        x_train, y_train,\n",
    "        validation_data=(x_test, y_test),\n",
    "        batch_size=config[\"batch_size\"],\n",
    "        epochs=10,\n",
    "        callbacks=[TuneReportCallback({\"accuracy\": \"accuracy\"})]\n",
    "    )\n",
    "\n",
    "# Define the search space\n",
    "search_space = {\n",
    "    \"conv_filters\": tune.choice([64, 128, 256]),\n",
    "    \"lr\": tune.loguniform(0.001, 0.1),\n",
    "    \"batch_size\": tune.choice([64, 128, 256]),\n",
    "    \"dropout\": tune.uniform(0, 1)\n",
    "}\n",
    "\n",
    "# Initialize Ray\n",
    "ray.init(ignore_reinit_error=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_mnist(config):\n",
    "    num_classes = 10\n",
    "    epochs = 12\n",
    "\n",
    "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "    x_train, x_test = x_train.reshape(-1, 28, 28, 1) / 255.0, x_test.reshape(-1, 28, 28, 1) / 255.0\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Conv2D(filters=config[\"conv_filters\"], kernel_size=(3, 3), activation=\"relu\", input_shape=(28, 28, 1)),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "        tf.keras.layers.Dropout(config[\"dropout\"]),\n",
    "        tf.keras.layers.Dense(num_classes, activation=\"softmax\")\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=config[\"lr\"]),\n",
    "        metrics=[\"accuracy\"])\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.fit(\n",
    "            x_train,\n",
    "            y_train,\n",
    "            batch_size=config[\"batch_size\"],\n",
    "            epochs=1,\n",
    "            verbose=0,\n",
    "            validation_data=(x_test, y_test))\n",
    "\n",
    "        # Evaluate the model\n",
    "        i, accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
    "        session.report({\"mean_accuracy\": accuracy})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-05 12:14:58,081\tINFO tune.py:586 -- [output] This uses the legacy output and progress reporter, as Jupyter notebooks are not supported by the new engine, yet. For more information, please see https://github.com/ray-project/ray/issues/36949\n",
      "2023-12-05 12:14:58,096\tWARNING callback.py:137 -- The TensorboardX logger cannot be instantiated because either TensorboardX or one of it's dependencies is not installed. Please make sure you have the latest version of TensorboardX installed: `pip install -U tensorboardx`\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2023-12-05 14:13:29</td></tr>\n",
       "<tr><td>Running for: </td><td>01:58:30.97        </td></tr>\n",
       "<tr><td>Memory:      </td><td>60.0/377.3 GiB     </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using FIFO scheduling algorithm.<br>Logical resource usage: 0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name             </th><th>status    </th><th>loc                </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_filters</th><th style=\"text-align: right;\">  dropout</th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">   acc</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_mnist_d0fea_00000</td><td>TERMINATED</td><td>10.32.35.81:3179883</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">            64</td><td style=\"text-align: right;\">     0   </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">0.9875</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         62.2493</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00001</td><td>TERMINATED</td><td>10.32.35.81:3184307</td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">            64</td><td style=\"text-align: right;\">     0   </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">0.9879</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         40.4822</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00002</td><td>TERMINATED</td><td>10.32.35.81:3186750</td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\">            64</td><td style=\"text-align: right;\">     0   </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">0.9875</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         29.8463</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00003</td><td>TERMINATED</td><td>10.32.35.81:3189247</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">           128</td><td style=\"text-align: right;\">     0   </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">0.988 </td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         61.7737</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00004</td><td>TERMINATED</td><td>10.32.35.81:3193022</td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">           128</td><td style=\"text-align: right;\">     0   </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">0.9871</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         40.8085</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00005</td><td>TERMINATED</td><td>10.32.35.81:3195582</td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\">           128</td><td style=\"text-align: right;\">     0   </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">0.9862</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         33.7739</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00006</td><td>TERMINATED</td><td>10.32.35.81:3198748</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">           256</td><td style=\"text-align: right;\">     0   </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">0.9871</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         66.7068</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00007</td><td>TERMINATED</td><td>10.32.35.81:3202163</td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">           256</td><td style=\"text-align: right;\">     0   </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">0.9862</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         50.9287</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00008</td><td>TERMINATED</td><td>10.32.35.81:3205785</td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\">           256</td><td style=\"text-align: right;\">     0   </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">0.9871</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         43.7762</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00009</td><td>TERMINATED</td><td>10.32.35.81:3208531</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">            64</td><td style=\"text-align: right;\">     0.25</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">0.9883</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         64.5574</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00010</td><td>TERMINATED</td><td>10.32.35.81:3212973</td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">            64</td><td style=\"text-align: right;\">     0.25</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">0.9884</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         42.5269</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00011</td><td>TERMINATED</td><td>10.32.35.81:3215945</td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\">            64</td><td style=\"text-align: right;\">     0.25</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">0.9894</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         30.6465</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00012</td><td>TERMINATED</td><td>10.32.35.81:3217909</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">           128</td><td style=\"text-align: right;\">     0.25</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">0.9886</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         64.6617</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00013</td><td>TERMINATED</td><td>10.32.35.81:3222410</td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">           128</td><td style=\"text-align: right;\">     0.25</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">0.9876</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         42.3041</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00014</td><td>TERMINATED</td><td>10.32.35.81:3225377</td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\">           128</td><td style=\"text-align: right;\">     0.25</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">0.9885</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         34.61  </td></tr>\n",
       "<tr><td>train_mnist_d0fea_00015</td><td>TERMINATED</td><td>10.32.35.81:3227527</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">           256</td><td style=\"text-align: right;\">     0.25</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">0.9891</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         69.0243</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00016</td><td>TERMINATED</td><td>10.32.35.81:3232209</td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">           256</td><td style=\"text-align: right;\">     0.25</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">0.9885</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         51.8686</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00017</td><td>TERMINATED</td><td>10.32.35.81:3235815</td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\">           256</td><td style=\"text-align: right;\">     0.25</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">0.9882</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         44.4057</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00018</td><td>TERMINATED</td><td>10.32.35.81:3238984</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">            64</td><td style=\"text-align: right;\">     0.5 </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">0.9878</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         64.2121</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00019</td><td>TERMINATED</td><td>10.32.35.81:3242658</td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">            64</td><td style=\"text-align: right;\">     0.5 </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">0.9885</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         41.8814</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00020</td><td>TERMINATED</td><td>10.32.35.81:3245853</td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\">            64</td><td style=\"text-align: right;\">     0.5 </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">0.9874</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         30.8775</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00021</td><td>TERMINATED</td><td>10.32.35.81:3248015</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">           128</td><td style=\"text-align: right;\">     0.5 </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">0.989 </td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         65.0622</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00022</td><td>TERMINATED</td><td>10.32.35.81:3252234</td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">           128</td><td style=\"text-align: right;\">     0.5 </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">0.9892</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         42.3657</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00023</td><td>TERMINATED</td><td>10.32.35.81:3255428</td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\">           128</td><td style=\"text-align: right;\">     0.5 </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">0.988 </td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         34.6588</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00024</td><td>TERMINATED</td><td>10.32.35.81:3257587</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">           256</td><td style=\"text-align: right;\">     0.5 </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">0.9883</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         68.4077</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00025</td><td>TERMINATED</td><td>10.32.35.81:3261885</td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">           256</td><td style=\"text-align: right;\">     0.5 </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">0.9893</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         51.7342</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00026</td><td>TERMINATED</td><td>10.32.35.81:3265063</td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\">           256</td><td style=\"text-align: right;\">     0.5 </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">0.9894</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         44.3365</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00027</td><td>TERMINATED</td><td>10.32.35.81:3268260</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">            64</td><td style=\"text-align: right;\">     0.75</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">0.9879</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         64.5799</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00028</td><td>TERMINATED</td><td>10.32.35.81:3271700</td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">            64</td><td style=\"text-align: right;\">     0.75</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">0.9864</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         41.6619</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00029</td><td>TERMINATED</td><td>10.32.35.81:3274659</td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\">            64</td><td style=\"text-align: right;\">     0.75</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">0.9843</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         30.6247</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00030</td><td>TERMINATED</td><td>10.32.35.81:3277864</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">           128</td><td style=\"text-align: right;\">     0.75</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">0.9865</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         65.5705</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00031</td><td>TERMINATED</td><td>10.32.35.81:3281097</td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">           128</td><td style=\"text-align: right;\">     0.75</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">0.9872</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         42.3554</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00032</td><td>TERMINATED</td><td>10.32.35.81:3284291</td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\">           128</td><td style=\"text-align: right;\">     0.75</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">0.9864</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         34.8349</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00033</td><td>TERMINATED</td><td>10.32.35.81:3287465</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">           256</td><td style=\"text-align: right;\">     0.75</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">0.9864</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         68.4763</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00034</td><td>TERMINATED</td><td>10.32.35.81:3290900</td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">           256</td><td style=\"text-align: right;\">     0.75</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">0.9874</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         51.8581</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00035</td><td>TERMINATED</td><td>10.32.35.81:3294387</td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\">           256</td><td style=\"text-align: right;\">     0.75</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">0.9875</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         44.2452</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00036</td><td>TERMINATED</td><td>10.32.35.81:3297409</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">            64</td><td style=\"text-align: right;\">     0.9 </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">0.9829</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         64.8435</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00037</td><td>TERMINATED</td><td>10.32.35.81:3301863</td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">            64</td><td style=\"text-align: right;\">     0.9 </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">0.9828</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         42.219 </td></tr>\n",
       "<tr><td>train_mnist_d0fea_00038</td><td>TERMINATED</td><td>10.32.35.81:3304659</td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\">            64</td><td style=\"text-align: right;\">     0.9 </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">0.9804</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         31.0502</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00039</td><td>TERMINATED</td><td>10.32.35.81:3306821</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">           128</td><td style=\"text-align: right;\">     0.9 </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">0.9839</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         64.4997</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00040</td><td>TERMINATED</td><td>10.32.35.81:3311233</td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">           128</td><td style=\"text-align: right;\">     0.9 </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">0.9838</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         42.512 </td></tr>\n",
       "<tr><td>train_mnist_d0fea_00041</td><td>TERMINATED</td><td>10.32.35.81:3314000</td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\">           128</td><td style=\"text-align: right;\">     0.9 </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">0.9824</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         34.6883</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00042</td><td>TERMINATED</td><td>10.32.35.81:3316418</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">           256</td><td style=\"text-align: right;\">     0.9 </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">0.984 </td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         68.6953</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00043</td><td>TERMINATED</td><td>10.32.35.81:3321082</td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">           256</td><td style=\"text-align: right;\">     0.9 </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">0.985 </td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         51.9278</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00044</td><td>TERMINATED</td><td>10.32.35.81:3324583</td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\">           256</td><td style=\"text-align: right;\">     0.9 </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">0.982 </td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         44.636 </td></tr>\n",
       "<tr><td>train_mnist_d0fea_00045</td><td>TERMINATED</td><td>10.32.35.81:3327472</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">            64</td><td style=\"text-align: right;\">     0   </td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">0.9833</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         62.2165</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00046</td><td>TERMINATED</td><td>10.32.35.81:3331505</td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">            64</td><td style=\"text-align: right;\">     0   </td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">0.9792</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         40.2582</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00047</td><td>TERMINATED</td><td>10.32.35.81:3334246</td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\">            64</td><td style=\"text-align: right;\">     0   </td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">0.9807</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         30.0323</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00048</td><td>TERMINATED</td><td>10.32.35.81:3336220</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">           128</td><td style=\"text-align: right;\">     0   </td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">0.9833</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         62.7476</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00049</td><td>TERMINATED</td><td>10.32.35.81:3340644</td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">           128</td><td style=\"text-align: right;\">     0   </td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">0.9754</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         40.8852</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00050</td><td>TERMINATED</td><td>10.32.35.81:3343327</td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\">           128</td><td style=\"text-align: right;\">     0   </td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">0.9851</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         33.8609</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00051</td><td>TERMINATED</td><td>10.32.35.81:3345335</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">           256</td><td style=\"text-align: right;\">     0   </td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">0.1135</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         66.6083</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00052</td><td>TERMINATED</td><td>10.32.35.81:3350148</td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">           256</td><td style=\"text-align: right;\">     0   </td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">0.9812</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         50.9181</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00053</td><td>TERMINATED</td><td>10.32.35.81:3353761</td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\">           256</td><td style=\"text-align: right;\">     0   </td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">0.9845</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         43.7279</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00054</td><td>TERMINATED</td><td>10.32.35.81:3356569</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">            64</td><td style=\"text-align: right;\">     0.25</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">0.9846</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         64.5837</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00055</td><td>TERMINATED</td><td>10.32.35.81:3360224</td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">            64</td><td style=\"text-align: right;\">     0.25</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">0.9841</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         42.4503</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00056</td><td>TERMINATED</td><td>10.32.35.81:3363410</td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\">            64</td><td style=\"text-align: right;\">     0.25</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">0.9839</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         30.6497</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00057</td><td>TERMINATED</td><td>10.32.35.81:3365734</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">           128</td><td style=\"text-align: right;\">     0.25</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">0.9798</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         64.6781</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00058</td><td>TERMINATED</td><td>10.32.35.81:3369784</td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">           128</td><td style=\"text-align: right;\">     0.25</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">0.9831</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         42.7292</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00059</td><td>TERMINATED</td><td>10.32.35.81:3373005</td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\">           128</td><td style=\"text-align: right;\">     0.25</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">0.9855</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         34.8691</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00060</td><td>TERMINATED</td><td>10.32.35.81:3375370</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">           256</td><td style=\"text-align: right;\">     0.25</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">0.9802</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         69.4355</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00061</td><td>TERMINATED</td><td>10.32.35.81:3379430</td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">           256</td><td style=\"text-align: right;\">     0.25</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">0.9853</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         51.9401</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00062</td><td>TERMINATED</td><td>10.32.35.81:3382622</td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\">           256</td><td style=\"text-align: right;\">     0.25</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">0.9851</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         44.5834</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00063</td><td>TERMINATED</td><td>10.32.35.81:3385808</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">            64</td><td style=\"text-align: right;\">     0.5 </td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">0.9848</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         64.6894</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00064</td><td>TERMINATED</td><td>10.32.35.81:3389649</td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">            64</td><td style=\"text-align: right;\">     0.5 </td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">0.9844</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         41.5088</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00065</td><td>TERMINATED</td><td>10.32.35.81:3392463</td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\">            64</td><td style=\"text-align: right;\">     0.5 </td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">0.9866</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         30.2691</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00066</td><td>TERMINATED</td><td>10.32.35.81:3395433</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">           128</td><td style=\"text-align: right;\">     0.5 </td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">0.9803</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         64.6186</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00067</td><td>TERMINATED</td><td>10.32.35.81:3398842</td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">           128</td><td style=\"text-align: right;\">     0.5 </td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">0.9861</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         42.0941</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00068</td><td>TERMINATED</td><td>10.32.35.81:3401830</td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\">           128</td><td style=\"text-align: right;\">     0.5 </td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">0.9864</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         34.6367</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00069</td><td>TERMINATED</td><td>10.32.35.81:3405015</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">           256</td><td style=\"text-align: right;\">     0.5 </td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">0.9791</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         68.9684</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00070</td><td>TERMINATED</td><td>10.32.35.81:3408501</td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">           256</td><td style=\"text-align: right;\">     0.5 </td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">0.9828</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         51.6694</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00071</td><td>TERMINATED</td><td>10.32.35.81:3412109</td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\">           256</td><td style=\"text-align: right;\">     0.5 </td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">0.986 </td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         44.2494</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00072</td><td>TERMINATED</td><td>10.32.35.81:3415295</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">            64</td><td style=\"text-align: right;\">     0.75</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">0.9768</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         64.9929</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00073</td><td>TERMINATED</td><td>10.32.35.81:3419728</td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">            64</td><td style=\"text-align: right;\">     0.75</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">0.9808</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         42.2869</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00074</td><td>TERMINATED</td><td>10.32.35.81:3422511</td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\">            64</td><td style=\"text-align: right;\">     0.75</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">0.9847</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         30.341 </td></tr>\n",
       "<tr><td>train_mnist_d0fea_00075</td><td>TERMINATED</td><td>10.32.35.81:3424434</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">           128</td><td style=\"text-align: right;\">     0.75</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">0.9776</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         64.5315</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00076</td><td>TERMINATED</td><td>10.32.35.81:3428956</td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">           128</td><td style=\"text-align: right;\">     0.75</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">0.9809</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         42.3332</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00077</td><td>TERMINATED</td><td>10.32.35.81:3431751</td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\">           128</td><td style=\"text-align: right;\">     0.75</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">0.9861</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         34.5323</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00078</td><td>TERMINATED</td><td>10.32.35.81:3434115</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">           256</td><td style=\"text-align: right;\">     0.75</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">0.9383</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         69.1118</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00079</td><td>TERMINATED</td><td>10.32.35.81:3438957</td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">           256</td><td style=\"text-align: right;\">     0.75</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">0.9801</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         51.6257</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00080</td><td>TERMINATED</td><td>10.32.35.81:3442557</td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\">           256</td><td style=\"text-align: right;\">     0.75</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">0.9826</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         44.4758</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00081</td><td>TERMINATED</td><td>10.32.35.81:3445557</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">            64</td><td style=\"text-align: right;\">     0.9 </td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">0.9458</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         64.7486</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00082</td><td>TERMINATED</td><td>10.32.35.81:3449007</td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">            64</td><td style=\"text-align: right;\">     0.9 </td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">0.9679</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         41.8804</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00083</td><td>TERMINATED</td><td>10.32.35.81:3452202</td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\">            64</td><td style=\"text-align: right;\">     0.9 </td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">0.9763</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         30.4674</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00084</td><td>TERMINATED</td><td>10.32.35.81:3454557</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">           128</td><td style=\"text-align: right;\">     0.9 </td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">0.1032</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         65.2172</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00085</td><td>TERMINATED</td><td>10.32.35.81:3458576</td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">           128</td><td style=\"text-align: right;\">     0.9 </td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">0.8858</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         42.7806</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00086</td><td>TERMINATED</td><td>10.32.35.81:3461765</td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\">           128</td><td style=\"text-align: right;\">     0.9 </td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">0.9756</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         35.1525</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00087</td><td>TERMINATED</td><td>10.32.35.81:3464417</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">           256</td><td style=\"text-align: right;\">     0.9 </td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">0.893 </td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         69.133 </td></tr>\n",
       "<tr><td>train_mnist_d0fea_00088</td><td>TERMINATED</td><td>10.32.35.81:3468242</td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">           256</td><td style=\"text-align: right;\">     0.9 </td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">0.8203</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         51.9102</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00089</td><td>TERMINATED</td><td>10.32.35.81:3471441</td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\">           256</td><td style=\"text-align: right;\">     0.9 </td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">0.9707</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         44.2393</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00090</td><td>TERMINATED</td><td>10.32.35.81:3474636</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">            64</td><td style=\"text-align: right;\">     0   </td><td style=\"text-align: right;\">0.1  </td><td style=\"text-align: right;\">0.098 </td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         61.7178</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00091</td><td>TERMINATED</td><td>10.32.35.81:3478412</td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">            64</td><td style=\"text-align: right;\">     0   </td><td style=\"text-align: right;\">0.1  </td><td style=\"text-align: right;\">0.1135</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         40.2409</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00092</td><td>TERMINATED</td><td>10.32.35.81:3481054</td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\">            64</td><td style=\"text-align: right;\">     0   </td><td style=\"text-align: right;\">0.1  </td><td style=\"text-align: right;\">0.1135</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         29.7068</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00093</td><td>TERMINATED</td><td>10.32.35.81:3484180</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">           128</td><td style=\"text-align: right;\">     0   </td><td style=\"text-align: right;\">0.1  </td><td style=\"text-align: right;\">0.098 </td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         62.8852</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00094</td><td>TERMINATED</td><td>10.32.35.81:3487429</td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">           128</td><td style=\"text-align: right;\">     0   </td><td style=\"text-align: right;\">0.1  </td><td style=\"text-align: right;\">0.9257</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         40.8744</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00095</td><td>TERMINATED</td><td>10.32.35.81:3490607</td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\">           128</td><td style=\"text-align: right;\">     0   </td><td style=\"text-align: right;\">0.1  </td><td style=\"text-align: right;\">0.0982</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         33.8454</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00096</td><td>TERMINATED</td><td>10.32.35.81:3493337</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">           256</td><td style=\"text-align: right;\">     0   </td><td style=\"text-align: right;\">0.1  </td><td style=\"text-align: right;\">0.101 </td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         66.9738</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00097</td><td>TERMINATED</td><td>10.32.35.81:3496956</td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">           256</td><td style=\"text-align: right;\">     0   </td><td style=\"text-align: right;\">0.1  </td><td style=\"text-align: right;\">0.9285</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         50.914 </td></tr>\n",
       "<tr><td>train_mnist_d0fea_00098</td><td>TERMINATED</td><td>10.32.35.81:3500157</td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\">           256</td><td style=\"text-align: right;\">     0   </td><td style=\"text-align: right;\">0.1  </td><td style=\"text-align: right;\">0.1028</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         43.671 </td></tr>\n",
       "<tr><td>train_mnist_d0fea_00099</td><td>TERMINATED</td><td>10.32.35.81:3503347</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">            64</td><td style=\"text-align: right;\">     0.25</td><td style=\"text-align: right;\">0.1  </td><td style=\"text-align: right;\">0.1135</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         65.1262</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00100</td><td>TERMINATED</td><td>10.32.35.81:3507557</td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">            64</td><td style=\"text-align: right;\">     0.25</td><td style=\"text-align: right;\">0.1  </td><td style=\"text-align: right;\">0.098 </td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         41.7262</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00101</td><td>TERMINATED</td><td>10.32.35.81:3509977</td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\">            64</td><td style=\"text-align: right;\">     0.25</td><td style=\"text-align: right;\">0.1  </td><td style=\"text-align: right;\">0.1135</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         30.4292</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00102</td><td>TERMINATED</td><td>10.32.35.81:3512952</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">           128</td><td style=\"text-align: right;\">     0.25</td><td style=\"text-align: right;\">0.1  </td><td style=\"text-align: right;\">0.1135</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         64.5894</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00103</td><td>TERMINATED</td><td>10.32.35.81:3516405</td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">           128</td><td style=\"text-align: right;\">     0.25</td><td style=\"text-align: right;\">0.1  </td><td style=\"text-align: right;\">0.101 </td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         42.678 </td></tr>\n",
       "<tr><td>train_mnist_d0fea_00104</td><td>TERMINATED</td><td>10.32.35.81:3519370</td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\">           128</td><td style=\"text-align: right;\">     0.25</td><td style=\"text-align: right;\">0.1  </td><td style=\"text-align: right;\">0.1135</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         34.5376</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00105</td><td>TERMINATED</td><td>10.32.35.81:3522575</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">           256</td><td style=\"text-align: right;\">     0.25</td><td style=\"text-align: right;\">0.1  </td><td style=\"text-align: right;\">0.1028</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         68.7121</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00106</td><td>TERMINATED</td><td>10.32.35.81:3526400</td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">           256</td><td style=\"text-align: right;\">     0.25</td><td style=\"text-align: right;\">0.1  </td><td style=\"text-align: right;\">0.8948</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         52.1431</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00107</td><td>TERMINATED</td><td>10.32.35.81:3530012</td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\">           256</td><td style=\"text-align: right;\">     0.25</td><td style=\"text-align: right;\">0.1  </td><td style=\"text-align: right;\">0.1135</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         44.5525</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00108</td><td>TERMINATED</td><td>10.32.35.81:3532829</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">            64</td><td style=\"text-align: right;\">     0.5 </td><td style=\"text-align: right;\">0.1  </td><td style=\"text-align: right;\">0.0982</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         64.9518</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00109</td><td>TERMINATED</td><td>10.32.35.81:3537643</td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">            64</td><td style=\"text-align: right;\">     0.5 </td><td style=\"text-align: right;\">0.1  </td><td style=\"text-align: right;\">0.101 </td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         41.8628</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00110</td><td>TERMINATED</td><td>10.32.35.81:3540467</td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\">            64</td><td style=\"text-align: right;\">     0.5 </td><td style=\"text-align: right;\">0.1  </td><td style=\"text-align: right;\">0.1028</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         30.5346</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00111</td><td>TERMINATED</td><td>10.32.35.81:3542387</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">           128</td><td style=\"text-align: right;\">     0.5 </td><td style=\"text-align: right;\">0.1  </td><td style=\"text-align: right;\">0.1028</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         64.5757</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00112</td><td>TERMINATED</td><td>10.32.35.81:3546733</td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">           128</td><td style=\"text-align: right;\">     0.5 </td><td style=\"text-align: right;\">0.1  </td><td style=\"text-align: right;\">0.1135</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         42.0446</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00113</td><td>TERMINATED</td><td>10.32.35.81:3549664</td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\">           128</td><td style=\"text-align: right;\">     0.5 </td><td style=\"text-align: right;\">0.1  </td><td style=\"text-align: right;\">0.1135</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         34.5945</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00114</td><td>TERMINATED</td><td>10.32.35.81:3551586</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">           256</td><td style=\"text-align: right;\">     0.5 </td><td style=\"text-align: right;\">0.1  </td><td style=\"text-align: right;\">0.101 </td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         69.1548</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00115</td><td>TERMINATED</td><td>10.32.35.81:3556692</td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">           256</td><td style=\"text-align: right;\">     0.5 </td><td style=\"text-align: right;\">0.1  </td><td style=\"text-align: right;\">0.1135</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         51.6699</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00116</td><td>TERMINATED</td><td>10.32.35.81:3560116</td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\">           256</td><td style=\"text-align: right;\">     0.5 </td><td style=\"text-align: right;\">0.1  </td><td style=\"text-align: right;\">0.922 </td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         44.619 </td></tr>\n",
       "<tr><td>train_mnist_d0fea_00117</td><td>TERMINATED</td><td>10.32.35.81:3563251</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">            64</td><td style=\"text-align: right;\">     0.75</td><td style=\"text-align: right;\">0.1  </td><td style=\"text-align: right;\">0.0958</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         64.6451</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00118</td><td>TERMINATED</td><td>10.32.35.81:3566510</td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">            64</td><td style=\"text-align: right;\">     0.75</td><td style=\"text-align: right;\">0.1  </td><td style=\"text-align: right;\">0.098 </td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         41.8063</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00119</td><td>TERMINATED</td><td>10.32.35.81:3569706</td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\">            64</td><td style=\"text-align: right;\">     0.75</td><td style=\"text-align: right;\">0.1  </td><td style=\"text-align: right;\">0.1028</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         30.3652</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00120</td><td>TERMINATED</td><td>10.32.35.81:3572069</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">           128</td><td style=\"text-align: right;\">     0.75</td><td style=\"text-align: right;\">0.1  </td><td style=\"text-align: right;\">0.1135</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         65.4395</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00121</td><td>TERMINATED</td><td>10.32.35.81:3576127</td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">           128</td><td style=\"text-align: right;\">     0.75</td><td style=\"text-align: right;\">0.1  </td><td style=\"text-align: right;\">0.8485</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         42.0948</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00122</td><td>TERMINATED</td><td>10.32.35.81:3579349</td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\">           128</td><td style=\"text-align: right;\">     0.75</td><td style=\"text-align: right;\">0.1  </td><td style=\"text-align: right;\">0.1135</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         36.3688</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00123</td><td>TERMINATED</td><td>10.32.35.81:3581854</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">           256</td><td style=\"text-align: right;\">     0.75</td><td style=\"text-align: right;\">0.1  </td><td style=\"text-align: right;\">0.1009</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         68.4524</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00124</td><td>TERMINATED</td><td>10.32.35.81:3585729</td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">           256</td><td style=\"text-align: right;\">     0.75</td><td style=\"text-align: right;\">0.1  </td><td style=\"text-align: right;\">0.1135</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         51.8985</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00125</td><td>TERMINATED</td><td>10.32.35.81:3588926</td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\">           256</td><td style=\"text-align: right;\">     0.75</td><td style=\"text-align: right;\">0.1  </td><td style=\"text-align: right;\">0.101 </td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         44.2224</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00126</td><td>TERMINATED</td><td>10.32.35.81:3592125</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">            64</td><td style=\"text-align: right;\">     0.9 </td><td style=\"text-align: right;\">0.1  </td><td style=\"text-align: right;\">0.1028</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         64.1843</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00127</td><td>TERMINATED</td><td>10.32.35.81:3596027</td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">            64</td><td style=\"text-align: right;\">     0.9 </td><td style=\"text-align: right;\">0.1  </td><td style=\"text-align: right;\">0.1135</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         41.6136</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00128</td><td>TERMINATED</td><td>10.32.35.81:3598815</td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\">            64</td><td style=\"text-align: right;\">     0.9 </td><td style=\"text-align: right;\">0.1  </td><td style=\"text-align: right;\">0.098 </td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         30.6119</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00129</td><td>TERMINATED</td><td>10.32.35.81:3601755</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">           128</td><td style=\"text-align: right;\">     0.9 </td><td style=\"text-align: right;\">0.1  </td><td style=\"text-align: right;\">0.0982</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         64.7361</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00130</td><td>TERMINATED</td><td>10.32.35.81:3605213</td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">           128</td><td style=\"text-align: right;\">     0.9 </td><td style=\"text-align: right;\">0.1  </td><td style=\"text-align: right;\">0.1135</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         42.3588</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00131</td><td>TERMINATED</td><td>10.32.35.81:3608204</td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\">           128</td><td style=\"text-align: right;\">     0.9 </td><td style=\"text-align: right;\">0.1  </td><td style=\"text-align: right;\">0.1028</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         34.7438</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00132</td><td>TERMINATED</td><td>10.32.35.81:3611361</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">           256</td><td style=\"text-align: right;\">     0.9 </td><td style=\"text-align: right;\">0.1  </td><td style=\"text-align: right;\">0.1032</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         68.7871</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00133</td><td>TERMINATED</td><td>10.32.35.81:3615064</td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">           256</td><td style=\"text-align: right;\">     0.9 </td><td style=\"text-align: right;\">0.1  </td><td style=\"text-align: right;\">0.1135</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         52.0322</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00134</td><td>TERMINATED</td><td>10.32.35.81:3618655</td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\">           256</td><td style=\"text-align: right;\">     0.9 </td><td style=\"text-align: right;\">0.1  </td><td style=\"text-align: right;\">0.1135</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         44.2783</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3179883)\u001b[0m 2023-12-05 12:15:01.457202: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3179883)\u001b[0m 2023-12-05 12:15:01.496067: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3179883)\u001b[0m 2023-12-05 12:15:01.496096: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3179883)\u001b[0m 2023-12-05 12:15:01.497140: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3179883)\u001b[0m 2023-12-05 12:15:01.503023: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3179883)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3179883)\u001b[0m 2023-12-05 12:15:02.213497: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3179883)\u001b[0m 2023-12-05 12:15:03.537545: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3179883)\u001b[0m 2023-12-05 12:15:05.231328: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3179883)\u001b[0m 2023-12-05 12:15:05.577737: I external/local_xla/xla/service/service.cc:168] XLA service 0x153921c3d780 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3179883)\u001b[0m 2023-12-05 12:15:05.577784: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3179883)\u001b[0m 2023-12-05 12:15:05.584980: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3179883)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3179883)\u001b[0m I0000 00:00:1701796505.698906 3180374 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"trialProgress\">\n",
       "  <h3>Trial Progress</h3>\n",
       "  <table>\n",
       "<thead>\n",
       "<tr><th>Trial name             </th><th style=\"text-align: right;\">  mean_accuracy</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_mnist_d0fea_00000</td><td style=\"text-align: right;\">         0.9875</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00001</td><td style=\"text-align: right;\">         0.9879</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00002</td><td style=\"text-align: right;\">         0.9875</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00003</td><td style=\"text-align: right;\">         0.988 </td></tr>\n",
       "<tr><td>train_mnist_d0fea_00004</td><td style=\"text-align: right;\">         0.9871</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00005</td><td style=\"text-align: right;\">         0.9862</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00006</td><td style=\"text-align: right;\">         0.9871</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00007</td><td style=\"text-align: right;\">         0.9862</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00008</td><td style=\"text-align: right;\">         0.9871</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00009</td><td style=\"text-align: right;\">         0.9883</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00010</td><td style=\"text-align: right;\">         0.9884</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00011</td><td style=\"text-align: right;\">         0.9894</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00012</td><td style=\"text-align: right;\">         0.9886</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00013</td><td style=\"text-align: right;\">         0.9876</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00014</td><td style=\"text-align: right;\">         0.9885</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00015</td><td style=\"text-align: right;\">         0.9891</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00016</td><td style=\"text-align: right;\">         0.9885</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00017</td><td style=\"text-align: right;\">         0.9882</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00018</td><td style=\"text-align: right;\">         0.9878</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00019</td><td style=\"text-align: right;\">         0.9885</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00020</td><td style=\"text-align: right;\">         0.9874</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00021</td><td style=\"text-align: right;\">         0.989 </td></tr>\n",
       "<tr><td>train_mnist_d0fea_00022</td><td style=\"text-align: right;\">         0.9892</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00023</td><td style=\"text-align: right;\">         0.988 </td></tr>\n",
       "<tr><td>train_mnist_d0fea_00024</td><td style=\"text-align: right;\">         0.9883</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00025</td><td style=\"text-align: right;\">         0.9893</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00026</td><td style=\"text-align: right;\">         0.9894</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00027</td><td style=\"text-align: right;\">         0.9879</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00028</td><td style=\"text-align: right;\">         0.9864</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00029</td><td style=\"text-align: right;\">         0.9843</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00030</td><td style=\"text-align: right;\">         0.9865</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00031</td><td style=\"text-align: right;\">         0.9872</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00032</td><td style=\"text-align: right;\">         0.9864</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00033</td><td style=\"text-align: right;\">         0.9864</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00034</td><td style=\"text-align: right;\">         0.9874</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00035</td><td style=\"text-align: right;\">         0.9875</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00036</td><td style=\"text-align: right;\">         0.9829</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00037</td><td style=\"text-align: right;\">         0.9828</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00038</td><td style=\"text-align: right;\">         0.9804</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00039</td><td style=\"text-align: right;\">         0.9839</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00040</td><td style=\"text-align: right;\">         0.9838</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00041</td><td style=\"text-align: right;\">         0.9824</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00042</td><td style=\"text-align: right;\">         0.984 </td></tr>\n",
       "<tr><td>train_mnist_d0fea_00043</td><td style=\"text-align: right;\">         0.985 </td></tr>\n",
       "<tr><td>train_mnist_d0fea_00044</td><td style=\"text-align: right;\">         0.982 </td></tr>\n",
       "<tr><td>train_mnist_d0fea_00045</td><td style=\"text-align: right;\">         0.9833</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00046</td><td style=\"text-align: right;\">         0.9792</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00047</td><td style=\"text-align: right;\">         0.9807</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00048</td><td style=\"text-align: right;\">         0.9833</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00049</td><td style=\"text-align: right;\">         0.9754</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00050</td><td style=\"text-align: right;\">         0.9851</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00051</td><td style=\"text-align: right;\">         0.1135</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00052</td><td style=\"text-align: right;\">         0.9812</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00053</td><td style=\"text-align: right;\">         0.9845</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00054</td><td style=\"text-align: right;\">         0.9846</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00055</td><td style=\"text-align: right;\">         0.9841</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00056</td><td style=\"text-align: right;\">         0.9839</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00057</td><td style=\"text-align: right;\">         0.9798</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00058</td><td style=\"text-align: right;\">         0.9831</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00059</td><td style=\"text-align: right;\">         0.9855</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00060</td><td style=\"text-align: right;\">         0.9802</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00061</td><td style=\"text-align: right;\">         0.9853</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00062</td><td style=\"text-align: right;\">         0.9851</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00063</td><td style=\"text-align: right;\">         0.9848</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00064</td><td style=\"text-align: right;\">         0.9844</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00065</td><td style=\"text-align: right;\">         0.9866</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00066</td><td style=\"text-align: right;\">         0.9803</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00067</td><td style=\"text-align: right;\">         0.9861</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00068</td><td style=\"text-align: right;\">         0.9864</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00069</td><td style=\"text-align: right;\">         0.9791</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00070</td><td style=\"text-align: right;\">         0.9828</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00071</td><td style=\"text-align: right;\">         0.986 </td></tr>\n",
       "<tr><td>train_mnist_d0fea_00072</td><td style=\"text-align: right;\">         0.9768</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00073</td><td style=\"text-align: right;\">         0.9808</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00074</td><td style=\"text-align: right;\">         0.9847</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00075</td><td style=\"text-align: right;\">         0.9776</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00076</td><td style=\"text-align: right;\">         0.9809</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00077</td><td style=\"text-align: right;\">         0.9861</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00078</td><td style=\"text-align: right;\">         0.9383</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00079</td><td style=\"text-align: right;\">         0.9801</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00080</td><td style=\"text-align: right;\">         0.9826</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00081</td><td style=\"text-align: right;\">         0.9458</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00082</td><td style=\"text-align: right;\">         0.9679</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00083</td><td style=\"text-align: right;\">         0.9763</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00084</td><td style=\"text-align: right;\">         0.1032</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00085</td><td style=\"text-align: right;\">         0.8858</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00086</td><td style=\"text-align: right;\">         0.9756</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00087</td><td style=\"text-align: right;\">         0.893 </td></tr>\n",
       "<tr><td>train_mnist_d0fea_00088</td><td style=\"text-align: right;\">         0.8203</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00089</td><td style=\"text-align: right;\">         0.9707</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00090</td><td style=\"text-align: right;\">         0.098 </td></tr>\n",
       "<tr><td>train_mnist_d0fea_00091</td><td style=\"text-align: right;\">         0.1135</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00092</td><td style=\"text-align: right;\">         0.1135</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00093</td><td style=\"text-align: right;\">         0.098 </td></tr>\n",
       "<tr><td>train_mnist_d0fea_00094</td><td style=\"text-align: right;\">         0.9257</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00095</td><td style=\"text-align: right;\">         0.0982</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00096</td><td style=\"text-align: right;\">         0.101 </td></tr>\n",
       "<tr><td>train_mnist_d0fea_00097</td><td style=\"text-align: right;\">         0.9285</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00098</td><td style=\"text-align: right;\">         0.1028</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00099</td><td style=\"text-align: right;\">         0.1135</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00100</td><td style=\"text-align: right;\">         0.098 </td></tr>\n",
       "<tr><td>train_mnist_d0fea_00101</td><td style=\"text-align: right;\">         0.1135</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00102</td><td style=\"text-align: right;\">         0.1135</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00103</td><td style=\"text-align: right;\">         0.101 </td></tr>\n",
       "<tr><td>train_mnist_d0fea_00104</td><td style=\"text-align: right;\">         0.1135</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00105</td><td style=\"text-align: right;\">         0.1028</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00106</td><td style=\"text-align: right;\">         0.8948</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00107</td><td style=\"text-align: right;\">         0.1135</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00108</td><td style=\"text-align: right;\">         0.0982</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00109</td><td style=\"text-align: right;\">         0.101 </td></tr>\n",
       "<tr><td>train_mnist_d0fea_00110</td><td style=\"text-align: right;\">         0.1028</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00111</td><td style=\"text-align: right;\">         0.1028</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00112</td><td style=\"text-align: right;\">         0.1135</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00113</td><td style=\"text-align: right;\">         0.1135</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00114</td><td style=\"text-align: right;\">         0.101 </td></tr>\n",
       "<tr><td>train_mnist_d0fea_00115</td><td style=\"text-align: right;\">         0.1135</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00116</td><td style=\"text-align: right;\">         0.922 </td></tr>\n",
       "<tr><td>train_mnist_d0fea_00117</td><td style=\"text-align: right;\">         0.0958</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00118</td><td style=\"text-align: right;\">         0.098 </td></tr>\n",
       "<tr><td>train_mnist_d0fea_00119</td><td style=\"text-align: right;\">         0.1028</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00120</td><td style=\"text-align: right;\">         0.1135</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00121</td><td style=\"text-align: right;\">         0.8485</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00122</td><td style=\"text-align: right;\">         0.1135</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00123</td><td style=\"text-align: right;\">         0.1009</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00124</td><td style=\"text-align: right;\">         0.1135</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00125</td><td style=\"text-align: right;\">         0.101 </td></tr>\n",
       "<tr><td>train_mnist_d0fea_00126</td><td style=\"text-align: right;\">         0.1028</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00127</td><td style=\"text-align: right;\">         0.1135</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00128</td><td style=\"text-align: right;\">         0.098 </td></tr>\n",
       "<tr><td>train_mnist_d0fea_00129</td><td style=\"text-align: right;\">         0.0982</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00130</td><td style=\"text-align: right;\">         0.1135</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00131</td><td style=\"text-align: right;\">         0.1028</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00132</td><td style=\"text-align: right;\">         0.1032</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00133</td><td style=\"text-align: right;\">         0.1135</td></tr>\n",
       "<tr><td>train_mnist_d0fea_00134</td><td style=\"text-align: right;\">         0.1135</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".trialProgress {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".trialProgress h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".trialProgress td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3184307)\u001b[0m 2023-12-05 12:16:07.126488: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3184307)\u001b[0m 2023-12-05 12:16:07.166194: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3184307)\u001b[0m 2023-12-05 12:16:07.166222: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3184307)\u001b[0m 2023-12-05 12:16:07.167270: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3184307)\u001b[0m 2023-12-05 12:16:07.173313: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3184307)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3184307)\u001b[0m 2023-12-05 12:16:07.869722: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3184307)\u001b[0m 2023-12-05 12:16:09.205062: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3184307)\u001b[0m 2023-12-05 12:16:10.900852: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3184307)\u001b[0m 2023-12-05 12:16:11.239058: I external/local_xla/xla/service/service.cc:168] XLA service 0x1502ddcfe750 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3184307)\u001b[0m 2023-12-05 12:16:11.239103: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3184307)\u001b[0m 2023-12-05 12:16:11.248713: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3184307)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3184307)\u001b[0m I0000 00:00:1701796571.364129 3184393 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3186750)\u001b[0m 2023-12-05 12:16:51.150446: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3186750)\u001b[0m 2023-12-05 12:16:51.189821: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3186750)\u001b[0m 2023-12-05 12:16:51.189844: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3186750)\u001b[0m 2023-12-05 12:16:51.190906: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3186750)\u001b[0m 2023-12-05 12:16:51.196825: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3186750)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3186750)\u001b[0m 2023-12-05 12:16:51.887533: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3186750)\u001b[0m 2023-12-05 12:16:53.186450: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3186750)\u001b[0m 2023-12-05 12:16:54.854886: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3186750)\u001b[0m 2023-12-05 12:16:55.204707: I external/local_xla/xla/service/service.cc:168] XLA service 0x151ef1830b20 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3186750)\u001b[0m 2023-12-05 12:16:55.204741: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3186750)\u001b[0m 2023-12-05 12:16:55.210492: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3186750)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3186750)\u001b[0m I0000 00:00:1701796615.330865 3187191 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3189247)\u001b[0m 2023-12-05 12:17:24.142287: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3189247)\u001b[0m 2023-12-05 12:17:24.181571: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3189247)\u001b[0m 2023-12-05 12:17:24.181593: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3189247)\u001b[0m 2023-12-05 12:17:24.182634: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3189247)\u001b[0m 2023-12-05 12:17:24.188550: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3189247)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3189247)\u001b[0m 2023-12-05 12:17:24.880859: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3189247)\u001b[0m 2023-12-05 12:17:26.199451: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3189247)\u001b[0m 2023-12-05 12:17:27.868462: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3189247)\u001b[0m 2023-12-05 12:17:28.213088: I external/local_xla/xla/service/service.cc:168] XLA service 0x14615dd6b470 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3189247)\u001b[0m 2023-12-05 12:17:28.213127: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3189247)\u001b[0m 2023-12-05 12:17:28.221919: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3189247)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3189247)\u001b[0m I0000 00:00:1701796648.336244 3189331 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3193022)\u001b[0m 2023-12-05 12:18:29.200068: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3193022)\u001b[0m 2023-12-05 12:18:29.239564: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3193022)\u001b[0m 2023-12-05 12:18:29.239591: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3193022)\u001b[0m 2023-12-05 12:18:29.240637: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3193022)\u001b[0m 2023-12-05 12:18:29.246581: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3193022)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3193022)\u001b[0m 2023-12-05 12:18:29.944837: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3193022)\u001b[0m 2023-12-05 12:18:31.235212: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3193022)\u001b[0m 2023-12-05 12:18:32.897277: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3193022)\u001b[0m 2023-12-05 12:18:33.250022: I external/local_xla/xla/service/service.cc:168] XLA service 0x1477706e3710 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3193022)\u001b[0m 2023-12-05 12:18:33.250055: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3193022)\u001b[0m 2023-12-05 12:18:33.257328: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3193022)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3193022)\u001b[0m I0000 00:00:1701796713.371168 3193114 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3195582)\u001b[0m 2023-12-05 12:19:13.248046: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3195582)\u001b[0m 2023-12-05 12:19:13.248070: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3195582)\u001b[0m 2023-12-05 12:19:13.249121: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3195582)\u001b[0m 2023-12-05 12:19:13.255001: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3195582)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3195582)\u001b[0m 2023-12-05 12:19:13.208475: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3195582)\u001b[0m 2023-12-05 12:19:13.967084: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3195582)\u001b[0m 2023-12-05 12:19:15.278665: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3195582)\u001b[0m 2023-12-05 12:19:16.952946: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3195582)\u001b[0m 2023-12-05 12:19:17.322334: I external/local_xla/xla/service/service.cc:168] XLA service 0x14a401d4aca0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3195582)\u001b[0m 2023-12-05 12:19:17.322366: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3195582)\u001b[0m 2023-12-05 12:19:17.334210: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3195582)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3195582)\u001b[0m I0000 00:00:1701796757.450132 3195866 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3198748)\u001b[0m 2023-12-05 12:19:50.294215: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3198748)\u001b[0m 2023-12-05 12:19:50.333840: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3198748)\u001b[0m 2023-12-05 12:19:50.333871: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3198748)\u001b[0m 2023-12-05 12:19:50.334935: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3198748)\u001b[0m 2023-12-05 12:19:50.341000: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3198748)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3198748)\u001b[0m 2023-12-05 12:19:51.054547: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3198748)\u001b[0m 2023-12-05 12:19:52.392715: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3198748)\u001b[0m 2023-12-05 12:19:54.061488: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3198748)\u001b[0m 2023-12-05 12:19:54.419334: I external/local_xla/xla/service/service.cc:168] XLA service 0x14c0106d12d0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3198748)\u001b[0m 2023-12-05 12:19:54.419377: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3198748)\u001b[0m 2023-12-05 12:19:54.431809: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3198748)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3198748)\u001b[0m I0000 00:00:1701796794.549506 3198836 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3202163)\u001b[0m 2023-12-05 12:21:00.310889: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3202163)\u001b[0m 2023-12-05 12:21:00.310916: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3202163)\u001b[0m 2023-12-05 12:21:00.311949: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3202163)\u001b[0m 2023-12-05 12:21:00.317864: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3202163)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3202163)\u001b[0m 2023-12-05 12:21:00.271668: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3202163)\u001b[0m 2023-12-05 12:21:01.015527: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3202163)\u001b[0m 2023-12-05 12:21:02.312343: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3202163)\u001b[0m 2023-12-05 12:21:03.970501: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3202163)\u001b[0m 2023-12-05 12:21:04.350151: I external/local_xla/xla/service/service.cc:168] XLA service 0x14c64c6cdee0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3202163)\u001b[0m 2023-12-05 12:21:04.350193: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3202163)\u001b[0m 2023-12-05 12:21:04.356849: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3202163)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3202163)\u001b[0m I0000 00:00:1701796864.478651 3202655 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3205785)\u001b[0m 2023-12-05 12:21:54.309919: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3205785)\u001b[0m 2023-12-05 12:21:54.349692: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3205785)\u001b[0m 2023-12-05 12:21:54.349723: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3205785)\u001b[0m 2023-12-05 12:21:54.350771: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3205785)\u001b[0m 2023-12-05 12:21:54.356858: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3205785)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3205785)\u001b[0m 2023-12-05 12:21:55.078640: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3205785)\u001b[0m 2023-12-05 12:21:56.394920: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3205785)\u001b[0m 2023-12-05 12:21:58.068789: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3205785)\u001b[0m 2023-12-05 12:21:58.479910: I external/local_xla/xla/service/service.cc:168] XLA service 0x153838d990b0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3205785)\u001b[0m 2023-12-05 12:21:58.479934: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3205785)\u001b[0m 2023-12-05 12:21:58.486527: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3205785)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3205785)\u001b[0m I0000 00:00:1701796918.601170 3206064 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3208531)\u001b[0m 2023-12-05 12:22:41.300891: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3208531)\u001b[0m 2023-12-05 12:22:41.300917: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3208531)\u001b[0m 2023-12-05 12:22:41.301976: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3208531)\u001b[0m 2023-12-05 12:22:41.307916: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3208531)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3208531)\u001b[0m 2023-12-05 12:22:41.261244: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3208531)\u001b[0m 2023-12-05 12:22:41.999956: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3208531)\u001b[0m 2023-12-05 12:22:43.308712: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3208531)\u001b[0m 2023-12-05 12:22:44.987469: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3208531)\u001b[0m 2023-12-05 12:22:45.953008: I external/local_xla/xla/service/service.cc:168] XLA service 0x144fb431e2e0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3208531)\u001b[0m 2023-12-05 12:22:45.953067: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3208531)\u001b[0m 2023-12-05 12:22:45.961988: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3208531)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3208531)\u001b[0m I0000 00:00:1701796966.084348 3209023 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3212973)\u001b[0m 2023-12-05 12:23:49.279570: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3212973)\u001b[0m 2023-12-05 12:23:49.319076: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3212973)\u001b[0m 2023-12-05 12:23:49.319101: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3212973)\u001b[0m 2023-12-05 12:23:49.320139: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3212973)\u001b[0m 2023-12-05 12:23:49.325982: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3212973)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3212973)\u001b[0m 2023-12-05 12:23:50.015891: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3212973)\u001b[0m 2023-12-05 12:23:51.318262: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3212973)\u001b[0m 2023-12-05 12:23:52.982738: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3212973)\u001b[0m 2023-12-05 12:23:53.931078: I external/local_xla/xla/service/service.cc:168] XLA service 0x14485dd38d70 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3212973)\u001b[0m 2023-12-05 12:23:53.931122: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3212973)\u001b[0m 2023-12-05 12:23:53.943385: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3212973)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3212973)\u001b[0m I0000 00:00:1701797034.051963 3213502 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3215945)\u001b[0m 2023-12-05 12:24:35.321380: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3215945)\u001b[0m 2023-12-05 12:24:35.321407: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3215945)\u001b[0m 2023-12-05 12:24:35.322452: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3215945)\u001b[0m 2023-12-05 12:24:35.328400: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3215945)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3215945)\u001b[0m 2023-12-05 12:24:35.282015: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3215945)\u001b[0m 2023-12-05 12:24:36.020847: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3215945)\u001b[0m 2023-12-05 12:24:37.320848: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3215945)\u001b[0m 2023-12-05 12:24:38.998316: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3215945)\u001b[0m 2023-12-05 12:24:39.964652: I external/local_xla/xla/service/service.cc:168] XLA service 0x14c1fd833a50 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3215945)\u001b[0m 2023-12-05 12:24:39.964681: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3215945)\u001b[0m 2023-12-05 12:24:39.970663: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3215945)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3215945)\u001b[0m I0000 00:00:1701797080.084376 3216236 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3217909)\u001b[0m 2023-12-05 12:25:09.324244: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3217909)\u001b[0m 2023-12-05 12:25:09.363527: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3217909)\u001b[0m 2023-12-05 12:25:09.363555: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3217909)\u001b[0m 2023-12-05 12:25:09.364588: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3217909)\u001b[0m 2023-12-05 12:25:09.370481: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3217909)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3217909)\u001b[0m 2023-12-05 12:25:10.064552: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3217909)\u001b[0m 2023-12-05 12:25:11.356923: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3217909)\u001b[0m 2023-12-05 12:25:13.037167: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3217909)\u001b[0m 2023-12-05 12:25:13.987283: I external/local_xla/xla/service/service.cc:168] XLA service 0x148c346d0c70 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3217909)\u001b[0m 2023-12-05 12:25:13.987327: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3217909)\u001b[0m 2023-12-05 12:25:13.994228: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3217909)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3217909)\u001b[0m I0000 00:00:1701797114.119175 3218195 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3222410)\u001b[0m 2023-12-05 12:26:17.404781: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3222410)\u001b[0m 2023-12-05 12:26:17.444047: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3222410)\u001b[0m 2023-12-05 12:26:17.444070: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3222410)\u001b[0m 2023-12-05 12:26:17.445120: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3222410)\u001b[0m 2023-12-05 12:26:17.451062: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3222410)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3222410)\u001b[0m 2023-12-05 12:26:18.160276: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3222410)\u001b[0m 2023-12-05 12:26:19.471409: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3222410)\u001b[0m 2023-12-05 12:26:21.203293: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3222410)\u001b[0m 2023-12-05 12:26:22.166789: I external/local_xla/xla/service/service.cc:168] XLA service 0x15093430c540 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3222410)\u001b[0m 2023-12-05 12:26:22.166834: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3222410)\u001b[0m 2023-12-05 12:26:22.177629: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3222410)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3222410)\u001b[0m I0000 00:00:1701797182.293210 3222690 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3225377)\u001b[0m 2023-12-05 12:27:03.398858: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3225377)\u001b[0m 2023-12-05 12:27:03.438580: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3225377)\u001b[0m 2023-12-05 12:27:03.438610: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3225377)\u001b[0m 2023-12-05 12:27:03.439685: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3225377)\u001b[0m 2023-12-05 12:27:03.445790: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3225377)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3225377)\u001b[0m 2023-12-05 12:27:04.166491: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3225377)\u001b[0m 2023-12-05 12:27:05.485925: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3225377)\u001b[0m 2023-12-05 12:27:07.184776: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3225377)\u001b[0m 2023-12-05 12:27:08.159596: I external/local_xla/xla/service/service.cc:168] XLA service 0x151d318042b0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3225377)\u001b[0m 2023-12-05 12:27:08.159625: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3225377)\u001b[0m 2023-12-05 12:27:08.166006: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3225377)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3225377)\u001b[0m I0000 00:00:1701797228.291572 3225461 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3227527)\u001b[0m 2023-12-05 12:27:41.434870: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3227527)\u001b[0m 2023-12-05 12:27:41.434897: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3227527)\u001b[0m 2023-12-05 12:27:41.435941: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3227527)\u001b[0m 2023-12-05 12:27:41.442020: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3227527)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3227527)\u001b[0m 2023-12-05 12:27:41.395587: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3227527)\u001b[0m 2023-12-05 12:27:42.136153: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3227527)\u001b[0m 2023-12-05 12:27:43.420991: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3227527)\u001b[0m 2023-12-05 12:27:45.100909: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3227527)\u001b[0m 2023-12-05 12:27:46.053987: I external/local_xla/xla/service/service.cc:168] XLA service 0x14d18030b4a0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3227527)\u001b[0m 2023-12-05 12:27:46.054042: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3227527)\u001b[0m 2023-12-05 12:27:46.062974: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3227527)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3227527)\u001b[0m I0000 00:00:1701797266.178021 3227812 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3232209)\u001b[0m 2023-12-05 12:28:54.494946: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3232209)\u001b[0m 2023-12-05 12:28:54.534257: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3232209)\u001b[0m 2023-12-05 12:28:54.534281: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3232209)\u001b[0m 2023-12-05 12:28:54.535334: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3232209)\u001b[0m 2023-12-05 12:28:54.541283: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3232209)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3232209)\u001b[0m 2023-12-05 12:28:55.263668: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3232209)\u001b[0m 2023-12-05 12:28:56.570157: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3232209)\u001b[0m 2023-12-05 12:28:58.282601: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3232209)\u001b[0m 2023-12-05 12:28:59.270609: I external/local_xla/xla/service/service.cc:168] XLA service 0x1496ddc10ed0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3232209)\u001b[0m 2023-12-05 12:28:59.270651: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3232209)\u001b[0m 2023-12-05 12:28:59.279862: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3232209)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3232209)\u001b[0m I0000 00:00:1701797339.404314 3232700 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3235815)\u001b[0m 2023-12-05 12:29:50.384512: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3235815)\u001b[0m 2023-12-05 12:29:50.423934: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3235815)\u001b[0m 2023-12-05 12:29:50.423961: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3235815)\u001b[0m 2023-12-05 12:29:50.425022: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3235815)\u001b[0m 2023-12-05 12:29:50.430990: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3235815)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3235815)\u001b[0m 2023-12-05 12:29:51.156542: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3235815)\u001b[0m 2023-12-05 12:29:52.480057: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3235815)\u001b[0m 2023-12-05 12:29:54.154013: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3235815)\u001b[0m 2023-12-05 12:29:55.161298: I external/local_xla/xla/service/service.cc:168] XLA service 0x1507b115f290 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3235815)\u001b[0m 2023-12-05 12:29:55.161324: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3235815)\u001b[0m 2023-12-05 12:29:55.167252: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3235815)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3235815)\u001b[0m I0000 00:00:1701797395.286531 3236299 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3238984)\u001b[0m 2023-12-05 12:30:38.371616: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3238984)\u001b[0m 2023-12-05 12:30:38.410713: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3238984)\u001b[0m 2023-12-05 12:30:38.410734: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3238984)\u001b[0m 2023-12-05 12:30:38.411778: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3238984)\u001b[0m 2023-12-05 12:30:38.417663: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3238984)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3238984)\u001b[0m 2023-12-05 12:30:39.106359: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3238984)\u001b[0m 2023-12-05 12:30:40.390809: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3238984)\u001b[0m 2023-12-05 12:30:42.060948: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3238984)\u001b[0m 2023-12-05 12:30:43.009793: I external/local_xla/xla/service/service.cc:168] XLA service 0x1452086d1760 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3238984)\u001b[0m 2023-12-05 12:30:43.009838: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3238984)\u001b[0m 2023-12-05 12:30:43.018066: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3238984)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3238984)\u001b[0m I0000 00:00:1701797443.137342 3239074 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3242658)\u001b[0m 2023-12-05 12:31:46.424702: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3242658)\u001b[0m 2023-12-05 12:31:46.463755: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3242658)\u001b[0m 2023-12-05 12:31:46.463786: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3242658)\u001b[0m 2023-12-05 12:31:46.464829: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3242658)\u001b[0m 2023-12-05 12:31:46.470860: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3242658)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3242658)\u001b[0m 2023-12-05 12:31:47.182260: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3242658)\u001b[0m 2023-12-05 12:31:48.537453: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3242658)\u001b[0m 2023-12-05 12:31:50.274832: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3242658)\u001b[0m 2023-12-05 12:31:51.227554: I external/local_xla/xla/service/service.cc:168] XLA service 0x1538702f62a0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3242658)\u001b[0m 2023-12-05 12:31:51.227597: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3242658)\u001b[0m 2023-12-05 12:31:51.238004: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3242658)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3242658)\u001b[0m I0000 00:00:1701797511.347611 3242758 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3245853)\u001b[0m 2023-12-05 12:32:31.551902: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3245853)\u001b[0m 2023-12-05 12:32:31.591358: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3245853)\u001b[0m 2023-12-05 12:32:31.591385: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3245853)\u001b[0m 2023-12-05 12:32:31.592448: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3245853)\u001b[0m 2023-12-05 12:32:31.598475: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3245853)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3245853)\u001b[0m 2023-12-05 12:32:32.339342: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3245853)\u001b[0m 2023-12-05 12:32:33.657940: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3245853)\u001b[0m 2023-12-05 12:32:35.354877: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3245853)\u001b[0m 2023-12-05 12:32:36.303736: I external/local_xla/xla/service/service.cc:168] XLA service 0x150edcd95850 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3245853)\u001b[0m 2023-12-05 12:32:36.303771: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3245853)\u001b[0m 2023-12-05 12:32:36.309353: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3245853)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3245853)\u001b[0m I0000 00:00:1701797556.422858 3245938 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3248015)\u001b[0m 2023-12-05 12:33:06.498150: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3248015)\u001b[0m 2023-12-05 12:33:06.537187: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3248015)\u001b[0m 2023-12-05 12:33:06.537212: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3248015)\u001b[0m 2023-12-05 12:33:06.538250: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3248015)\u001b[0m 2023-12-05 12:33:06.544124: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3248015)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3248015)\u001b[0m 2023-12-05 12:33:07.232469: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3248015)\u001b[0m 2023-12-05 12:33:08.517135: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3248015)\u001b[0m 2023-12-05 12:33:10.217463: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3248015)\u001b[0m 2023-12-05 12:33:11.172266: I external/local_xla/xla/service/service.cc:168] XLA service 0x150efc30b390 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3248015)\u001b[0m 2023-12-05 12:33:11.172311: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3248015)\u001b[0m 2023-12-05 12:33:11.181682: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3248015)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3248015)\u001b[0m I0000 00:00:1701797591.295916 3248303 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3252234)\u001b[0m 2023-12-05 12:34:15.511514: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3252234)\u001b[0m 2023-12-05 12:34:15.550681: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3252234)\u001b[0m 2023-12-05 12:34:15.550710: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3252234)\u001b[0m 2023-12-05 12:34:15.551754: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3252234)\u001b[0m 2023-12-05 12:34:15.557724: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3252234)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3252234)\u001b[0m 2023-12-05 12:34:16.268356: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3252234)\u001b[0m 2023-12-05 12:34:17.590488: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3252234)\u001b[0m 2023-12-05 12:34:19.268716: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3252234)\u001b[0m 2023-12-05 12:34:20.268193: I external/local_xla/xla/service/service.cc:168] XLA service 0x148c2d51f2a0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3252234)\u001b[0m 2023-12-05 12:34:20.268234: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3252234)\u001b[0m 2023-12-05 12:34:20.276048: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3252234)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3252234)\u001b[0m I0000 00:00:1701797660.395842 3252328 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3255428)\u001b[0m 2023-12-05 12:35:01.527377: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3255428)\u001b[0m 2023-12-05 12:35:01.566887: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3255428)\u001b[0m 2023-12-05 12:35:01.566911: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3255428)\u001b[0m 2023-12-05 12:35:01.567975: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3255428)\u001b[0m 2023-12-05 12:35:01.573903: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3255428)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3255428)\u001b[0m 2023-12-05 12:35:02.263743: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3255428)\u001b[0m 2023-12-05 12:35:03.553016: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3255428)\u001b[0m 2023-12-05 12:35:05.226464: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3255428)\u001b[0m 2023-12-05 12:35:06.198919: I external/local_xla/xla/service/service.cc:168] XLA service 0x14bc8dcf6070 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3255428)\u001b[0m 2023-12-05 12:35:06.198950: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3255428)\u001b[0m 2023-12-05 12:35:06.204764: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3255428)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3255428)\u001b[0m I0000 00:00:1701797706.319922 3255509 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3257587)\u001b[0m 2023-12-05 12:35:39.500719: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3257587)\u001b[0m 2023-12-05 12:35:39.540021: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3257587)\u001b[0m 2023-12-05 12:35:39.540047: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3257587)\u001b[0m 2023-12-05 12:35:39.541100: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3257587)\u001b[0m 2023-12-05 12:35:39.546986: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3257587)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3257587)\u001b[0m 2023-12-05 12:35:40.259948: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3257587)\u001b[0m 2023-12-05 12:35:41.582183: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3257587)\u001b[0m 2023-12-05 12:35:43.258786: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3257587)\u001b[0m 2023-12-05 12:35:44.223851: I external/local_xla/xla/service/service.cc:168] XLA service 0x14bcd06e38d0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3257587)\u001b[0m 2023-12-05 12:35:44.223894: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3257587)\u001b[0m 2023-12-05 12:35:44.231852: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3257587)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3257587)\u001b[0m I0000 00:00:1701797744.355125 3257877 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3261885)\u001b[0m 2023-12-05 12:36:51.499132: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3261885)\u001b[0m 2023-12-05 12:36:51.538134: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3261885)\u001b[0m 2023-12-05 12:36:51.538157: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3261885)\u001b[0m 2023-12-05 12:36:51.539196: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3261885)\u001b[0m 2023-12-05 12:36:51.545049: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3261885)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3261885)\u001b[0m 2023-12-05 12:36:52.231671: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3261885)\u001b[0m 2023-12-05 12:36:53.529012: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3261885)\u001b[0m 2023-12-05 12:36:55.215627: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3261885)\u001b[0m 2023-12-05 12:36:56.206733: I external/local_xla/xla/service/service.cc:168] XLA service 0x149849ccff90 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3261885)\u001b[0m 2023-12-05 12:36:56.206777: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3261885)\u001b[0m 2023-12-05 12:36:56.214069: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3261885)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3261885)\u001b[0m I0000 00:00:1701797816.336079 3261970 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3265063)\u001b[0m 2023-12-05 12:37:46.549475: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3265063)\u001b[0m 2023-12-05 12:37:46.588915: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3265063)\u001b[0m 2023-12-05 12:37:46.588940: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3265063)\u001b[0m 2023-12-05 12:37:46.590015: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3265063)\u001b[0m 2023-12-05 12:37:46.596042: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3265063)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3265063)\u001b[0m 2023-12-05 12:37:47.311239: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3265063)\u001b[0m 2023-12-05 12:37:48.646474: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3265063)\u001b[0m 2023-12-05 12:37:50.340342: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3265063)\u001b[0m 2023-12-05 12:37:51.348699: I external/local_xla/xla/service/service.cc:168] XLA service 0x15212515f230 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3265063)\u001b[0m 2023-12-05 12:37:51.348724: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3265063)\u001b[0m 2023-12-05 12:37:51.353792: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3265063)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3265063)\u001b[0m I0000 00:00:1701797871.476117 3265160 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3268260)\u001b[0m 2023-12-05 12:38:34.571825: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3268260)\u001b[0m 2023-12-05 12:38:34.611147: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3268260)\u001b[0m 2023-12-05 12:38:34.611172: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3268260)\u001b[0m 2023-12-05 12:38:34.612227: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3268260)\u001b[0m 2023-12-05 12:38:34.618156: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3268260)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3268260)\u001b[0m 2023-12-05 12:38:35.315762: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3268260)\u001b[0m 2023-12-05 12:38:36.638006: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3268260)\u001b[0m 2023-12-05 12:38:38.302724: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3268260)\u001b[0m 2023-12-05 12:38:39.250325: I external/local_xla/xla/service/service.cc:168] XLA service 0x14cd042f58c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3268260)\u001b[0m 2023-12-05 12:38:39.250363: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3268260)\u001b[0m 2023-12-05 12:38:39.259280: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3268260)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3268260)\u001b[0m I0000 00:00:1701797919.373902 3268344 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3271700)\u001b[0m 2023-12-05 12:39:42.597702: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3271700)\u001b[0m 2023-12-05 12:39:42.636942: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3271700)\u001b[0m 2023-12-05 12:39:42.636967: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3271700)\u001b[0m 2023-12-05 12:39:42.638033: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3271700)\u001b[0m 2023-12-05 12:39:42.643960: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3271700)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3271700)\u001b[0m 2023-12-05 12:39:43.333627: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3271700)\u001b[0m 2023-12-05 12:39:44.628864: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3271700)\u001b[0m 2023-12-05 12:39:46.327531: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3271700)\u001b[0m 2023-12-05 12:39:47.292875: I external/local_xla/xla/service/service.cc:168] XLA service 0x1507386e35e0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3271700)\u001b[0m 2023-12-05 12:39:47.292920: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3271700)\u001b[0m 2023-12-05 12:39:47.300798: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3271700)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3271700)\u001b[0m I0000 00:00:1701797987.424697 3272184 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3274659)\u001b[0m 2023-12-05 12:40:27.609992: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3274659)\u001b[0m 2023-12-05 12:40:27.649336: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3274659)\u001b[0m 2023-12-05 12:40:27.649361: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3274659)\u001b[0m 2023-12-05 12:40:27.650381: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3274659)\u001b[0m 2023-12-05 12:40:27.656292: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3274659)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3274659)\u001b[0m 2023-12-05 12:40:28.347173: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3274659)\u001b[0m 2023-12-05 12:40:29.638753: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3274659)\u001b[0m 2023-12-05 12:40:31.341601: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3274659)\u001b[0m 2023-12-05 12:40:32.303188: I external/local_xla/xla/service/service.cc:168] XLA service 0x14be2515e820 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3274659)\u001b[0m 2023-12-05 12:40:32.303218: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3274659)\u001b[0m 2023-12-05 12:40:32.309250: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3274659)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3274659)\u001b[0m I0000 00:00:1701798032.421343 3274835 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3277864)\u001b[0m 2023-12-05 12:41:01.663589: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3277864)\u001b[0m 2023-12-05 12:41:01.703276: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3277864)\u001b[0m 2023-12-05 12:41:01.703306: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3277864)\u001b[0m 2023-12-05 12:41:01.704348: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3277864)\u001b[0m 2023-12-05 12:41:01.710402: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3277864)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3277864)\u001b[0m 2023-12-05 12:41:02.447327: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3277864)\u001b[0m 2023-12-05 12:41:03.772140: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3277864)\u001b[0m 2023-12-05 12:41:05.461370: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3277864)\u001b[0m 2023-12-05 12:41:06.406743: I external/local_xla/xla/service/service.cc:168] XLA service 0x14fd142f5040 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3277864)\u001b[0m 2023-12-05 12:41:06.406785: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3277864)\u001b[0m 2023-12-05 12:41:06.416639: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3277864)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3277864)\u001b[0m I0000 00:00:1701798066.532052 3277947 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3281097)\u001b[0m 2023-12-05 12:42:10.571668: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3281097)\u001b[0m 2023-12-05 12:42:10.611405: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3281097)\u001b[0m 2023-12-05 12:42:10.611430: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3281097)\u001b[0m 2023-12-05 12:42:10.612479: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3281097)\u001b[0m 2023-12-05 12:42:10.618376: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3281097)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3281097)\u001b[0m 2023-12-05 12:42:11.318658: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3281097)\u001b[0m 2023-12-05 12:42:12.615899: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3281097)\u001b[0m 2023-12-05 12:42:14.321586: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3281097)\u001b[0m 2023-12-05 12:42:15.299777: I external/local_xla/xla/service/service.cc:168] XLA service 0x14dc346bb900 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3281097)\u001b[0m 2023-12-05 12:42:15.299813: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3281097)\u001b[0m 2023-12-05 12:42:15.308146: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3281097)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3281097)\u001b[0m I0000 00:00:1701798135.433822 3281417 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3284291)\u001b[0m 2023-12-05 12:42:56.607773: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3284291)\u001b[0m 2023-12-05 12:42:56.647101: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3284291)\u001b[0m 2023-12-05 12:42:56.647127: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3284291)\u001b[0m 2023-12-05 12:42:56.648166: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3284291)\u001b[0m 2023-12-05 12:42:56.654111: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3284291)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3284291)\u001b[0m 2023-12-05 12:42:57.340432: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3284291)\u001b[0m 2023-12-05 12:42:58.619200: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3284291)\u001b[0m 2023-12-05 12:43:00.309343: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3284291)\u001b[0m 2023-12-05 12:43:01.282971: I external/local_xla/xla/service/service.cc:168] XLA service 0x14fb41d09280 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3284291)\u001b[0m 2023-12-05 12:43:01.282995: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3284291)\u001b[0m 2023-12-05 12:43:01.289301: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3284291)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3284291)\u001b[0m I0000 00:00:1701798181.415345 3284374 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3287465)\u001b[0m 2023-12-05 12:43:34.668180: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3287465)\u001b[0m 2023-12-05 12:43:34.707872: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3287465)\u001b[0m 2023-12-05 12:43:34.707895: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3287465)\u001b[0m 2023-12-05 12:43:34.708933: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3287465)\u001b[0m 2023-12-05 12:43:34.714871: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3287465)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3287465)\u001b[0m 2023-12-05 12:43:35.405588: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3287465)\u001b[0m 2023-12-05 12:43:36.724422: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3287465)\u001b[0m 2023-12-05 12:43:38.415673: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3287465)\u001b[0m 2023-12-05 12:43:39.371722: I external/local_xla/xla/service/service.cc:168] XLA service 0x150cc02f4e80 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3287465)\u001b[0m 2023-12-05 12:43:39.371761: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3287465)\u001b[0m 2023-12-05 12:43:39.380674: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3287465)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3287465)\u001b[0m I0000 00:00:1701798219.497276 3287551 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3290900)\u001b[0m 2023-12-05 12:44:46.688841: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3290900)\u001b[0m 2023-12-05 12:44:46.728746: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3290900)\u001b[0m 2023-12-05 12:44:46.728769: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3290900)\u001b[0m 2023-12-05 12:44:46.729835: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3290900)\u001b[0m 2023-12-05 12:44:46.735835: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3290900)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3290900)\u001b[0m 2023-12-05 12:44:47.445380: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3290900)\u001b[0m 2023-12-05 12:44:48.737797: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3290900)\u001b[0m 2023-12-05 12:44:50.417486: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3290900)\u001b[0m 2023-12-05 12:44:51.390932: I external/local_xla/xla/service/service.cc:168] XLA service 0x143c79d596c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3290900)\u001b[0m 2023-12-05 12:44:51.390959: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3290900)\u001b[0m 2023-12-05 12:44:51.398039: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3290900)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3290900)\u001b[0m I0000 00:00:1701798291.511354 3291015 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3294387)\u001b[0m 2023-12-05 12:45:42.696236: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3294387)\u001b[0m 2023-12-05 12:45:42.736279: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3294387)\u001b[0m 2023-12-05 12:45:42.736301: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3294387)\u001b[0m 2023-12-05 12:45:42.737351: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3294387)\u001b[0m 2023-12-05 12:45:42.743265: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3294387)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3294387)\u001b[0m 2023-12-05 12:45:43.466377: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3294387)\u001b[0m 2023-12-05 12:45:45.712708: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3294387)\u001b[0m 2023-12-05 12:45:47.400221: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3294387)\u001b[0m 2023-12-05 12:45:48.431078: I external/local_xla/xla/service/service.cc:168] XLA service 0x14b620d99420 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3294387)\u001b[0m 2023-12-05 12:45:48.431104: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3294387)\u001b[0m 2023-12-05 12:45:48.437149: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3294387)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3294387)\u001b[0m I0000 00:00:1701798348.556476 3294879 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3297409)\u001b[0m 2023-12-05 12:46:31.756010: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3297409)\u001b[0m 2023-12-05 12:46:31.795196: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3297409)\u001b[0m 2023-12-05 12:46:31.795219: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3297409)\u001b[0m 2023-12-05 12:46:31.796277: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3297409)\u001b[0m 2023-12-05 12:46:31.802211: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3297409)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3297409)\u001b[0m 2023-12-05 12:46:32.495791: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3297409)\u001b[0m 2023-12-05 12:46:33.784646: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3297409)\u001b[0m 2023-12-05 12:46:35.481942: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3297409)\u001b[0m 2023-12-05 12:46:36.441872: I external/local_xla/xla/service/service.cc:168] XLA service 0x1474a46d14e0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3297409)\u001b[0m 2023-12-05 12:46:36.441915: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3297409)\u001b[0m 2023-12-05 12:46:36.450327: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3297409)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3297409)\u001b[0m I0000 00:00:1701798396.564957 3297898 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3301863)\u001b[0m 2023-12-05 12:47:39.844277: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3301863)\u001b[0m 2023-12-05 12:47:39.883642: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3301863)\u001b[0m 2023-12-05 12:47:39.883670: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3301863)\u001b[0m 2023-12-05 12:47:39.884719: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3301863)\u001b[0m 2023-12-05 12:47:39.890640: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3301863)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3301863)\u001b[0m 2023-12-05 12:47:40.585549: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3301863)\u001b[0m 2023-12-05 12:47:41.882719: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3301863)\u001b[0m 2023-12-05 12:47:43.565606: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3301863)\u001b[0m 2023-12-05 12:47:44.516283: I external/local_xla/xla/service/service.cc:168] XLA service 0x1455a030c400 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3301863)\u001b[0m 2023-12-05 12:47:44.516325: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3301863)\u001b[0m 2023-12-05 12:47:44.527224: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3301863)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3301863)\u001b[0m I0000 00:00:1701798464.642307 3302355 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3304659)\u001b[0m 2023-12-05 12:48:25.745836: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3304659)\u001b[0m 2023-12-05 12:48:25.785616: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3304659)\u001b[0m 2023-12-05 12:48:25.785642: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3304659)\u001b[0m 2023-12-05 12:48:25.786694: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3304659)\u001b[0m 2023-12-05 12:48:25.792643: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3304659)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3304659)\u001b[0m 2023-12-05 12:48:26.497265: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3304659)\u001b[0m 2023-12-05 12:48:27.817361: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3304659)\u001b[0m 2023-12-05 12:48:29.509478: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3304659)\u001b[0m 2023-12-05 12:48:30.477628: I external/local_xla/xla/service/service.cc:168] XLA service 0x152de4d9ff90 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3304659)\u001b[0m 2023-12-05 12:48:30.477655: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3304659)\u001b[0m 2023-12-05 12:48:30.483565: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3304659)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3304659)\u001b[0m I0000 00:00:1701798510.606122 3305152 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3306821)\u001b[0m 2023-12-05 12:49:00.794639: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3306821)\u001b[0m 2023-12-05 12:49:00.834187: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3306821)\u001b[0m 2023-12-05 12:49:00.834213: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3306821)\u001b[0m 2023-12-05 12:49:00.835233: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3306821)\u001b[0m 2023-12-05 12:49:00.841173: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3306821)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3306821)\u001b[0m 2023-12-05 12:49:01.533965: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3306821)\u001b[0m 2023-12-05 12:49:02.831397: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3306821)\u001b[0m 2023-12-05 12:49:04.527676: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3306821)\u001b[0m 2023-12-05 12:49:05.482496: I external/local_xla/xla/service/service.cc:168] XLA service 0x14d76d7ee180 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3306821)\u001b[0m 2023-12-05 12:49:05.482540: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3306821)\u001b[0m 2023-12-05 12:49:05.490353: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3306821)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3306821)\u001b[0m I0000 00:00:1701798545.601570 3307109 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3311233)\u001b[0m 2023-12-05 12:50:08.747397: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3311233)\u001b[0m 2023-12-05 12:50:08.786684: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3311233)\u001b[0m 2023-12-05 12:50:08.786712: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3311233)\u001b[0m 2023-12-05 12:50:08.787760: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3311233)\u001b[0m 2023-12-05 12:50:08.793708: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3311233)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3311233)\u001b[0m 2023-12-05 12:50:09.484084: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3311233)\u001b[0m 2023-12-05 12:50:10.795419: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3311233)\u001b[0m 2023-12-05 12:50:12.513817: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3311233)\u001b[0m 2023-12-05 12:50:13.481311: I external/local_xla/xla/service/service.cc:168] XLA service 0x1443a030ca30 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3311233)\u001b[0m 2023-12-05 12:50:13.481357: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3311233)\u001b[0m 2023-12-05 12:50:13.491882: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3311233)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3311233)\u001b[0m I0000 00:00:1701798613.607901 3311530 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3314000)\u001b[0m 2023-12-05 12:50:54.865685: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3314000)\u001b[0m 2023-12-05 12:50:54.905794: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3314000)\u001b[0m 2023-12-05 12:50:54.905817: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3314000)\u001b[0m 2023-12-05 12:50:54.906883: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3314000)\u001b[0m 2023-12-05 12:50:54.912913: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3314000)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3314000)\u001b[0m 2023-12-05 12:50:55.631333: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3314000)\u001b[0m 2023-12-05 12:50:56.959066: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3314000)\u001b[0m 2023-12-05 12:50:58.652037: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3314000)\u001b[0m 2023-12-05 12:50:59.612789: I external/local_xla/xla/service/service.cc:168] XLA service 0x14e9c5d4abc0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3314000)\u001b[0m 2023-12-05 12:50:59.612817: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3314000)\u001b[0m 2023-12-05 12:50:59.618739: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3314000)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3314000)\u001b[0m I0000 00:00:1701798659.744331 3314347 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3316418)\u001b[0m 2023-12-05 12:51:32.846334: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3316418)\u001b[0m 2023-12-05 12:51:32.885261: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3316418)\u001b[0m 2023-12-05 12:51:32.885285: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3316418)\u001b[0m 2023-12-05 12:51:32.886324: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3316418)\u001b[0m 2023-12-05 12:51:32.892253: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3316418)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3316418)\u001b[0m 2023-12-05 12:51:33.608405: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3316418)\u001b[0m 2023-12-05 12:51:34.974279: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3316418)\u001b[0m 2023-12-05 12:51:36.643172: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3316418)\u001b[0m 2023-12-05 12:51:37.599592: I external/local_xla/xla/service/service.cc:168] XLA service 0x1495746bb590 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3316418)\u001b[0m 2023-12-05 12:51:37.599620: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3316418)\u001b[0m 2023-12-05 12:51:37.606665: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3316418)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3316418)\u001b[0m I0000 00:00:1701798697.728766 3316605 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3321082)\u001b[0m 2023-12-05 12:52:44.846171: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3321082)\u001b[0m 2023-12-05 12:52:44.885485: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3321082)\u001b[0m 2023-12-05 12:52:44.885509: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3321082)\u001b[0m 2023-12-05 12:52:44.886551: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3321082)\u001b[0m 2023-12-05 12:52:44.892478: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3321082)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3321082)\u001b[0m 2023-12-05 12:52:45.601397: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3321082)\u001b[0m 2023-12-05 12:52:46.896597: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3321082)\u001b[0m 2023-12-05 12:52:48.566611: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3321082)\u001b[0m 2023-12-05 12:52:49.533076: I external/local_xla/xla/service/service.cc:168] XLA service 0x1479586d2130 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3321082)\u001b[0m 2023-12-05 12:52:49.533121: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3321082)\u001b[0m 2023-12-05 12:52:49.539748: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3321082)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3321082)\u001b[0m I0000 00:00:1701798769.649709 3321368 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3324583)\u001b[0m 2023-12-05 12:53:39.915758: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3324583)\u001b[0m 2023-12-05 12:53:39.955406: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3324583)\u001b[0m 2023-12-05 12:53:39.955439: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3324583)\u001b[0m 2023-12-05 12:53:39.956483: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3324583)\u001b[0m 2023-12-05 12:53:39.962536: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3324583)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3324583)\u001b[0m 2023-12-05 12:53:40.707984: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3324583)\u001b[0m 2023-12-05 12:53:42.071078: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3324583)\u001b[0m 2023-12-05 12:53:43.787495: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3324583)\u001b[0m 2023-12-05 12:53:44.793321: I external/local_xla/xla/service/service.cc:168] XLA service 0x14f1b9d58f90 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3324583)\u001b[0m 2023-12-05 12:53:44.793351: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3324583)\u001b[0m 2023-12-05 12:53:44.799602: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3324583)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3324583)\u001b[0m I0000 00:00:1701798824.913120 3324778 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3327472)\u001b[0m 2023-12-05 12:54:27.899543: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3327472)\u001b[0m 2023-12-05 12:54:27.939180: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3327472)\u001b[0m 2023-12-05 12:54:27.939207: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3327472)\u001b[0m 2023-12-05 12:54:27.940274: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3327472)\u001b[0m 2023-12-05 12:54:27.946239: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3327472)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3327472)\u001b[0m 2023-12-05 12:54:28.651848: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3327472)\u001b[0m 2023-12-05 12:54:29.984581: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3327472)\u001b[0m 2023-12-05 12:54:31.678498: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3327472)\u001b[0m 2023-12-05 12:54:32.028941: I external/local_xla/xla/service/service.cc:168] XLA service 0x152d31cecb30 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3327472)\u001b[0m 2023-12-05 12:54:32.028988: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3327472)\u001b[0m 2023-12-05 12:54:32.042061: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3327472)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3327472)\u001b[0m I0000 00:00:1701798872.161241 3327955 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3331505)\u001b[0m 2023-12-05 12:55:33.964133: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3331505)\u001b[0m 2023-12-05 12:55:34.003238: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3331505)\u001b[0m 2023-12-05 12:55:34.003260: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3331505)\u001b[0m 2023-12-05 12:55:34.004299: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3331505)\u001b[0m 2023-12-05 12:55:34.010220: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3331505)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3331505)\u001b[0m 2023-12-05 12:55:34.734861: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3331505)\u001b[0m 2023-12-05 12:55:36.088381: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3331505)\u001b[0m 2023-12-05 12:55:37.773215: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3331505)\u001b[0m 2023-12-05 12:55:38.119364: I external/local_xla/xla/service/service.cc:168] XLA service 0x149d042f60e0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3331505)\u001b[0m 2023-12-05 12:55:38.119407: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3331505)\u001b[0m 2023-12-05 12:55:38.128528: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3331505)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3331505)\u001b[0m I0000 00:00:1701798938.243104 3331590 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3334246)\u001b[0m 2023-12-05 12:56:17.964343: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3334246)\u001b[0m 2023-12-05 12:56:18.004081: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3334246)\u001b[0m 2023-12-05 12:56:18.004104: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3334246)\u001b[0m 2023-12-05 12:56:18.005156: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3334246)\u001b[0m 2023-12-05 12:56:18.011129: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3334246)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3334246)\u001b[0m 2023-12-05 12:56:18.730352: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3334246)\u001b[0m 2023-12-05 12:56:20.064293: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3334246)\u001b[0m 2023-12-05 12:56:21.755872: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3334246)\u001b[0m 2023-12-05 12:56:22.113204: I external/local_xla/xla/service/service.cc:168] XLA service 0x14555915a5b0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3334246)\u001b[0m 2023-12-05 12:56:22.113234: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3334246)\u001b[0m 2023-12-05 12:56:22.119033: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3334246)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3334246)\u001b[0m I0000 00:00:1701798982.241837 3334744 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3336220)\u001b[0m 2023-12-05 12:56:51.915226: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3336220)\u001b[0m 2023-12-05 12:56:51.954697: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3336220)\u001b[0m 2023-12-05 12:56:51.954726: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3336220)\u001b[0m 2023-12-05 12:56:51.955770: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3336220)\u001b[0m 2023-12-05 12:56:51.961775: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3336220)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3336220)\u001b[0m 2023-12-05 12:56:52.679288: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3336220)\u001b[0m 2023-12-05 12:56:54.014309: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3336220)\u001b[0m 2023-12-05 12:56:55.706904: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3336220)\u001b[0m 2023-12-05 12:56:56.045060: I external/local_xla/xla/service/service.cc:168] XLA service 0x15345c2f5f70 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3336220)\u001b[0m 2023-12-05 12:56:56.045107: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3336220)\u001b[0m 2023-12-05 12:56:56.054694: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3336220)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3336220)\u001b[0m I0000 00:00:1701799016.178117 3336702 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3340644)\u001b[0m 2023-12-05 12:57:58.036316: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3340644)\u001b[0m 2023-12-05 12:57:58.075889: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3340644)\u001b[0m 2023-12-05 12:57:58.075918: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3340644)\u001b[0m 2023-12-05 12:57:58.076975: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3340644)\u001b[0m 2023-12-05 12:57:58.083003: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3340644)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3340644)\u001b[0m 2023-12-05 12:57:58.803635: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3340644)\u001b[0m 2023-12-05 12:58:00.129043: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3340644)\u001b[0m 2023-12-05 12:58:01.772375: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3340644)\u001b[0m 2023-12-05 12:58:02.118586: I external/local_xla/xla/service/service.cc:168] XLA service 0x147f71524a60 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3340644)\u001b[0m 2023-12-05 12:58:02.118629: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3340644)\u001b[0m 2023-12-05 12:58:02.129629: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3340644)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3340644)\u001b[0m I0000 00:00:1701799082.245257 3340926 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3343327)\u001b[0m 2023-12-05 12:58:43.044440: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3343327)\u001b[0m 2023-12-05 12:58:43.084018: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3343327)\u001b[0m 2023-12-05 12:58:43.084055: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3343327)\u001b[0m 2023-12-05 12:58:43.085114: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3343327)\u001b[0m 2023-12-05 12:58:43.091131: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3343327)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3343327)\u001b[0m 2023-12-05 12:58:43.806306: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3343327)\u001b[0m 2023-12-05 12:58:45.116765: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3343327)\u001b[0m 2023-12-05 12:58:46.780570: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3343327)\u001b[0m 2023-12-05 12:58:47.159509: I external/local_xla/xla/service/service.cc:168] XLA service 0x1457a915e310 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3343327)\u001b[0m 2023-12-05 12:58:47.159532: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3343327)\u001b[0m 2023-12-05 12:58:47.164752: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3343327)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3343327)\u001b[0m I0000 00:00:1701799127.283364 3343475 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3345335)\u001b[0m 2023-12-05 12:59:21.051176: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3345335)\u001b[0m 2023-12-05 12:59:21.090678: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3345335)\u001b[0m 2023-12-05 12:59:21.090708: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3345335)\u001b[0m 2023-12-05 12:59:21.091784: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3345335)\u001b[0m 2023-12-05 12:59:21.097858: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3345335)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3345335)\u001b[0m 2023-12-05 12:59:21.804755: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3345335)\u001b[0m 2023-12-05 12:59:23.120182: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3345335)\u001b[0m 2023-12-05 12:59:24.842852: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3345335)\u001b[0m 2023-12-05 12:59:25.198474: I external/local_xla/xla/service/service.cc:168] XLA service 0x144761cfed10 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3345335)\u001b[0m 2023-12-05 12:59:25.198519: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3345335)\u001b[0m 2023-12-05 12:59:25.208155: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3345335)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3345335)\u001b[0m I0000 00:00:1701799165.331202 3345830 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3350148)\u001b[0m 2023-12-05 13:00:31.042965: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3350148)\u001b[0m 2023-12-05 13:00:31.082153: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3350148)\u001b[0m 2023-12-05 13:00:31.082180: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3350148)\u001b[0m 2023-12-05 13:00:31.083224: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3350148)\u001b[0m 2023-12-05 13:00:31.089170: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3350148)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3350148)\u001b[0m 2023-12-05 13:00:31.784582: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3350148)\u001b[0m 2023-12-05 13:00:33.112525: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3350148)\u001b[0m 2023-12-05 13:00:34.825278: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3350148)\u001b[0m 2023-12-05 13:00:35.198652: I external/local_xla/xla/service/service.cc:168] XLA service 0x14a0d430b5e0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3350148)\u001b[0m 2023-12-05 13:00:35.198697: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3350148)\u001b[0m 2023-12-05 13:00:35.208835: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3350148)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3350148)\u001b[0m I0000 00:00:1701799235.333587 3350467 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3353761)\u001b[0m 2023-12-05 13:01:26.033356: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3353761)\u001b[0m 2023-12-05 13:01:26.073373: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3353761)\u001b[0m 2023-12-05 13:01:26.073401: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3353761)\u001b[0m 2023-12-05 13:01:26.074481: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3353761)\u001b[0m 2023-12-05 13:01:26.080533: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3353761)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3353761)\u001b[0m 2023-12-05 13:01:26.793815: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3353761)\u001b[0m 2023-12-05 13:01:28.155108: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3353761)\u001b[0m 2023-12-05 13:01:29.871376: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3353761)\u001b[0m 2023-12-05 13:01:30.286345: I external/local_xla/xla/service/service.cc:168] XLA service 0x14d49915ed70 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3353761)\u001b[0m 2023-12-05 13:01:30.286375: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3353761)\u001b[0m 2023-12-05 13:01:30.292346: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3353761)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3353761)\u001b[0m I0000 00:00:1701799290.408326 3353900 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3356569)\u001b[0m 2023-12-05 13:02:13.073924: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3356569)\u001b[0m 2023-12-05 13:02:13.113463: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3356569)\u001b[0m 2023-12-05 13:02:13.113495: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3356569)\u001b[0m 2023-12-05 13:02:13.114536: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3356569)\u001b[0m 2023-12-05 13:02:13.120575: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3356569)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3356569)\u001b[0m 2023-12-05 13:02:13.844395: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3356569)\u001b[0m 2023-12-05 13:02:15.201197: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3356569)\u001b[0m 2023-12-05 13:02:16.893731: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3356569)\u001b[0m 2023-12-05 13:02:17.868508: I external/local_xla/xla/service/service.cc:168] XLA service 0x14d6806e2b60 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3356569)\u001b[0m 2023-12-05 13:02:17.868552: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3356569)\u001b[0m 2023-12-05 13:02:17.877135: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3356569)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3356569)\u001b[0m I0000 00:00:1701799337.999463 3356940 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3360224)\u001b[0m 2023-12-05 13:03:21.062574: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3360224)\u001b[0m 2023-12-05 13:03:21.102288: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3360224)\u001b[0m 2023-12-05 13:03:21.102317: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3360224)\u001b[0m 2023-12-05 13:03:21.103390: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3360224)\u001b[0m 2023-12-05 13:03:21.109450: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3360224)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3360224)\u001b[0m 2023-12-05 13:03:21.822667: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3360224)\u001b[0m 2023-12-05 13:03:23.140958: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3360224)\u001b[0m 2023-12-05 13:03:24.864316: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3360224)\u001b[0m 2023-12-05 13:03:25.807859: I external/local_xla/xla/service/service.cc:168] XLA service 0x1446d5d34a70 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3360224)\u001b[0m 2023-12-05 13:03:25.807902: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3360224)\u001b[0m 2023-12-05 13:03:25.818248: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3360224)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3360224)\u001b[0m I0000 00:00:1701799405.942497 3360308 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3363410)\u001b[0m 2023-12-05 13:04:07.036100: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3363410)\u001b[0m 2023-12-05 13:04:07.075513: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3363410)\u001b[0m 2023-12-05 13:04:07.075538: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3363410)\u001b[0m 2023-12-05 13:04:07.076582: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3363410)\u001b[0m 2023-12-05 13:04:07.082473: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3363410)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3363410)\u001b[0m 2023-12-05 13:04:07.787906: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3363410)\u001b[0m 2023-12-05 13:04:09.111181: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3363410)\u001b[0m 2023-12-05 13:04:10.816558: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3363410)\u001b[0m 2023-12-05 13:04:11.790317: I external/local_xla/xla/service/service.cc:168] XLA service 0x149d30d99270 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3363410)\u001b[0m 2023-12-05 13:04:11.790349: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3363410)\u001b[0m 2023-12-05 13:04:11.796458: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3363410)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3363410)\u001b[0m I0000 00:00:1701799451.910819 3363495 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3365734)\u001b[0m 2023-12-05 13:04:41.034808: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3365734)\u001b[0m 2023-12-05 13:04:41.074109: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3365734)\u001b[0m 2023-12-05 13:04:41.074137: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3365734)\u001b[0m 2023-12-05 13:04:41.075186: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3365734)\u001b[0m 2023-12-05 13:04:41.081160: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3365734)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3365734)\u001b[0m 2023-12-05 13:04:41.788354: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3365734)\u001b[0m 2023-12-05 13:04:43.114497: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3365734)\u001b[0m 2023-12-05 13:04:44.863980: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3365734)\u001b[0m 2023-12-05 13:04:45.845796: I external/local_xla/xla/service/service.cc:168] XLA service 0x14a7e42f5b20 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3365734)\u001b[0m 2023-12-05 13:04:45.845838: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3365734)\u001b[0m 2023-12-05 13:04:45.856712: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3365734)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3365734)\u001b[0m I0000 00:00:1701799485.972359 3366116 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3369784)\u001b[0m 2023-12-05 13:05:49.141575: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3369784)\u001b[0m 2023-12-05 13:05:49.181482: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3369784)\u001b[0m 2023-12-05 13:05:49.181504: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3369784)\u001b[0m 2023-12-05 13:05:49.182588: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3369784)\u001b[0m 2023-12-05 13:05:49.188629: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3369784)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3369784)\u001b[0m 2023-12-05 13:05:49.901989: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3369784)\u001b[0m 2023-12-05 13:05:51.225203: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3369784)\u001b[0m 2023-12-05 13:05:52.943868: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3369784)\u001b[0m 2023-12-05 13:05:53.920380: I external/local_xla/xla/service/service.cc:168] XLA service 0x14abdc31e030 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3369784)\u001b[0m 2023-12-05 13:05:53.920424: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3369784)\u001b[0m 2023-12-05 13:05:53.930045: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3369784)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3369784)\u001b[0m I0000 00:00:1701799554.045767 3369904 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3373005)\u001b[0m 2023-12-05 13:06:35.169088: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3373005)\u001b[0m 2023-12-05 13:06:35.208623: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3373005)\u001b[0m 2023-12-05 13:06:35.208652: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3373005)\u001b[0m 2023-12-05 13:06:35.209745: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3373005)\u001b[0m 2023-12-05 13:06:35.215937: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3373005)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3373005)\u001b[0m 2023-12-05 13:06:35.939911: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3373005)\u001b[0m 2023-12-05 13:06:37.266406: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3373005)\u001b[0m 2023-12-05 13:06:38.947507: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3373005)\u001b[0m 2023-12-05 13:06:39.930562: I external/local_xla/xla/service/service.cc:168] XLA service 0x151e51170b70 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3373005)\u001b[0m 2023-12-05 13:06:39.930594: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3373005)\u001b[0m 2023-12-05 13:06:39.936466: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3373005)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3373005)\u001b[0m I0000 00:00:1701799600.062951 3373090 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3375370)\u001b[0m 2023-12-05 13:07:14.196450: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3375370)\u001b[0m 2023-12-05 13:07:14.235970: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3375370)\u001b[0m 2023-12-05 13:07:14.236000: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3375370)\u001b[0m 2023-12-05 13:07:14.237062: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3375370)\u001b[0m 2023-12-05 13:07:14.243084: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3375370)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3375370)\u001b[0m 2023-12-05 13:07:14.960553: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3375370)\u001b[0m 2023-12-05 13:07:16.298276: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3375370)\u001b[0m 2023-12-05 13:07:18.005961: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3375370)\u001b[0m 2023-12-05 13:07:18.991346: I external/local_xla/xla/service/service.cc:168] XLA service 0x149da82f53e0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3375370)\u001b[0m 2023-12-05 13:07:18.991393: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3375370)\u001b[0m 2023-12-05 13:07:19.000374: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3375370)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3375370)\u001b[0m I0000 00:00:1701799639.124511 3375584 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3379430)\u001b[0m 2023-12-05 13:08:27.144723: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3379430)\u001b[0m 2023-12-05 13:08:27.184469: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3379430)\u001b[0m 2023-12-05 13:08:27.184494: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3379430)\u001b[0m 2023-12-05 13:08:27.185568: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3379430)\u001b[0m 2023-12-05 13:08:27.191559: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3379430)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3379430)\u001b[0m 2023-12-05 13:08:27.910046: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3379430)\u001b[0m 2023-12-05 13:08:29.271806: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3379430)\u001b[0m 2023-12-05 13:08:30.985838: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3379430)\u001b[0m 2023-12-05 13:08:32.000109: I external/local_xla/xla/service/service.cc:168] XLA service 0x147b70307dc0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3379430)\u001b[0m 2023-12-05 13:08:32.000156: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3379430)\u001b[0m 2023-12-05 13:08:32.010405: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3379430)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3379430)\u001b[0m I0000 00:00:1701799712.126519 3379514 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3382622)\u001b[0m 2023-12-05 13:09:23.225585: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3382622)\u001b[0m 2023-12-05 13:09:23.265175: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3382622)\u001b[0m 2023-12-05 13:09:23.265207: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3382622)\u001b[0m 2023-12-05 13:09:23.266255: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3382622)\u001b[0m 2023-12-05 13:09:23.272255: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3382622)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3382622)\u001b[0m 2023-12-05 13:09:23.998556: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3382622)\u001b[0m 2023-12-05 13:09:25.340730: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3382622)\u001b[0m 2023-12-05 13:09:27.051603: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3382622)\u001b[0m 2023-12-05 13:09:28.063002: I external/local_xla/xla/service/service.cc:168] XLA service 0x14e72d15f310 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3382622)\u001b[0m 2023-12-05 13:09:28.063036: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3382622)\u001b[0m 2023-12-05 13:09:28.068869: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3382622)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3382622)\u001b[0m I0000 00:00:1701799768.193748 3382708 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3385808)\u001b[0m 2023-12-05 13:10:11.202549: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3385808)\u001b[0m 2023-12-05 13:10:11.242021: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3385808)\u001b[0m 2023-12-05 13:10:11.242050: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3385808)\u001b[0m 2023-12-05 13:10:11.243111: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3385808)\u001b[0m 2023-12-05 13:10:11.249076: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3385808)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3385808)\u001b[0m 2023-12-05 13:10:11.958321: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3385808)\u001b[0m 2023-12-05 13:10:13.288553: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3385808)\u001b[0m 2023-12-05 13:10:15.015389: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3385808)\u001b[0m 2023-12-05 13:10:15.975276: I external/local_xla/xla/service/service.cc:168] XLA service 0x14e5395299f0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3385808)\u001b[0m 2023-12-05 13:10:15.975323: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3385808)\u001b[0m 2023-12-05 13:10:15.983523: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3385808)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3385808)\u001b[0m I0000 00:00:1701799816.098571 3385893 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3389649)\u001b[0m 2023-12-05 13:11:19.238648: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3389649)\u001b[0m 2023-12-05 13:11:19.279053: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3389649)\u001b[0m 2023-12-05 13:11:19.279077: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3389649)\u001b[0m 2023-12-05 13:11:19.280130: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3389649)\u001b[0m 2023-12-05 13:11:19.286111: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3389649)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3389649)\u001b[0m 2023-12-05 13:11:19.988081: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3389649)\u001b[0m 2023-12-05 13:11:21.282438: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3389649)\u001b[0m 2023-12-05 13:11:22.975319: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3389649)\u001b[0m 2023-12-05 13:11:23.908949: I external/local_xla/xla/service/service.cc:168] XLA service 0x14b28c30c000 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3389649)\u001b[0m 2023-12-05 13:11:23.908990: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3389649)\u001b[0m 2023-12-05 13:11:23.919933: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3389649)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3389649)\u001b[0m I0000 00:00:1701799884.030469 3390045 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3392463)\u001b[0m 2023-12-05 13:12:04.234976: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3392463)\u001b[0m 2023-12-05 13:12:04.274120: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3392463)\u001b[0m 2023-12-05 13:12:04.274145: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3392463)\u001b[0m 2023-12-05 13:12:04.275189: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3392463)\u001b[0m 2023-12-05 13:12:04.281064: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3392463)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3392463)\u001b[0m 2023-12-05 13:12:04.978683: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3392463)\u001b[0m 2023-12-05 13:12:06.302956: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3392463)\u001b[0m 2023-12-05 13:12:08.035991: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3392463)\u001b[0m 2023-12-05 13:12:08.999445: I external/local_xla/xla/service/service.cc:168] XLA service 0x14ff9cdaa8c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3392463)\u001b[0m 2023-12-05 13:12:08.999476: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3392463)\u001b[0m 2023-12-05 13:12:09.005627: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3392463)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3392463)\u001b[0m I0000 00:00:1701799929.114510 3392745 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3395433)\u001b[0m 2023-12-05 13:12:38.269313: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3395433)\u001b[0m 2023-12-05 13:12:38.269344: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3395433)\u001b[0m 2023-12-05 13:12:38.270397: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3395433)\u001b[0m 2023-12-05 13:12:38.276419: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3395433)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3395433)\u001b[0m 2023-12-05 13:12:38.229625: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3395433)\u001b[0m 2023-12-05 13:12:39.103382: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3395433)\u001b[0m 2023-12-05 13:12:40.325022: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3395433)\u001b[0m 2023-12-05 13:12:42.152932: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3395433)\u001b[0m 2023-12-05 13:12:43.112452: I external/local_xla/xla/service/service.cc:168] XLA service 0x149099bea830 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3395433)\u001b[0m 2023-12-05 13:12:43.112487: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3395433)\u001b[0m 2023-12-05 13:12:43.120280: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3395433)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3395433)\u001b[0m I0000 00:00:1701799963.234887 3395517 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3398842)\u001b[0m 2023-12-05 13:13:46.347570: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3398842)\u001b[0m 2023-12-05 13:13:46.387225: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3398842)\u001b[0m 2023-12-05 13:13:46.387249: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3398842)\u001b[0m 2023-12-05 13:13:46.388316: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3398842)\u001b[0m 2023-12-05 13:13:46.394274: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3398842)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3398842)\u001b[0m 2023-12-05 13:13:47.109095: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3398842)\u001b[0m 2023-12-05 13:13:48.437592: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3398842)\u001b[0m 2023-12-05 13:13:50.103108: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3398842)\u001b[0m 2023-12-05 13:13:51.064193: I external/local_xla/xla/service/service.cc:168] XLA service 0x1494bc30b8f0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3398842)\u001b[0m 2023-12-05 13:13:51.064219: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3398842)\u001b[0m 2023-12-05 13:13:51.069258: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3398842)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3398842)\u001b[0m I0000 00:00:1701800031.191060 3399130 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3401830)\u001b[0m 2023-12-05 13:14:32.280758: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3401830)\u001b[0m 2023-12-05 13:14:32.280783: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3401830)\u001b[0m 2023-12-05 13:14:32.281837: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3401830)\u001b[0m 2023-12-05 13:14:32.241492: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3401830)\u001b[0m 2023-12-05 13:14:32.287801: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3401830)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3401830)\u001b[0m 2023-12-05 13:14:32.980582: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3401830)\u001b[0m 2023-12-05 13:14:34.276628: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3401830)\u001b[0m 2023-12-05 13:14:35.975008: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3401830)\u001b[0m 2023-12-05 13:14:36.959878: I external/local_xla/xla/service/service.cc:168] XLA service 0x14ffd9d27fc0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3401830)\u001b[0m 2023-12-05 13:14:36.959912: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3401830)\u001b[0m 2023-12-05 13:14:36.965863: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3401830)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3401830)\u001b[0m I0000 00:00:1701800077.082731 3401918 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3405015)\u001b[0m 2023-12-05 13:15:10.286658: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3405015)\u001b[0m 2023-12-05 13:15:10.326162: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3405015)\u001b[0m 2023-12-05 13:15:10.326190: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3405015)\u001b[0m 2023-12-05 13:15:10.327250: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3405015)\u001b[0m 2023-12-05 13:15:10.333255: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3405015)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3405015)\u001b[0m 2023-12-05 13:15:11.038320: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3405015)\u001b[0m 2023-12-05 13:15:12.372497: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3405015)\u001b[0m 2023-12-05 13:15:14.064484: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3405015)\u001b[0m 2023-12-05 13:15:15.011470: I external/local_xla/xla/service/service.cc:168] XLA service 0x14ef8c30c5b0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3405015)\u001b[0m 2023-12-05 13:15:15.011514: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3405015)\u001b[0m 2023-12-05 13:15:15.020486: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3405015)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3405015)\u001b[0m I0000 00:00:1701800115.134691 3405097 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3408501)\u001b[0m 2023-12-05 13:16:23.295404: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3408501)\u001b[0m 2023-12-05 13:16:23.334830: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3408501)\u001b[0m 2023-12-05 13:16:23.334857: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3408501)\u001b[0m 2023-12-05 13:16:23.335892: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3408501)\u001b[0m 2023-12-05 13:16:23.341760: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3408501)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3408501)\u001b[0m 2023-12-05 13:16:24.028907: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3408501)\u001b[0m 2023-12-05 13:16:25.315672: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3408501)\u001b[0m 2023-12-05 13:16:27.020194: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3408501)\u001b[0m 2023-12-05 13:16:28.007497: I external/local_xla/xla/service/service.cc:168] XLA service 0x148e8c6bb630 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3408501)\u001b[0m 2023-12-05 13:16:28.007530: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3408501)\u001b[0m 2023-12-05 13:16:28.015402: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3408501)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3408501)\u001b[0m I0000 00:00:1701800188.132083 3408979 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3412109)\u001b[0m 2023-12-05 13:17:18.325992: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3412109)\u001b[0m 2023-12-05 13:17:18.365425: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3412109)\u001b[0m 2023-12-05 13:17:18.365450: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3412109)\u001b[0m 2023-12-05 13:17:18.366519: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3412109)\u001b[0m 2023-12-05 13:17:18.372515: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3412109)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3412109)\u001b[0m 2023-12-05 13:17:19.091479: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3412109)\u001b[0m 2023-12-05 13:17:20.430256: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3412109)\u001b[0m 2023-12-05 13:17:22.122419: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3412109)\u001b[0m 2023-12-05 13:17:23.118816: I external/local_xla/xla/service/service.cc:168] XLA service 0x14f015d6ea90 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3412109)\u001b[0m 2023-12-05 13:17:23.118847: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3412109)\u001b[0m 2023-12-05 13:17:23.125248: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3412109)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3412109)\u001b[0m I0000 00:00:1701800243.250652 3412614 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3415295)\u001b[0m 2023-12-05 13:18:06.385440: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3415295)\u001b[0m 2023-12-05 13:18:06.385465: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3415295)\u001b[0m 2023-12-05 13:18:06.386509: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3415295)\u001b[0m 2023-12-05 13:18:06.346310: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3415295)\u001b[0m 2023-12-05 13:18:06.392405: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3415295)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3415295)\u001b[0m 2023-12-05 13:18:07.087428: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3415295)\u001b[0m 2023-12-05 13:18:08.389660: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3415295)\u001b[0m 2023-12-05 13:18:10.086610: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3415295)\u001b[0m 2023-12-05 13:18:11.071080: I external/local_xla/xla/service/service.cc:168] XLA service 0x1473b16bbdd0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3415295)\u001b[0m 2023-12-05 13:18:11.071109: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3415295)\u001b[0m 2023-12-05 13:18:11.078325: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3415295)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3415295)\u001b[0m I0000 00:00:1701800291.191741 3415387 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3419728)\u001b[0m 2023-12-05 13:19:15.335621: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3419728)\u001b[0m 2023-12-05 13:19:15.375404: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3419728)\u001b[0m 2023-12-05 13:19:15.375429: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3419728)\u001b[0m 2023-12-05 13:19:15.376501: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3419728)\u001b[0m 2023-12-05 13:19:15.382472: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3419728)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3419728)\u001b[0m 2023-12-05 13:19:16.106746: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3419728)\u001b[0m 2023-12-05 13:19:17.437813: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3419728)\u001b[0m 2023-12-05 13:19:19.157842: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3419728)\u001b[0m 2023-12-05 13:19:20.130072: I external/local_xla/xla/service/service.cc:168] XLA service 0x14cf4dd01090 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3419728)\u001b[0m 2023-12-05 13:19:20.130121: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3419728)\u001b[0m 2023-12-05 13:19:20.140386: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3419728)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3419728)\u001b[0m I0000 00:00:1701800360.254808 3420210 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3422511)\u001b[0m 2023-12-05 13:20:01.397117: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3422511)\u001b[0m 2023-12-05 13:20:01.436455: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3422511)\u001b[0m 2023-12-05 13:20:01.436482: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3422511)\u001b[0m 2023-12-05 13:20:01.437531: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3422511)\u001b[0m 2023-12-05 13:20:01.443515: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3422511)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3422511)\u001b[0m 2023-12-05 13:20:02.137644: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3422511)\u001b[0m 2023-12-05 13:20:03.431709: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3422511)\u001b[0m 2023-12-05 13:20:05.121667: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3422511)\u001b[0m 2023-12-05 13:20:06.069246: I external/local_xla/xla/service/service.cc:168] XLA service 0x14c690d98810 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3422511)\u001b[0m 2023-12-05 13:20:06.069278: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3422511)\u001b[0m 2023-12-05 13:20:06.074677: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3422511)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3422511)\u001b[0m I0000 00:00:1701800406.198644 3423003 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3424434)\u001b[0m 2023-12-05 13:20:35.415078: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3424434)\u001b[0m 2023-12-05 13:20:35.454379: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3424434)\u001b[0m 2023-12-05 13:20:35.454400: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3424434)\u001b[0m 2023-12-05 13:20:35.455432: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3424434)\u001b[0m 2023-12-05 13:20:35.461299: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3424434)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3424434)\u001b[0m 2023-12-05 13:20:36.150304: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3424434)\u001b[0m 2023-12-05 13:20:37.448107: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3424434)\u001b[0m 2023-12-05 13:20:39.149368: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3424434)\u001b[0m 2023-12-05 13:20:40.073396: I external/local_xla/xla/service/service.cc:168] XLA service 0x14991c30b030 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3424434)\u001b[0m 2023-12-05 13:20:40.073438: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3424434)\u001b[0m 2023-12-05 13:20:40.083010: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3424434)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3424434)\u001b[0m I0000 00:00:1701800440.197628 3424753 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3428956)\u001b[0m 2023-12-05 13:21:43.424474: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3428956)\u001b[0m 2023-12-05 13:21:43.463928: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3428956)\u001b[0m 2023-12-05 13:21:43.463953: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3428956)\u001b[0m 2023-12-05 13:21:43.464980: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3428956)\u001b[0m 2023-12-05 13:21:43.470892: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3428956)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3428956)\u001b[0m 2023-12-05 13:21:44.166411: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3428956)\u001b[0m 2023-12-05 13:21:45.469346: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3428956)\u001b[0m 2023-12-05 13:21:47.168768: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3428956)\u001b[0m 2023-12-05 13:21:48.110337: I external/local_xla/xla/service/service.cc:168] XLA service 0x14950dbe8250 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3428956)\u001b[0m 2023-12-05 13:21:48.110380: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3428956)\u001b[0m 2023-12-05 13:21:48.120111: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3428956)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3428956)\u001b[0m I0000 00:00:1701800508.244652 3429454 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3431751)\u001b[0m 2023-12-05 13:22:29.447711: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3431751)\u001b[0m 2023-12-05 13:22:29.488021: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3431751)\u001b[0m 2023-12-05 13:22:29.488065: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3431751)\u001b[0m 2023-12-05 13:22:29.489131: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3431751)\u001b[0m 2023-12-05 13:22:29.495145: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3431751)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3431751)\u001b[0m 2023-12-05 13:22:30.197045: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3431751)\u001b[0m 2023-12-05 13:22:32.382593: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3431751)\u001b[0m 2023-12-05 13:22:34.094695: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3431751)\u001b[0m 2023-12-05 13:22:35.062186: I external/local_xla/xla/service/service.cc:168] XLA service 0x15143d8074b0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3431751)\u001b[0m 2023-12-05 13:22:35.062215: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3431751)\u001b[0m 2023-12-05 13:22:35.067668: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3431751)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3431751)\u001b[0m I0000 00:00:1701800555.191880 3432242 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2023-12-05 13:22:39,258\tWARNING util.py:202 -- The `callbacks.on_trial_result` operation took 0.990 s, which may be a performance bottleneck.\n",
      "2023-12-05 13:22:39,260\tWARNING util.py:202 -- The `process_trial_result` operation took 0.992 s, which may be a performance bottleneck.\n",
      "2023-12-05 13:22:39,260\tWARNING util.py:202 -- Processing trial results took 0.992 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "2023-12-05 13:22:39,262\tWARNING util.py:202 -- The `process_trial_result` operation took 0.994 s, which may be a performance bottleneck.\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3434115)\u001b[0m 2023-12-05 13:23:09.438582: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3434115)\u001b[0m 2023-12-05 13:23:09.477867: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3434115)\u001b[0m 2023-12-05 13:23:09.477893: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3434115)\u001b[0m 2023-12-05 13:23:09.478926: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3434115)\u001b[0m 2023-12-05 13:23:09.484870: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3434115)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3434115)\u001b[0m 2023-12-05 13:23:10.173611: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3434115)\u001b[0m 2023-12-05 13:23:11.475626: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3434115)\u001b[0m 2023-12-05 13:23:13.165577: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3434115)\u001b[0m 2023-12-05 13:23:14.135780: I external/local_xla/xla/service/service.cc:168] XLA service 0x144aa82f5aa0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3434115)\u001b[0m 2023-12-05 13:23:14.135823: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3434115)\u001b[0m 2023-12-05 13:23:14.144650: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3434115)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3434115)\u001b[0m I0000 00:00:1701800594.255590 3434608 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3438957)\u001b[0m 2023-12-05 13:24:22.498551: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3438957)\u001b[0m 2023-12-05 13:24:22.538463: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3438957)\u001b[0m 2023-12-05 13:24:22.538493: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3438957)\u001b[0m 2023-12-05 13:24:22.539560: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3438957)\u001b[0m 2023-12-05 13:24:22.545592: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3438957)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3438957)\u001b[0m 2023-12-05 13:24:23.267168: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3438957)\u001b[0m 2023-12-05 13:24:24.603629: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3438957)\u001b[0m 2023-12-05 13:24:26.293861: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3438957)\u001b[0m 2023-12-05 13:24:27.297742: I external/local_xla/xla/service/service.cc:168] XLA service 0x14c1906d15d0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3438957)\u001b[0m 2023-12-05 13:24:27.297774: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3438957)\u001b[0m 2023-12-05 13:24:27.303898: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3438957)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3438957)\u001b[0m I0000 00:00:1701800667.425287 3439444 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3442557)\u001b[0m 2023-12-05 13:25:17.484101: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3442557)\u001b[0m 2023-12-05 13:25:17.523392: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3442557)\u001b[0m 2023-12-05 13:25:17.523419: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3442557)\u001b[0m 2023-12-05 13:25:17.524447: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3442557)\u001b[0m 2023-12-05 13:25:17.530346: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3442557)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3442557)\u001b[0m 2023-12-05 13:25:18.222413: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3442557)\u001b[0m 2023-12-05 13:25:19.522043: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3442557)\u001b[0m 2023-12-05 13:25:21.257305: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3442557)\u001b[0m 2023-12-05 13:25:22.264943: I external/local_xla/xla/service/service.cc:168] XLA service 0x14c065552090 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3442557)\u001b[0m 2023-12-05 13:25:22.264974: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3442557)\u001b[0m 2023-12-05 13:25:22.270645: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3442557)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3442557)\u001b[0m I0000 00:00:1701800722.385380 3442652 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3445557)\u001b[0m 2023-12-05 13:26:05.498142: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3445557)\u001b[0m 2023-12-05 13:26:05.537493: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3445557)\u001b[0m 2023-12-05 13:26:05.537521: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3445557)\u001b[0m 2023-12-05 13:26:05.538579: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3445557)\u001b[0m 2023-12-05 13:26:05.544598: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3445557)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3445557)\u001b[0m 2023-12-05 13:26:06.250345: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3445557)\u001b[0m 2023-12-05 13:26:07.578912: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3445557)\u001b[0m 2023-12-05 13:26:09.296251: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3445557)\u001b[0m 2023-12-05 13:26:10.242158: I external/local_xla/xla/service/service.cc:168] XLA service 0x14d674308ab0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3445557)\u001b[0m 2023-12-05 13:26:10.242211: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3445557)\u001b[0m 2023-12-05 13:26:10.251690: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3445557)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3445557)\u001b[0m I0000 00:00:1701800770.374689 3445853 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3449007)\u001b[0m 2023-12-05 13:27:13.518542: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3449007)\u001b[0m 2023-12-05 13:27:13.557920: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3449007)\u001b[0m 2023-12-05 13:27:13.557947: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3449007)\u001b[0m 2023-12-05 13:27:13.558996: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3449007)\u001b[0m 2023-12-05 13:27:13.565064: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3449007)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3449007)\u001b[0m 2023-12-05 13:27:14.259116: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3449007)\u001b[0m 2023-12-05 13:27:15.561355: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3449007)\u001b[0m 2023-12-05 13:27:17.223242: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3449007)\u001b[0m 2023-12-05 13:27:18.160517: I external/local_xla/xla/service/service.cc:168] XLA service 0x14b08430bfe0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3449007)\u001b[0m 2023-12-05 13:27:18.160561: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3449007)\u001b[0m 2023-12-05 13:27:18.171012: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3449007)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3449007)\u001b[0m I0000 00:00:1701800838.296071 3449125 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3452202)\u001b[0m 2023-12-05 13:27:58.542715: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3452202)\u001b[0m 2023-12-05 13:27:58.542743: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3452202)\u001b[0m 2023-12-05 13:27:58.543775: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3452202)\u001b[0m 2023-12-05 13:27:58.502804: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3452202)\u001b[0m 2023-12-05 13:27:58.549695: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3452202)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3452202)\u001b[0m 2023-12-05 13:27:59.238896: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3452202)\u001b[0m 2023-12-05 13:28:00.539061: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3452202)\u001b[0m 2023-12-05 13:28:02.258772: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3452202)\u001b[0m 2023-12-05 13:28:03.219841: I external/local_xla/xla/service/service.cc:168] XLA service 0x1498e5d11990 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3452202)\u001b[0m 2023-12-05 13:28:03.219869: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3452202)\u001b[0m 2023-12-05 13:28:03.225799: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3452202)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3452202)\u001b[0m I0000 00:00:1701800883.331265 3452283 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3454557)\u001b[0m 2023-12-05 13:28:32.543700: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3454557)\u001b[0m 2023-12-05 13:28:32.584146: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3454557)\u001b[0m 2023-12-05 13:28:32.584172: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3454557)\u001b[0m 2023-12-05 13:28:32.585202: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3454557)\u001b[0m 2023-12-05 13:28:32.591086: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3454557)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3454557)\u001b[0m 2023-12-05 13:28:33.282837: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3454557)\u001b[0m 2023-12-05 13:28:34.582595: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3454557)\u001b[0m 2023-12-05 13:28:36.279560: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3454557)\u001b[0m 2023-12-05 13:28:37.248788: I external/local_xla/xla/service/service.cc:168] XLA service 0x1462506babd0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3454557)\u001b[0m 2023-12-05 13:28:37.248815: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3454557)\u001b[0m 2023-12-05 13:28:37.255599: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3454557)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3454557)\u001b[0m I0000 00:00:1701800917.378171 3455049 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3458576)\u001b[0m 2023-12-05 13:29:41.666310: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3458576)\u001b[0m 2023-12-05 13:29:41.666342: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3458576)\u001b[0m 2023-12-05 13:29:41.667405: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3458576)\u001b[0m 2023-12-05 13:29:41.673467: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3458576)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3458576)\u001b[0m 2023-12-05 13:29:41.626473: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3458576)\u001b[0m 2023-12-05 13:29:42.405278: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3458576)\u001b[0m 2023-12-05 13:29:43.761656: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3458576)\u001b[0m 2023-12-05 13:29:45.454894: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3458576)\u001b[0m 2023-12-05 13:29:46.428139: I external/local_xla/xla/service/service.cc:168] XLA service 0x14891d5241f0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3458576)\u001b[0m 2023-12-05 13:29:46.428181: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3458576)\u001b[0m 2023-12-05 13:29:46.436710: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3458576)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3458576)\u001b[0m I0000 00:00:1701800986.551684 3458661 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3461765)\u001b[0m 2023-12-05 13:30:27.593710: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3461765)\u001b[0m 2023-12-05 13:30:27.633471: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3461765)\u001b[0m 2023-12-05 13:30:27.633497: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3461765)\u001b[0m 2023-12-05 13:30:27.634540: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3461765)\u001b[0m 2023-12-05 13:30:27.640481: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3461765)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3461765)\u001b[0m 2023-12-05 13:30:28.357639: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3461765)\u001b[0m 2023-12-05 13:30:29.688120: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3461765)\u001b[0m 2023-12-05 13:30:31.365126: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3461765)\u001b[0m 2023-12-05 13:30:32.343591: I external/local_xla/xla/service/service.cc:168] XLA service 0x14cdd115df80 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3461765)\u001b[0m 2023-12-05 13:30:32.343617: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3461765)\u001b[0m 2023-12-05 13:30:32.349674: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3461765)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3461765)\u001b[0m I0000 00:00:1701801032.471434 3461849 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3464417)\u001b[0m 2023-12-05 13:31:06.596080: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3464417)\u001b[0m 2023-12-05 13:31:06.635959: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3464417)\u001b[0m 2023-12-05 13:31:06.635987: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3464417)\u001b[0m 2023-12-05 13:31:06.637074: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3464417)\u001b[0m 2023-12-05 13:31:06.643228: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3464417)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3464417)\u001b[0m 2023-12-05 13:31:07.374978: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3464417)\u001b[0m 2023-12-05 13:31:08.722198: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3464417)\u001b[0m 2023-12-05 13:31:10.403962: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3464417)\u001b[0m 2023-12-05 13:31:11.357166: I external/local_xla/xla/service/service.cc:168] XLA service 0x14f094005310 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3464417)\u001b[0m 2023-12-05 13:31:11.357210: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3464417)\u001b[0m 2023-12-05 13:31:11.366500: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3464417)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3464417)\u001b[0m I0000 00:00:1701801071.490353 3464652 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3468242)\u001b[0m 2023-12-05 13:32:19.647726: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3468242)\u001b[0m 2023-12-05 13:32:19.686917: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3468242)\u001b[0m 2023-12-05 13:32:19.686944: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3468242)\u001b[0m 2023-12-05 13:32:19.687985: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3468242)\u001b[0m 2023-12-05 13:32:19.693899: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3468242)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3468242)\u001b[0m 2023-12-05 13:32:20.393431: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3468242)\u001b[0m 2023-12-05 13:32:21.683266: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3468242)\u001b[0m 2023-12-05 13:32:23.400636: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3468242)\u001b[0m 2023-12-05 13:32:24.373927: I external/local_xla/xla/service/service.cc:168] XLA service 0x14c759cf9b90 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3468242)\u001b[0m 2023-12-05 13:32:24.373968: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3468242)\u001b[0m 2023-12-05 13:32:24.384118: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3468242)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3468242)\u001b[0m I0000 00:00:1701801144.506501 3468339 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3471441)\u001b[0m 2023-12-05 13:33:14.653547: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3471441)\u001b[0m 2023-12-05 13:33:14.693395: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3471441)\u001b[0m 2023-12-05 13:33:14.693422: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3471441)\u001b[0m 2023-12-05 13:33:14.694485: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3471441)\u001b[0m 2023-12-05 13:33:14.700556: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3471441)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3471441)\u001b[0m 2023-12-05 13:33:15.424912: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3471441)\u001b[0m 2023-12-05 13:33:16.789121: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3471441)\u001b[0m 2023-12-05 13:33:18.491115: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3471441)\u001b[0m 2023-12-05 13:33:19.498270: I external/local_xla/xla/service/service.cc:168] XLA service 0x14eda11494b0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3471441)\u001b[0m 2023-12-05 13:33:19.498296: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3471441)\u001b[0m 2023-12-05 13:33:19.504249: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3471441)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3471441)\u001b[0m I0000 00:00:1701801199.619245 3471572 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3474636)\u001b[0m 2023-12-05 13:34:02.712647: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3474636)\u001b[0m 2023-12-05 13:34:02.752347: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3474636)\u001b[0m 2023-12-05 13:34:02.752374: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3474636)\u001b[0m 2023-12-05 13:34:02.753437: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3474636)\u001b[0m 2023-12-05 13:34:02.759477: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3474636)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3474636)\u001b[0m 2023-12-05 13:34:03.475265: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3474636)\u001b[0m 2023-12-05 13:34:04.787717: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3474636)\u001b[0m 2023-12-05 13:34:06.450105: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3474636)\u001b[0m 2023-12-05 13:34:06.790594: I external/local_xla/xla/service/service.cc:168] XLA service 0x14962c6d1000 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3474636)\u001b[0m 2023-12-05 13:34:06.790637: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3474636)\u001b[0m 2023-12-05 13:34:06.799286: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3474636)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3474636)\u001b[0m I0000 00:00:1701801246.922544 3474716 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3478412)\u001b[0m 2023-12-05 13:35:07.682538: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3478412)\u001b[0m 2023-12-05 13:35:07.721766: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3478412)\u001b[0m 2023-12-05 13:35:07.721791: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3478412)\u001b[0m 2023-12-05 13:35:07.722834: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3478412)\u001b[0m 2023-12-05 13:35:07.728743: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3478412)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3478412)\u001b[0m 2023-12-05 13:35:08.431292: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3478412)\u001b[0m 2023-12-05 13:35:09.737097: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3478412)\u001b[0m 2023-12-05 13:35:11.435497: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3478412)\u001b[0m 2023-12-05 13:35:11.777939: I external/local_xla/xla/service/service.cc:168] XLA service 0x143c2c6d13a0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3478412)\u001b[0m 2023-12-05 13:35:11.777977: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3478412)\u001b[0m 2023-12-05 13:35:11.786507: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3478412)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3478412)\u001b[0m I0000 00:00:1701801311.911089 3478553 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3481054)\u001b[0m 2023-12-05 13:35:51.709119: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3481054)\u001b[0m 2023-12-05 13:35:51.748422: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3481054)\u001b[0m 2023-12-05 13:35:51.748446: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3481054)\u001b[0m 2023-12-05 13:35:51.749507: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3481054)\u001b[0m 2023-12-05 13:35:51.755463: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3481054)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3481054)\u001b[0m 2023-12-05 13:35:52.451309: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3481054)\u001b[0m 2023-12-05 13:35:53.764241: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3481054)\u001b[0m 2023-12-05 13:35:55.458646: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3481054)\u001b[0m 2023-12-05 13:35:55.811871: I external/local_xla/xla/service/service.cc:168] XLA service 0x151491149280 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3481054)\u001b[0m 2023-12-05 13:35:55.811893: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3481054)\u001b[0m 2023-12-05 13:35:55.816978: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3481054)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3481054)\u001b[0m I0000 00:00:1701801355.925328 3481345 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3484180)\u001b[0m 2023-12-05 13:36:24.657056: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3484180)\u001b[0m 2023-12-05 13:36:24.696607: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3484180)\u001b[0m 2023-12-05 13:36:24.696629: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3484180)\u001b[0m 2023-12-05 13:36:24.697691: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3484180)\u001b[0m 2023-12-05 13:36:24.703651: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3484180)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3484180)\u001b[0m 2023-12-05 13:36:25.425572: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3484180)\u001b[0m 2023-12-05 13:36:26.734782: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3484180)\u001b[0m 2023-12-05 13:36:28.418115: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3484180)\u001b[0m 2023-12-05 13:36:28.765565: I external/local_xla/xla/service/service.cc:168] XLA service 0x143f586bb4a0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3484180)\u001b[0m 2023-12-05 13:36:28.765596: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3484180)\u001b[0m 2023-12-05 13:36:28.773844: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3484180)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3484180)\u001b[0m I0000 00:00:1701801388.885921 3484301 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3487429)\u001b[0m 2023-12-05 13:37:30.776571: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3487429)\u001b[0m 2023-12-05 13:37:30.816521: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3487429)\u001b[0m 2023-12-05 13:37:30.816549: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3487429)\u001b[0m 2023-12-05 13:37:30.817615: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3487429)\u001b[0m 2023-12-05 13:37:30.823674: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3487429)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3487429)\u001b[0m 2023-12-05 13:37:31.555399: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3487429)\u001b[0m 2023-12-05 13:37:32.881471: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3487429)\u001b[0m 2023-12-05 13:37:34.535492: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3487429)\u001b[0m 2023-12-05 13:37:34.893664: I external/local_xla/xla/service/service.cc:168] XLA service 0x14696dcbe740 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3487429)\u001b[0m 2023-12-05 13:37:34.893693: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3487429)\u001b[0m 2023-12-05 13:37:34.901031: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3487429)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3487429)\u001b[0m I0000 00:00:1701801455.023652 3487513 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3490607)\u001b[0m 2023-12-05 13:38:15.727013: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3490607)\u001b[0m 2023-12-05 13:38:15.727047: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3490607)\u001b[0m 2023-12-05 13:38:15.728089: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3490607)\u001b[0m 2023-12-05 13:38:15.733964: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3490607)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3490607)\u001b[0m 2023-12-05 13:38:15.687764: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3490607)\u001b[0m 2023-12-05 13:38:16.430029: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3490607)\u001b[0m 2023-12-05 13:38:17.758658: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3490607)\u001b[0m 2023-12-05 13:38:19.398275: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3490607)\u001b[0m 2023-12-05 13:38:19.764673: I external/local_xla/xla/service/service.cc:168] XLA service 0x1515dcd981e0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3490607)\u001b[0m 2023-12-05 13:38:19.764695: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3490607)\u001b[0m 2023-12-05 13:38:19.770785: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3490607)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3490607)\u001b[0m I0000 00:00:1701801499.887697 3490688 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3493337)\u001b[0m 2023-12-05 13:38:52.729111: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3493337)\u001b[0m 2023-12-05 13:38:52.768402: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3493337)\u001b[0m 2023-12-05 13:38:52.768426: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3493337)\u001b[0m 2023-12-05 13:38:52.769484: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3493337)\u001b[0m 2023-12-05 13:38:52.775458: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3493337)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3493337)\u001b[0m 2023-12-05 13:38:53.472020: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3493337)\u001b[0m 2023-12-05 13:38:54.834489: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3493337)\u001b[0m 2023-12-05 13:38:56.528318: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3493337)\u001b[0m 2023-12-05 13:38:56.889179: I external/local_xla/xla/service/service.cc:168] XLA service 0x1532746e2640 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3493337)\u001b[0m 2023-12-05 13:38:56.889215: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3493337)\u001b[0m 2023-12-05 13:38:56.897654: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3493337)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3493337)\u001b[0m I0000 00:00:1701801537.025600 3493829 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3496956)\u001b[0m 2023-12-05 13:40:03.732443: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3496956)\u001b[0m 2023-12-05 13:40:03.772272: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3496956)\u001b[0m 2023-12-05 13:40:03.772297: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3496956)\u001b[0m 2023-12-05 13:40:03.773345: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3496956)\u001b[0m 2023-12-05 13:40:03.779290: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3496956)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3496956)\u001b[0m 2023-12-05 13:40:04.475192: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3496956)\u001b[0m 2023-12-05 13:40:05.783081: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3496956)\u001b[0m 2023-12-05 13:40:07.482121: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3496956)\u001b[0m 2023-12-05 13:40:07.848514: I external/local_xla/xla/service/service.cc:168] XLA service 0x148b5830c010 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3496956)\u001b[0m 2023-12-05 13:40:07.848549: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3496956)\u001b[0m 2023-12-05 13:40:07.855916: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3496956)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3496956)\u001b[0m I0000 00:00:1701801607.978461 3497040 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3500157)\u001b[0m 2023-12-05 13:40:57.749253: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3500157)\u001b[0m 2023-12-05 13:40:57.789098: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3500157)\u001b[0m 2023-12-05 13:40:57.789120: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3500157)\u001b[0m 2023-12-05 13:40:57.790198: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3500157)\u001b[0m 2023-12-05 13:40:57.796216: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3500157)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3500157)\u001b[0m 2023-12-05 13:40:58.500069: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3500157)\u001b[0m 2023-12-05 13:40:59.828908: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3500157)\u001b[0m 2023-12-05 13:41:01.543582: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3500157)\u001b[0m 2023-12-05 13:41:01.965611: I external/local_xla/xla/service/service.cc:168] XLA service 0x151c4d7d7b10 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3500157)\u001b[0m 2023-12-05 13:41:01.965635: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3500157)\u001b[0m 2023-12-05 13:41:01.970750: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3500157)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3500157)\u001b[0m I0000 00:00:1701801662.092762 3500446 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3503347)\u001b[0m 2023-12-05 13:41:44.805667: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3503347)\u001b[0m 2023-12-05 13:41:44.845460: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3503347)\u001b[0m 2023-12-05 13:41:44.845488: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3503347)\u001b[0m 2023-12-05 13:41:44.846563: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3503347)\u001b[0m 2023-12-05 13:41:44.852587: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3503347)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3503347)\u001b[0m 2023-12-05 13:41:45.572783: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3503347)\u001b[0m 2023-12-05 13:41:46.917889: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3503347)\u001b[0m 2023-12-05 13:41:48.605399: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3503347)\u001b[0m 2023-12-05 13:41:49.551593: I external/local_xla/xla/service/service.cc:168] XLA service 0x15018dce2250 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3503347)\u001b[0m 2023-12-05 13:41:49.551633: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3503347)\u001b[0m 2023-12-05 13:41:49.560060: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3503347)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3503347)\u001b[0m I0000 00:00:1701801709.686749 3503433 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3507557)\u001b[0m 2023-12-05 13:42:53.881660: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3507557)\u001b[0m 2023-12-05 13:42:53.921070: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3507557)\u001b[0m 2023-12-05 13:42:53.921093: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3507557)\u001b[0m 2023-12-05 13:42:53.922164: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3507557)\u001b[0m 2023-12-05 13:42:53.928131: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3507557)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3507557)\u001b[0m 2023-12-05 13:42:54.659401: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3507557)\u001b[0m 2023-12-05 13:42:55.999754: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3507557)\u001b[0m 2023-12-05 13:42:57.719344: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3507557)\u001b[0m 2023-12-05 13:42:58.684162: I external/local_xla/xla/service/service.cc:168] XLA service 0x14a3c1d3b750 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3507557)\u001b[0m 2023-12-05 13:42:58.684209: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3507557)\u001b[0m 2023-12-05 13:42:58.694513: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3507557)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3507557)\u001b[0m I0000 00:00:1701801778.809151 3507700 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3509977)\u001b[0m 2023-12-05 13:43:38.832232: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3509977)\u001b[0m 2023-12-05 13:43:38.872048: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3509977)\u001b[0m 2023-12-05 13:43:38.872070: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3509977)\u001b[0m 2023-12-05 13:43:38.873125: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3509977)\u001b[0m 2023-12-05 13:43:38.879161: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3509977)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3509977)\u001b[0m 2023-12-05 13:43:39.600121: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3509977)\u001b[0m 2023-12-05 13:43:40.922696: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3509977)\u001b[0m 2023-12-05 13:43:42.609445: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3509977)\u001b[0m 2023-12-05 13:43:43.572791: I external/local_xla/xla/service/service.cc:168] XLA service 0x147d6cd83510 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3509977)\u001b[0m 2023-12-05 13:43:43.572819: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3509977)\u001b[0m 2023-12-05 13:43:43.578950: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3509977)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3509977)\u001b[0m I0000 00:00:1701801823.700597 3510470 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3512952)\u001b[0m 2023-12-05 13:44:12.820112: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3512952)\u001b[0m 2023-12-05 13:44:12.859093: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3512952)\u001b[0m 2023-12-05 13:44:12.859116: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3512952)\u001b[0m 2023-12-05 13:44:12.860162: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3512952)\u001b[0m 2023-12-05 13:44:12.866057: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3512952)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3512952)\u001b[0m 2023-12-05 13:44:13.584164: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3512952)\u001b[0m 2023-12-05 13:44:14.894224: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3512952)\u001b[0m 2023-12-05 13:44:16.554259: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3512952)\u001b[0m 2023-12-05 13:44:17.499959: I external/local_xla/xla/service/service.cc:168] XLA service 0x1521e5cf2500 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3512952)\u001b[0m 2023-12-05 13:44:17.500003: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3512952)\u001b[0m 2023-12-05 13:44:17.509854: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3512952)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3512952)\u001b[0m I0000 00:00:1701801857.625087 3513035 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3516405)\u001b[0m 2023-12-05 13:45:20.848411: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3516405)\u001b[0m 2023-12-05 13:45:20.888312: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3516405)\u001b[0m 2023-12-05 13:45:20.888336: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3516405)\u001b[0m 2023-12-05 13:45:20.889409: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3516405)\u001b[0m 2023-12-05 13:45:20.895454: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3516405)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3516405)\u001b[0m 2023-12-05 13:45:21.601088: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3516405)\u001b[0m 2023-12-05 13:45:22.911770: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3516405)\u001b[0m 2023-12-05 13:45:24.627945: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3516405)\u001b[0m 2023-12-05 13:45:25.614904: I external/local_xla/xla/service/service.cc:168] XLA service 0x14956dbaf210 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3516405)\u001b[0m 2023-12-05 13:45:25.614950: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3516405)\u001b[0m 2023-12-05 13:45:25.624335: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3516405)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3516405)\u001b[0m I0000 00:00:1701801925.741976 3516856 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3519370)\u001b[0m 2023-12-05 13:46:06.848902: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3519370)\u001b[0m 2023-12-05 13:46:06.888912: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3519370)\u001b[0m 2023-12-05 13:46:06.888937: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3519370)\u001b[0m 2023-12-05 13:46:06.890023: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3519370)\u001b[0m 2023-12-05 13:46:06.896082: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3519370)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3519370)\u001b[0m 2023-12-05 13:46:07.616314: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3519370)\u001b[0m 2023-12-05 13:46:08.932826: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3519370)\u001b[0m 2023-12-05 13:46:10.641775: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3519370)\u001b[0m 2023-12-05 13:46:11.615208: I external/local_xla/xla/service/service.cc:168] XLA service 0x151470d84700 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3519370)\u001b[0m 2023-12-05 13:46:11.615236: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3519370)\u001b[0m 2023-12-05 13:46:11.621692: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3519370)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3519370)\u001b[0m I0000 00:00:1701801971.736709 3519658 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3522575)\u001b[0m 2023-12-05 13:46:44.832732: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3522575)\u001b[0m 2023-12-05 13:46:44.871874: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3522575)\u001b[0m 2023-12-05 13:46:44.871899: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3522575)\u001b[0m 2023-12-05 13:46:44.872940: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3522575)\u001b[0m 2023-12-05 13:46:44.878871: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3522575)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3522575)\u001b[0m 2023-12-05 13:46:45.571997: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3522575)\u001b[0m 2023-12-05 13:46:46.858586: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3522575)\u001b[0m 2023-12-05 13:46:48.572527: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3522575)\u001b[0m 2023-12-05 13:46:49.533470: I external/local_xla/xla/service/service.cc:168] XLA service 0x14eeddd186f0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3522575)\u001b[0m 2023-12-05 13:46:49.533519: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3522575)\u001b[0m 2023-12-05 13:46:49.543945: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3522575)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3522575)\u001b[0m I0000 00:00:1701802009.652043 3522658 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3526400)\u001b[0m 2023-12-05 13:47:56.859772: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3526400)\u001b[0m 2023-12-05 13:47:56.899186: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3526400)\u001b[0m 2023-12-05 13:47:56.899212: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3526400)\u001b[0m 2023-12-05 13:47:56.900261: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3526400)\u001b[0m 2023-12-05 13:47:56.906172: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3526400)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3526400)\u001b[0m 2023-12-05 13:47:57.632927: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3526400)\u001b[0m 2023-12-05 13:47:58.974518: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3526400)\u001b[0m 2023-12-05 13:48:00.694195: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3526400)\u001b[0m 2023-12-05 13:48:01.690451: I external/local_xla/xla/service/service.cc:168] XLA service 0x14c064300f20 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3526400)\u001b[0m 2023-12-05 13:48:01.690497: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3526400)\u001b[0m 2023-12-05 13:48:01.701123: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3526400)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3526400)\u001b[0m I0000 00:00:1701802081.828279 3526889 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3530012)\u001b[0m 2023-12-05 13:48:52.938386: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3530012)\u001b[0m 2023-12-05 13:48:52.938415: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3530012)\u001b[0m 2023-12-05 13:48:52.939475: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3530012)\u001b[0m 2023-12-05 13:48:52.945520: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3530012)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3530012)\u001b[0m 2023-12-05 13:48:52.897776: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3530012)\u001b[0m 2023-12-05 13:48:53.638797: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3530012)\u001b[0m 2023-12-05 13:48:54.967667: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3530012)\u001b[0m 2023-12-05 13:48:56.699111: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3530012)\u001b[0m 2023-12-05 13:48:57.724822: I external/local_xla/xla/service/service.cc:168] XLA service 0x143cf0d98b40 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3530012)\u001b[0m 2023-12-05 13:48:57.724855: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3530012)\u001b[0m 2023-12-05 13:48:57.731305: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3530012)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3530012)\u001b[0m I0000 00:00:1701802137.856490 3530443 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3532829)\u001b[0m 2023-12-05 13:49:40.887818: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3532829)\u001b[0m 2023-12-05 13:49:40.926873: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3532829)\u001b[0m 2023-12-05 13:49:40.926897: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3532829)\u001b[0m 2023-12-05 13:49:40.927953: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3532829)\u001b[0m 2023-12-05 13:49:40.933881: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3532829)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3532829)\u001b[0m 2023-12-05 13:49:41.635784: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3532829)\u001b[0m 2023-12-05 13:49:42.958280: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3532829)\u001b[0m 2023-12-05 13:49:44.664861: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3532829)\u001b[0m 2023-12-05 13:49:45.639501: I external/local_xla/xla/service/service.cc:168] XLA service 0x14e2f031e370 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3532829)\u001b[0m 2023-12-05 13:49:45.639546: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3532829)\u001b[0m 2023-12-05 13:49:45.649118: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3532829)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3532829)\u001b[0m I0000 00:00:1701802185.774833 3533274 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3537643)\u001b[0m 2023-12-05 13:50:49.927414: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3537643)\u001b[0m 2023-12-05 13:50:49.967252: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3537643)\u001b[0m 2023-12-05 13:50:49.967280: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3537643)\u001b[0m 2023-12-05 13:50:49.968346: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3537643)\u001b[0m 2023-12-05 13:50:49.974425: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3537643)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3537643)\u001b[0m 2023-12-05 13:50:50.693374: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3537643)\u001b[0m 2023-12-05 13:50:52.002237: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3537643)\u001b[0m 2023-12-05 13:50:53.734573: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3537643)\u001b[0m 2023-12-05 13:50:54.698835: I external/local_xla/xla/service/service.cc:168] XLA service 0x14b3bd6a7470 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3537643)\u001b[0m 2023-12-05 13:50:54.698882: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3537643)\u001b[0m 2023-12-05 13:50:54.705588: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3537643)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3537643)\u001b[0m I0000 00:00:1701802254.827836 3537774 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3540467)\u001b[0m 2023-12-05 13:51:36.013886: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3540467)\u001b[0m 2023-12-05 13:51:36.053707: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3540467)\u001b[0m 2023-12-05 13:51:36.053737: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3540467)\u001b[0m 2023-12-05 13:51:36.054784: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3540467)\u001b[0m 2023-12-05 13:51:36.060777: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3540467)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3540467)\u001b[0m 2023-12-05 13:51:36.774966: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3540467)\u001b[0m 2023-12-05 13:51:38.116366: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3540467)\u001b[0m 2023-12-05 13:51:39.835972: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3540467)\u001b[0m 2023-12-05 13:51:40.797109: I external/local_xla/xla/service/service.cc:168] XLA service 0x14e580d959c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3540467)\u001b[0m 2023-12-05 13:51:40.797140: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3540467)\u001b[0m 2023-12-05 13:51:40.803482: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3540467)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3540467)\u001b[0m I0000 00:00:1701802300.919514 3540850 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3542387)\u001b[0m 2023-12-05 13:52:09.900276: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3542387)\u001b[0m 2023-12-05 13:52:09.939760: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3542387)\u001b[0m 2023-12-05 13:52:09.939791: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3542387)\u001b[0m 2023-12-05 13:52:09.940840: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3542387)\u001b[0m 2023-12-05 13:52:09.946842: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3542387)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3542387)\u001b[0m 2023-12-05 13:52:10.671897: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3542387)\u001b[0m 2023-12-05 13:52:12.009272: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3542387)\u001b[0m 2023-12-05 13:52:13.731468: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3542387)\u001b[0m 2023-12-05 13:52:14.699917: I external/local_xla/xla/service/service.cc:168] XLA service 0x14751030b880 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3542387)\u001b[0m 2023-12-05 13:52:14.699964: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3542387)\u001b[0m 2023-12-05 13:52:14.710159: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3542387)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3542387)\u001b[0m I0000 00:00:1701802334.825753 3542518 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3546733)\u001b[0m 2023-12-05 13:53:17.954355: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3546733)\u001b[0m 2023-12-05 13:53:17.993865: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3546733)\u001b[0m 2023-12-05 13:53:17.993894: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3546733)\u001b[0m 2023-12-05 13:53:17.994938: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3546733)\u001b[0m 2023-12-05 13:53:18.000975: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3546733)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3546733)\u001b[0m 2023-12-05 13:53:18.732381: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3546733)\u001b[0m 2023-12-05 13:53:20.085987: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3546733)\u001b[0m 2023-12-05 13:53:21.775905: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3546733)\u001b[0m 2023-12-05 13:53:22.743394: I external/local_xla/xla/service/service.cc:168] XLA service 0x1499f430bc60 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3546733)\u001b[0m 2023-12-05 13:53:22.743438: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3546733)\u001b[0m 2023-12-05 13:53:22.752457: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3546733)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3546733)\u001b[0m I0000 00:00:1701802402.868905 3546973 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3549664)\u001b[0m 2023-12-05 13:54:04.028452: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3549664)\u001b[0m 2023-12-05 13:54:04.028479: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3549664)\u001b[0m 2023-12-05 13:54:04.029510: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3549664)\u001b[0m 2023-12-05 13:54:04.035422: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3549664)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3549664)\u001b[0m 2023-12-05 13:54:03.989550: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3549664)\u001b[0m 2023-12-05 13:54:04.735246: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3549664)\u001b[0m 2023-12-05 13:54:06.059398: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3549664)\u001b[0m 2023-12-05 13:54:07.765525: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3549664)\u001b[0m 2023-12-05 13:54:08.737174: I external/local_xla/xla/service/service.cc:168] XLA service 0x15195115de70 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3549664)\u001b[0m 2023-12-05 13:54:08.737203: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3549664)\u001b[0m 2023-12-05 13:54:08.742395: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3549664)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3549664)\u001b[0m I0000 00:00:1701802448.855382 3549757 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3551586)\u001b[0m 2023-12-05 13:54:41.928608: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3551586)\u001b[0m 2023-12-05 13:54:41.967796: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3551586)\u001b[0m 2023-12-05 13:54:41.967823: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3551586)\u001b[0m 2023-12-05 13:54:41.968858: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3551586)\u001b[0m 2023-12-05 13:54:41.974749: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3551586)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3551586)\u001b[0m 2023-12-05 13:54:42.665315: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3551586)\u001b[0m 2023-12-05 13:54:43.966603: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3551586)\u001b[0m 2023-12-05 13:54:45.679139: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3551586)\u001b[0m 2023-12-05 13:54:46.651752: I external/local_xla/xla/service/service.cc:168] XLA service 0x1536ec30b300 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3551586)\u001b[0m 2023-12-05 13:54:46.651797: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3551586)\u001b[0m 2023-12-05 13:54:46.662129: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3551586)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3551586)\u001b[0m I0000 00:00:1701802486.777467 3552081 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3556692)\u001b[0m 2023-12-05 13:55:54.958953: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3556692)\u001b[0m 2023-12-05 13:55:54.958977: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3556692)\u001b[0m 2023-12-05 13:55:54.960034: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3556692)\u001b[0m 2023-12-05 13:55:54.965945: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3556692)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3556692)\u001b[0m 2023-12-05 13:55:54.919279: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3556692)\u001b[0m 2023-12-05 13:55:55.651205: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3556692)\u001b[0m 2023-12-05 13:55:56.954556: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3556692)\u001b[0m 2023-12-05 13:55:58.654127: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3556692)\u001b[0m 2023-12-05 13:55:59.631589: I external/local_xla/xla/service/service.cc:168] XLA service 0x146249c102e0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3556692)\u001b[0m 2023-12-05 13:55:59.631622: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3556692)\u001b[0m 2023-12-05 13:55:59.639859: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3556692)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3556692)\u001b[0m I0000 00:00:1701802559.752586 3556990 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3560116)\u001b[0m 2023-12-05 13:56:49.959697: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3560116)\u001b[0m 2023-12-05 13:56:49.999413: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3560116)\u001b[0m 2023-12-05 13:56:49.999443: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3560116)\u001b[0m 2023-12-05 13:56:50.000522: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3560116)\u001b[0m 2023-12-05 13:56:50.006529: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3560116)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3560116)\u001b[0m 2023-12-05 13:56:50.709276: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3560116)\u001b[0m 2023-12-05 13:56:52.030448: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3560116)\u001b[0m 2023-12-05 13:56:53.758864: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3560116)\u001b[0m 2023-12-05 13:56:54.781935: I external/local_xla/xla/service/service.cc:168] XLA service 0x14f639b943a0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3560116)\u001b[0m 2023-12-05 13:56:54.781967: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3560116)\u001b[0m 2023-12-05 13:56:54.787300: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3560116)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3560116)\u001b[0m I0000 00:00:1701802614.907877 3560217 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3563251)\u001b[0m 2023-12-05 13:57:38.031468: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3563251)\u001b[0m 2023-12-05 13:57:38.031494: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3563251)\u001b[0m 2023-12-05 13:57:38.032539: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3563251)\u001b[0m 2023-12-05 13:57:38.038453: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3563251)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3563251)\u001b[0m 2023-12-05 13:57:37.991936: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3563251)\u001b[0m 2023-12-05 13:57:38.753550: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3563251)\u001b[0m 2023-12-05 13:57:40.097112: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3563251)\u001b[0m 2023-12-05 13:57:41.804072: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3563251)\u001b[0m 2023-12-05 13:57:42.767457: I external/local_xla/xla/service/service.cc:168] XLA service 0x15004c6d0f00 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3563251)\u001b[0m 2023-12-05 13:57:42.767495: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3563251)\u001b[0m 2023-12-05 13:57:42.776023: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3563251)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3563251)\u001b[0m I0000 00:00:1701802662.891739 3563388 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3566510)\u001b[0m 2023-12-05 13:58:46.013257: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3566510)\u001b[0m 2023-12-05 13:58:46.052592: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3566510)\u001b[0m 2023-12-05 13:58:46.052618: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3566510)\u001b[0m 2023-12-05 13:58:46.053653: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3566510)\u001b[0m 2023-12-05 13:58:46.059605: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3566510)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3566510)\u001b[0m 2023-12-05 13:58:46.757077: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3566510)\u001b[0m 2023-12-05 13:58:48.052383: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3566510)\u001b[0m 2023-12-05 13:58:49.711657: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3566510)\u001b[0m 2023-12-05 13:58:50.660127: I external/local_xla/xla/service/service.cc:168] XLA service 0x14d5f430bc20 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3566510)\u001b[0m 2023-12-05 13:58:50.660170: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3566510)\u001b[0m 2023-12-05 13:58:50.668983: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3566510)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3566510)\u001b[0m I0000 00:00:1701802730.792472 3566591 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3569706)\u001b[0m 2023-12-05 13:59:30.999388: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3569706)\u001b[0m 2023-12-05 13:59:31.038393: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3569706)\u001b[0m 2023-12-05 13:59:31.038417: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3569706)\u001b[0m 2023-12-05 13:59:31.039450: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3569706)\u001b[0m 2023-12-05 13:59:31.045311: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3569706)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3569706)\u001b[0m 2023-12-05 13:59:31.734945: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3569706)\u001b[0m 2023-12-05 13:59:33.044404: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3569706)\u001b[0m 2023-12-05 13:59:34.760054: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3569706)\u001b[0m 2023-12-05 13:59:35.720212: I external/local_xla/xla/service/service.cc:168] XLA service 0x150ccd15d8d0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3569706)\u001b[0m 2023-12-05 13:59:35.720235: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3569706)\u001b[0m 2023-12-05 13:59:35.725219: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3569706)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3569706)\u001b[0m I0000 00:00:1701802775.834738 3569789 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3572069)\u001b[0m 2023-12-05 14:00:05.044901: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3572069)\u001b[0m 2023-12-05 14:00:05.083860: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3572069)\u001b[0m 2023-12-05 14:00:05.083885: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3572069)\u001b[0m 2023-12-05 14:00:05.084926: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3572069)\u001b[0m 2023-12-05 14:00:05.090786: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3572069)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3572069)\u001b[0m 2023-12-05 14:00:05.782572: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3572069)\u001b[0m 2023-12-05 14:00:07.099514: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3572069)\u001b[0m 2023-12-05 14:00:08.804709: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3572069)\u001b[0m 2023-12-05 14:00:09.747541: I external/local_xla/xla/service/service.cc:168] XLA service 0x144c29ccc6e0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3572069)\u001b[0m 2023-12-05 14:00:09.747570: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3572069)\u001b[0m 2023-12-05 14:00:09.752646: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3572069)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3572069)\u001b[0m I0000 00:00:1701802809.878999 3572560 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3576127)\u001b[0m 2023-12-05 14:01:14.094943: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3576127)\u001b[0m 2023-12-05 14:01:14.094970: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3576127)\u001b[0m 2023-12-05 14:01:14.096014: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3576127)\u001b[0m 2023-12-05 14:01:14.102021: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3576127)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3576127)\u001b[0m 2023-12-05 14:01:14.055609: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3576127)\u001b[0m 2023-12-05 14:01:14.805020: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3576127)\u001b[0m 2023-12-05 14:01:16.136473: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3576127)\u001b[0m 2023-12-05 14:01:17.813618: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3576127)\u001b[0m 2023-12-05 14:01:18.780372: I external/local_xla/xla/service/service.cc:168] XLA service 0x14cd306d2900 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3576127)\u001b[0m 2023-12-05 14:01:18.780404: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3576127)\u001b[0m 2023-12-05 14:01:18.788843: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3576127)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3576127)\u001b[0m I0000 00:00:1701802878.910723 3576212 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3579349)\u001b[0m 2023-12-05 14:02:00.021309: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3579349)\u001b[0m 2023-12-05 14:02:00.060718: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3579349)\u001b[0m 2023-12-05 14:02:00.060744: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3579349)\u001b[0m 2023-12-05 14:02:00.061800: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3579349)\u001b[0m 2023-12-05 14:02:00.067739: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3579349)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3579349)\u001b[0m 2023-12-05 14:02:00.761541: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3579349)\u001b[0m 2023-12-05 14:02:02.070230: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3579349)\u001b[0m 2023-12-05 14:02:03.754343: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3579349)\u001b[0m 2023-12-05 14:02:04.728270: I external/local_xla/xla/service/service.cc:168] XLA service 0x14b39980c110 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3579349)\u001b[0m 2023-12-05 14:02:04.728299: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3579349)\u001b[0m 2023-12-05 14:02:04.733385: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3579349)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3579349)\u001b[0m I0000 00:00:1701802924.847978 3579434 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3581854)\u001b[0m 2023-12-05 14:02:40.121152: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3581854)\u001b[0m 2023-12-05 14:02:40.160459: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3581854)\u001b[0m 2023-12-05 14:02:40.160485: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3581854)\u001b[0m 2023-12-05 14:02:40.161531: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3581854)\u001b[0m 2023-12-05 14:02:40.167688: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3581854)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3581854)\u001b[0m 2023-12-05 14:02:40.885373: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3581854)\u001b[0m 2023-12-05 14:02:42.189947: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3581854)\u001b[0m 2023-12-05 14:02:43.871378: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3581854)\u001b[0m 2023-12-05 14:02:44.829512: I external/local_xla/xla/service/service.cc:168] XLA service 0x152a09c442b0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3581854)\u001b[0m 2023-12-05 14:02:44.829563: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3581854)\u001b[0m 2023-12-05 14:02:44.837686: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3581854)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3581854)\u001b[0m I0000 00:00:1701802964.950831 3582203 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3585729)\u001b[0m 2023-12-05 14:03:52.134488: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3585729)\u001b[0m 2023-12-05 14:03:52.173816: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3585729)\u001b[0m 2023-12-05 14:03:52.173839: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3585729)\u001b[0m 2023-12-05 14:03:52.174898: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3585729)\u001b[0m 2023-12-05 14:03:52.180890: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3585729)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3585729)\u001b[0m 2023-12-05 14:03:52.878331: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3585729)\u001b[0m 2023-12-05 14:03:54.182754: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3585729)\u001b[0m 2023-12-05 14:03:55.877870: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3585729)\u001b[0m 2023-12-05 14:03:56.848088: I external/local_xla/xla/service/service.cc:168] XLA service 0x14945c3081d0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3585729)\u001b[0m 2023-12-05 14:03:56.848133: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3585729)\u001b[0m 2023-12-05 14:03:56.858319: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3585729)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3585729)\u001b[0m I0000 00:00:1701803036.974284 3585830 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3588926)\u001b[0m 2023-12-05 14:04:48.109199: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3588926)\u001b[0m 2023-12-05 14:04:48.109227: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3588926)\u001b[0m 2023-12-05 14:04:48.110338: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3588926)\u001b[0m 2023-12-05 14:04:48.116447: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3588926)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3588926)\u001b[0m 2023-12-05 14:04:48.069329: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3588926)\u001b[0m 2023-12-05 14:04:48.820833: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3588926)\u001b[0m 2023-12-05 14:04:50.134048: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3588926)\u001b[0m 2023-12-05 14:04:51.825693: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3588926)\u001b[0m 2023-12-05 14:04:52.854487: I external/local_xla/xla/service/service.cc:168] XLA service 0x153941147e60 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3588926)\u001b[0m 2023-12-05 14:04:52.854514: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3588926)\u001b[0m 2023-12-05 14:04:52.860267: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3588926)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3588926)\u001b[0m I0000 00:00:1701803092.981961 3589043 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3592125)\u001b[0m 2023-12-05 14:05:36.074922: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3592125)\u001b[0m 2023-12-05 14:05:36.114543: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3592125)\u001b[0m 2023-12-05 14:05:36.114569: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3592125)\u001b[0m 2023-12-05 14:05:36.115632: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3592125)\u001b[0m 2023-12-05 14:05:36.121652: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3592125)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3592125)\u001b[0m 2023-12-05 14:05:36.841727: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3592125)\u001b[0m 2023-12-05 14:05:38.161943: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3592125)\u001b[0m 2023-12-05 14:05:39.860123: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3592125)\u001b[0m 2023-12-05 14:05:40.792694: I external/local_xla/xla/service/service.cc:168] XLA service 0x14f3cdcc7ca0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3592125)\u001b[0m 2023-12-05 14:05:40.792739: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3592125)\u001b[0m 2023-12-05 14:05:40.804120: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3592125)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3592125)\u001b[0m I0000 00:00:1701803140.926132 3592203 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3596027)\u001b[0m 2023-12-05 14:06:44.068696: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3596027)\u001b[0m 2023-12-05 14:06:44.107939: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3596027)\u001b[0m 2023-12-05 14:06:44.107962: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3596027)\u001b[0m 2023-12-05 14:06:44.109008: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3596027)\u001b[0m 2023-12-05 14:06:44.114980: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3596027)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3596027)\u001b[0m 2023-12-05 14:06:44.810454: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3596027)\u001b[0m 2023-12-05 14:06:46.112656: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3596027)\u001b[0m 2023-12-05 14:06:47.832118: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3596027)\u001b[0m 2023-12-05 14:06:48.789407: I external/local_xla/xla/service/service.cc:168] XLA service 0x14676830c5e0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3596027)\u001b[0m 2023-12-05 14:06:48.789451: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3596027)\u001b[0m 2023-12-05 14:06:48.798431: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3596027)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3596027)\u001b[0m I0000 00:00:1701803208.923155 3596520 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3598815)\u001b[0m 2023-12-05 14:07:29.075568: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3598815)\u001b[0m 2023-12-05 14:07:29.115139: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3598815)\u001b[0m 2023-12-05 14:07:29.115164: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3598815)\u001b[0m 2023-12-05 14:07:29.116220: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3598815)\u001b[0m 2023-12-05 14:07:29.122241: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3598815)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3598815)\u001b[0m 2023-12-05 14:07:29.838229: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3598815)\u001b[0m 2023-12-05 14:07:31.159679: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3598815)\u001b[0m 2023-12-05 14:07:32.876210: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3598815)\u001b[0m 2023-12-05 14:07:33.865145: I external/local_xla/xla/service/service.cc:168] XLA service 0x14eead148fd0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3598815)\u001b[0m 2023-12-05 14:07:33.865169: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3598815)\u001b[0m 2023-12-05 14:07:33.870823: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3598815)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3598815)\u001b[0m I0000 00:00:1701803253.992912 3599304 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3601755)\u001b[0m 2023-12-05 14:08:03.109127: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3601755)\u001b[0m 2023-12-05 14:08:03.148583: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3601755)\u001b[0m 2023-12-05 14:08:03.148613: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3601755)\u001b[0m 2023-12-05 14:08:03.149649: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3601755)\u001b[0m 2023-12-05 14:08:03.155523: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3601755)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3601755)\u001b[0m 2023-12-05 14:08:03.845413: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3601755)\u001b[0m 2023-12-05 14:08:05.133502: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3601755)\u001b[0m 2023-12-05 14:08:06.830117: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3601755)\u001b[0m 2023-12-05 14:08:07.780666: I external/local_xla/xla/service/service.cc:168] XLA service 0x1518bc307680 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3601755)\u001b[0m 2023-12-05 14:08:07.780706: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3601755)\u001b[0m 2023-12-05 14:08:07.791679: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3601755)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3601755)\u001b[0m I0000 00:00:1701803287.917906 3601841 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3605213)\u001b[0m 2023-12-05 14:09:11.076270: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3605213)\u001b[0m 2023-12-05 14:09:11.116058: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3605213)\u001b[0m 2023-12-05 14:09:11.116085: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3605213)\u001b[0m 2023-12-05 14:09:11.117187: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3605213)\u001b[0m 2023-12-05 14:09:11.123207: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3605213)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3605213)\u001b[0m 2023-12-05 14:09:11.825208: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3605213)\u001b[0m 2023-12-05 14:09:13.112757: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3605213)\u001b[0m 2023-12-05 14:09:14.802301: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3605213)\u001b[0m 2023-12-05 14:09:15.775782: I external/local_xla/xla/service/service.cc:168] XLA service 0x148439d296a0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3605213)\u001b[0m 2023-12-05 14:09:15.775834: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3605213)\u001b[0m 2023-12-05 14:09:15.786692: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3605213)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3605213)\u001b[0m I0000 00:00:1701803355.902006 3605709 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3608204)\u001b[0m 2023-12-05 14:09:57.113541: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3608204)\u001b[0m 2023-12-05 14:09:57.153230: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3608204)\u001b[0m 2023-12-05 14:09:57.153256: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3608204)\u001b[0m 2023-12-05 14:09:57.154308: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3608204)\u001b[0m 2023-12-05 14:09:57.160206: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3608204)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3608204)\u001b[0m 2023-12-05 14:09:57.853584: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3608204)\u001b[0m 2023-12-05 14:09:59.181812: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3608204)\u001b[0m 2023-12-05 14:10:00.905980: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3608204)\u001b[0m 2023-12-05 14:10:01.894785: I external/local_xla/xla/service/service.cc:168] XLA service 0x14b12915f180 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3608204)\u001b[0m 2023-12-05 14:10:01.894812: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3608204)\u001b[0m 2023-12-05 14:10:01.899903: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3608204)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3608204)\u001b[0m I0000 00:00:1701803402.013093 3608495 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3611361)\u001b[0m 2023-12-05 14:10:35.134801: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3611361)\u001b[0m 2023-12-05 14:10:35.174169: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3611361)\u001b[0m 2023-12-05 14:10:35.174196: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3611361)\u001b[0m 2023-12-05 14:10:35.175257: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3611361)\u001b[0m 2023-12-05 14:10:35.181288: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3611361)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3611361)\u001b[0m 2023-12-05 14:10:35.892826: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3611361)\u001b[0m 2023-12-05 14:10:37.219765: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3611361)\u001b[0m 2023-12-05 14:10:38.911964: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3611361)\u001b[0m 2023-12-05 14:10:39.856086: I external/local_xla/xla/service/service.cc:168] XLA service 0x152f386e2280 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3611361)\u001b[0m 2023-12-05 14:10:39.856116: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3611361)\u001b[0m 2023-12-05 14:10:39.864368: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3611361)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3611361)\u001b[0m I0000 00:00:1701803439.986935 3611447 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3615064)\u001b[0m 2023-12-05 14:11:47.116173: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3615064)\u001b[0m 2023-12-05 14:11:47.155350: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3615064)\u001b[0m 2023-12-05 14:11:47.155379: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3615064)\u001b[0m 2023-12-05 14:11:47.156413: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3615064)\u001b[0m 2023-12-05 14:11:47.162408: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3615064)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3615064)\u001b[0m 2023-12-05 14:11:47.889095: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3615064)\u001b[0m 2023-12-05 14:11:49.192639: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3615064)\u001b[0m 2023-12-05 14:11:50.878638: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3615064)\u001b[0m 2023-12-05 14:11:51.870360: I external/local_xla/xla/service/service.cc:168] XLA service 0x14ded9520280 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3615064)\u001b[0m 2023-12-05 14:11:51.870403: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3615064)\u001b[0m 2023-12-05 14:11:51.877115: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3615064)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3615064)\u001b[0m I0000 00:00:1701803511.999080 3615353 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3618655)\u001b[0m 2023-12-05 14:12:43.099519: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3618655)\u001b[0m 2023-12-05 14:12:43.138815: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3618655)\u001b[0m 2023-12-05 14:12:43.138838: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3618655)\u001b[0m 2023-12-05 14:12:43.139899: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3618655)\u001b[0m 2023-12-05 14:12:43.145835: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3618655)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3618655)\u001b[0m 2023-12-05 14:12:43.842129: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3618655)\u001b[0m 2023-12-05 14:12:45.141861: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3618655)\u001b[0m 2023-12-05 14:12:46.834781: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3618655)\u001b[0m 2023-12-05 14:12:47.851176: I external/local_xla/xla/service/service.cc:168] XLA service 0x14b819d8ad20 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3618655)\u001b[0m 2023-12-05 14:12:47.851213: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3618655)\u001b[0m 2023-12-05 14:12:47.856426: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3618655)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3618655)\u001b[0m I0000 00:00:1701803567.979182 3618953 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2023-12-05 14:13:29,085\tINFO tune.py:1047 -- Total run time: 7111.00 seconds (7110.95 seconds for the tuning loop).\n"
     ]
    }
   ],
   "source": [
    "# Grid Search\n",
    "start_time = time()\n",
    "\n",
    "grid_analysis = tune.run(\n",
    "    train_mnist,\n",
    "    name=\"exp\",\n",
    "    metric=\"mean_accuracy\",\n",
    "    mode=\"max\",\n",
    "    stop={\"mean_accuracy\": 0.99},\n",
    "    resources_per_trial={\"gpu\": 1},\n",
    "    config={\n",
    "        \"conv_filters\": tune.grid_search([64, 128, 256]),\n",
    "        \"lr\": tune.grid_search([0.001, 0.01, 0.1]),\n",
    "        \"batch_size\": tune.grid_search([64, 128, 256]),\n",
    "        \"dropout\": tune.grid_search([0.0, 0.25, 0.5, 0.75, 0.9]),\n",
    "    }\n",
    ")\n",
    "\n",
    "end_time = time()\n",
    "grid_time = end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial config: {'conv_filters': 64, 'lr': 0.001, 'batch_size': 256, 'dropout': 0.25}\n",
      "Best trial final validation accuracy: 0.9894000291824341\n",
      "Time taken for Grid Search: 7111.168742179871 seconds\n"
     ]
    }
   ],
   "source": [
    "best_trial = grid_analysis.get_best_trial(\"mean_accuracy\", \"max\", \"last\")\n",
    "best_config = best_trial.config\n",
    "\n",
    "print(\"Best trial config: {}\".format(best_config))\n",
    "print(\"Best trial final validation accuracy: {}\".format(\n",
    "    best_trial.last_result[\"mean_accuracy\"]))\n",
    "print(\"Time taken for Grid Search: {} seconds\".format(grid_time))\n",
    "# Naming error; takes too long to run but fixed the error in the code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayesian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_mnist_bayes(config):\n",
    "    # Convert continuous parameters back to categorical\n",
    "    #conv_filters_map = {0: 64, 1: 128, 2: 256}\n",
    "    batch_size_map = {0: 64, 1: 128, 2: 256}\n",
    "\n",
    "    config[\"conv_filters\"] = int(round(config[\"conv_filters\"]))\n",
    "    config[\"batch_size\"] = batch_size_map[int(round(config[\"batch_size\"]))]\n",
    "\n",
    "    # Load MNIST data\n",
    "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "    x_train, x_test = x_train.reshape(-1, 28, 28, 1) / 255.0, x_test.reshape(-1, 28, 28, 1) / 255.0\n",
    "\n",
    "    # Define the model\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Conv2D(filters=config[\"conv_filters\"], kernel_size=(3, 3), activation=\"relu\", input_shape=(28, 28, 1)),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "        tf.keras.layers.Dropout(config[\"dropout\"]),\n",
    "        tf.keras.layers.Dense(10, activation=\"softmax\")  # Assuming 10 classes for MNIST\n",
    "    ])\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=config[\"lr\"]),\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(\n",
    "        x_train,\n",
    "        y_train,\n",
    "        batch_size=config[\"batch_size\"],\n",
    "        epochs=12,  # or any other number of epochs you wish to use\n",
    "        verbose=1,\n",
    "        validation_data=(x_test, y_test)\n",
    "    )\n",
    "\n",
    "    # Evaluate the model\n",
    "    i, accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
    "    session.report({\"mean_accuracy\": accuracy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-05 09:44:19,935\tINFO tune.py:586 -- [output] This uses the legacy output and progress reporter, as Jupyter notebooks are not supported by the new engine, yet. For more information, please see https://github.com/ray-project/ray/issues/36949\n",
      "2023-12-05 09:44:19,952\tWARNING bayesopt_search.py:431 -- BayesOpt does not support specific sampling methods. The LogUniform sampler will be dropped.\n",
      "2023-12-05 09:44:19,954\tWARNING callback.py:137 -- The TensorboardX logger cannot be instantiated because either TensorboardX or one of it's dependencies is not installed. Please make sure you have the latest version of TensorboardX installed: `pip install -U tensorboardx`\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2023-12-05 09:51:25</td></tr>\n",
       "<tr><td>Running for: </td><td>00:07:05.54        </td></tr>\n",
       "<tr><td>Memory:      </td><td>40.6/377.3 GiB     </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using FIFO scheduling algorithm.<br>Logical resource usage: 0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name          </th><th>status    </th><th>loc                </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_filters</th><th style=\"text-align: right;\">  dropout</th><th style=\"text-align: right;\">       lr</th><th style=\"text-align: right;\">   acc</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_mnist_a19e9cc9</td><td>TERMINATED</td><td>10.32.35.81:2617307</td><td style=\"text-align: right;\">    0.74908 </td><td style=\"text-align: right;\">      246.537 </td><td style=\"text-align: right;\">0.731994 </td><td style=\"text-align: right;\">0.0602672</td><td style=\"text-align: right;\">0.1135</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         56.3798</td></tr>\n",
       "<tr><td>train_mnist_580f069e</td><td>TERMINATED</td><td>10.32.35.81:2621766</td><td style=\"text-align: right;\">    0.312037</td><td style=\"text-align: right;\">       93.9509</td><td style=\"text-align: right;\">0.0580836</td><td style=\"text-align: right;\">0.0867514</td><td style=\"text-align: right;\">0.1135</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         54.36  </td></tr>\n",
       "<tr><td>train_mnist_27ad4a92</td><td>TERMINATED</td><td>10.32.35.81:2626033</td><td style=\"text-align: right;\">    1.20223 </td><td style=\"text-align: right;\">      199.95  </td><td style=\"text-align: right;\">0.0205845</td><td style=\"text-align: right;\">0.0970211</td><td style=\"text-align: right;\">0.101 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         36.624 </td></tr>\n",
       "<tr><td>train_mnist_36566aaa</td><td>TERMINATED</td><td>10.32.35.81:2628692</td><td style=\"text-align: right;\">    1.66489 </td><td style=\"text-align: right;\">      104.769 </td><td style=\"text-align: right;\">0.181825 </td><td style=\"text-align: right;\">0.019157 </td><td style=\"text-align: right;\">0.9587</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         21.6515</td></tr>\n",
       "<tr><td>train_mnist_3d3d47c2</td><td>TERMINATED</td><td>10.32.35.81:2630824</td><td style=\"text-align: right;\">    0.608484</td><td style=\"text-align: right;\">      164.753 </td><td style=\"text-align: right;\">0.431945 </td><td style=\"text-align: right;\">0.0298317</td><td style=\"text-align: right;\">0.9727</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         34.1948</td></tr>\n",
       "<tr><td>train_mnist_0f0fb4fc</td><td>TERMINATED</td><td>10.32.35.81:2634070</td><td style=\"text-align: right;\">    1.22371 </td><td style=\"text-align: right;\">       90.7828</td><td style=\"text-align: right;\">0.292145 </td><td style=\"text-align: right;\">0.0372698</td><td style=\"text-align: right;\">0.9589</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         30.6681</td></tr>\n",
       "<tr><td>train_mnist_f53e8a34</td><td>TERMINATED</td><td>10.32.35.81:2636148</td><td style=\"text-align: right;\">    0.91214 </td><td style=\"text-align: right;\">      214.754 </td><td style=\"text-align: right;\">0.199674 </td><td style=\"text-align: right;\">0.0519092</td><td style=\"text-align: right;\">0.9516</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         38.052 </td></tr>\n",
       "<tr><td>train_mnist_050b7b5d</td><td>TERMINATED</td><td>10.32.35.81:2638393</td><td style=\"text-align: right;\">    1.18483 </td><td style=\"text-align: right;\">       72.9185</td><td style=\"text-align: right;\">0.607545 </td><td style=\"text-align: right;\">0.0178819</td><td style=\"text-align: right;\">0.9649</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         30.3309</td></tr>\n",
       "<tr><td>train_mnist_b010433f</td><td>TERMINATED</td><td>10.32.35.81:2641581</td><td style=\"text-align: right;\">    0.130103</td><td style=\"text-align: right;\">      246.186 </td><td style=\"text-align: right;\">0.965632 </td><td style=\"text-align: right;\">0.0810313</td><td style=\"text-align: right;\">0.1032</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         58.6808</td></tr>\n",
       "<tr><td>train_mnist_460491b1</td><td>TERMINATED</td><td>10.32.35.81:2645324</td><td style=\"text-align: right;\">    0.609228</td><td style=\"text-align: right;\">       82.753 </td><td style=\"text-align: right;\">0.684233 </td><td style=\"text-align: right;\">0.0445751</td><td style=\"text-align: right;\">0.1135</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         30.4812</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=2617307)\u001b[0m 2023-12-05 09:44:21.577392: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=2617307)\u001b[0m 2023-12-05 09:44:21.617503: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=2617307)\u001b[0m 2023-12-05 09:44:21.617530: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=2617307)\u001b[0m 2023-12-05 09:44:21.618606: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=2617307)\u001b[0m 2023-12-05 09:44:21.624624: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=2617307)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=2617307)\u001b[0m 2023-12-05 09:44:22.326234: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=2617307)\u001b[0m 2023-12-05 09:44:24.193022: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_mnist pid=2617307)\u001b[0m Epoch 1/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_mnist pid=2617307)\u001b[0m 2023-12-05 09:44:27.622406: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=2617307)\u001b[0m 2023-12-05 09:44:38.600964: I external/local_xla/xla/service/service.cc:168] XLA service 0x14d3902f69f0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=2617307)\u001b[0m 2023-12-05 09:44:38.601007: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=2617307)\u001b[0m 2023-12-05 09:44:38.610090: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=2617307)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=2617307)\u001b[0m I0000 00:00:1701787478.845065 2617902 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  9/469 [..............................] - ETA: 3s - loss: 44.1109 - accuracy: 0.0972    \n",
      " 27/469 [>.............................] - ETA: 2s - loss: 16.2429 - accuracy: 0.1062\n",
      " 45/469 [=>............................] - ETA: 2s - loss: 10.6681 - accuracy: 0.1043\n",
      " 63/469 [===>..........................] - ETA: 2s - loss: 8.2774 - accuracy: 0.1063\n",
      " 81/469 [====>.........................] - ETA: 2s - loss: 6.9504 - accuracy: 0.1068\n",
      "109/469 [=====>........................] - ETA: 2s - loss: 5.7573 - accuracy: 0.1059\n",
      "127/469 [=======>......................] - ETA: 2s - loss: 5.2681 - accuracy: 0.1045\n",
      "146/469 [========>.....................] - ETA: 1s - loss: 4.8823 - accuracy: 0.1046\n",
      "164/469 [=========>....................] - ETA: 1s - loss: 4.5993 - accuracy: 0.1051\n",
      "182/469 [==========>...................] - ETA: 1s - loss: 4.3723 - accuracy: 0.1058\n",
      "200/469 [===========>..................] - ETA: 1s - loss: 4.1862 - accuracy: 0.1063\n",
      "219/469 [=============>................] - ETA: 1s - loss: 4.0230 - accuracy: 0.1059\n",
      "237/469 [==============>...............] - ETA: 1s - loss: 3.8922 - accuracy: 0.1064\n",
      "246/469 [==============>...............] - ETA: 1s - loss: 3.8344 - accuracy: 0.1059\n",
      "264/469 [===============>..............] - ETA: 1s - loss: 3.7300 - accuracy: 0.1061\n",
      "282/469 [=================>............] - ETA: 1s - loss: 3.6391 - accuracy: 0.1055\n",
      "299/469 [==================>...........] - ETA: 0s - loss: 3.5633 - accuracy: 0.1047\n",
      "317/469 [===================>..........] - ETA: 0s - loss: 3.4919 - accuracy: 0.1040\n",
      "335/469 [====================>.........] - ETA: 0s - loss: 3.4281 - accuracy: 0.1044\n",
      "353/469 [=====================>........] - ETA: 0s - loss: 3.3707 - accuracy: 0.1046\n",
      "371/469 [======================>.......] - ETA: 0s - loss: 3.3190 - accuracy: 0.1044\n",
      "380/469 [=======================>......] - ETA: 0s - loss: 3.2951 - accuracy: 0.1040\n",
      "398/469 [========================>.....] - ETA: 0s - loss: 3.2502 - accuracy: 0.1042\n",
      "416/469 [=========================>....] - ETA: 0s - loss: 3.2093 - accuracy: 0.1042\n",
      "434/469 [==========================>...] - ETA: 0s - loss: 3.1717 - accuracy: 0.1044\n",
      "452/469 [===========================>..] - ETA: 0s - loss: 3.1371 - accuracy: 0.1053\n",
      "461/469 [============================>.] - ETA: 0s - loss: 3.1209 - accuracy: 0.1057\n",
      "469/469 [==============================] - ETA: 0s - loss: 3.1074 - accuracy: 0.1059\n",
      "469/469 [==============================] - 21s 8ms/step - loss: 3.1074 - accuracy: 0.1059 - val_loss: 2.3034 - val_accuracy: 0.1135\n",
      "\u001b[36m(train_mnist pid=2617307)\u001b[0m Epoch 2/12\n",
      "  1/469 [..............................] - ETA: 3s - loss: 2.3082 - accuracy: 0.0703\n",
      " 19/469 [>.............................] - ETA: 2s - loss: 2.3056 - accuracy: 0.1040\n",
      " 38/469 [=>............................] - ETA: 2s - loss: 2.3076 - accuracy: 0.1026\n",
      " 47/469 [==>...........................] - ETA: 2s - loss: 2.3073 - accuracy: 0.1016\n",
      " 65/469 [===>..........................] - ETA: 2s - loss: 2.3065 - accuracy: 0.1025\n",
      " 83/469 [====>.........................] - ETA: 2s - loss: 2.3067 - accuracy: 0.1038\n",
      "101/469 [=====>........................] - ETA: 2s - loss: 2.3058 - accuracy: 0.1058\n",
      "118/469 [======>.......................] - ETA: 2s - loss: 2.3058 - accuracy: 0.1061\n",
      "136/469 [=======>......................] - ETA: 1s - loss: 2.3064 - accuracy: 0.1070\n",
      "154/469 [========>.....................] - ETA: 1s - loss: 2.3066 - accuracy: 0.1067\n",
      "172/469 [==========>...................] - ETA: 1s - loss: 2.3063 - accuracy: 0.1065\n",
      "190/469 [===========>..................] - ETA: 1s - loss: 2.3062 - accuracy: 0.1075\n",
      "199/469 [===========>..................] - ETA: 1s - loss: 2.3060 - accuracy: 0.1069\n",
      "217/469 [============>.................] - ETA: 1s - loss: 2.3059 - accuracy: 0.1065\n",
      "235/469 [==============>...............] - ETA: 1s - loss: 2.3057 - accuracy: 0.1067\n",
      "253/469 [===============>..............] - ETA: 1s - loss: 2.3056 - accuracy: 0.1069\n",
      "271/469 [================>.............] - ETA: 1s - loss: 2.3055 - accuracy: 0.1067\n",
      "290/469 [=================>............] - ETA: 1s - loss: 2.3055 - accuracy: 0.1067\n",
      "309/469 [==================>...........] - ETA: 0s - loss: 2.3057 - accuracy: 0.1064\n",
      "327/469 [===================>..........] - ETA: 0s - loss: 2.3058 - accuracy: 0.1065\n",
      "346/469 [=====================>........] - ETA: 0s - loss: 2.3058 - accuracy: 0.1061\n",
      "364/469 [======================>.......] - ETA: 0s - loss: 2.3057 - accuracy: 0.1068\n",
      "383/469 [=======================>......] - ETA: 0s - loss: 2.3056 - accuracy: 0.1070\n",
      "392/469 [========================>.....] - ETA: 0s - loss: 2.3056 - accuracy: 0.1070\n",
      "411/469 [=========================>....] - ETA: 0s - loss: 2.3056 - accuracy: 0.1072\n",
      "429/469 [==========================>...] - ETA: 0s - loss: 2.3056 - accuracy: 0.1075\n",
      "447/469 [===========================>..] - ETA: 0s - loss: 2.3055 - accuracy: 0.1074\n",
      "465/469 [============================>.] - ETA: 0s - loss: 2.3054 - accuracy: 0.1074\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3054 - accuracy: 0.1076 - val_loss: 2.3043 - val_accuracy: 0.1135\n",
      "\u001b[36m(train_mnist pid=2617307)\u001b[0m Epoch 3/12\n",
      " 19/469 [>.............................] - ETA: 2s - loss: 2.3116 - accuracy: 0.0995\n",
      " 37/469 [=>............................] - ETA: 2s - loss: 2.3102 - accuracy: 0.1003\n",
      " 56/469 [==>...........................] - ETA: 2s - loss: 2.3096 - accuracy: 0.1000\n",
      " 76/469 [===>..........................] - ETA: 2s - loss: 2.3082 - accuracy: 0.1050\n",
      " 95/469 [=====>........................] - ETA: 2s - loss: 2.3072 - accuracy: 0.1075\n",
      "113/469 [======>.......................] - ETA: 2s - loss: 2.3071 - accuracy: 0.1072\n",
      "131/469 [=======>......................] - ETA: 1s - loss: 2.3066 - accuracy: 0.1062\n",
      "158/469 [=========>....................] - ETA: 1s - loss: 2.3063 - accuracy: 0.1070\n",
      "175/469 [==========>...................] - ETA: 1s - loss: 2.3062 - accuracy: 0.1072\n",
      "193/469 [===========>..................] - ETA: 1s - loss: 2.3061 - accuracy: 0.1076\n",
      "211/469 [============>.................] - ETA: 1s - loss: 2.3061 - accuracy: 0.1070\n",
      "229/469 [=============>................] - ETA: 1s - loss: 2.3059 - accuracy: 0.1065\n",
      "247/469 [==============>...............] - ETA: 1s - loss: 2.3058 - accuracy: 0.1061\n",
      "265/469 [===============>..............] - ETA: 1s - loss: 2.3057 - accuracy: 0.1066\n",
      "283/469 [=================>............] - ETA: 1s - loss: 2.3057 - accuracy: 0.1066\n",
      "292/469 [=================>............] - ETA: 1s - loss: 2.3059 - accuracy: 0.1063\n",
      "312/469 [==================>...........] - ETA: 0s - loss: 2.3057 - accuracy: 0.1068\n",
      "331/469 [====================>.........] - ETA: 0s - loss: 2.3058 - accuracy: 0.1066\n",
      "349/469 [=====================>........] - ETA: 0s - loss: 2.3058 - accuracy: 0.1067\n",
      "368/469 [======================>.......] - ETA: 0s - loss: 2.3058 - accuracy: 0.1067\n",
      "386/469 [=======================>......] - ETA: 0s - loss: 2.3057 - accuracy: 0.1064\n",
      "404/469 [========================>.....] - ETA: 0s - loss: 2.3057 - accuracy: 0.1062\n",
      "422/469 [=========================>....] - ETA: 0s - loss: 2.3055 - accuracy: 0.1071\n",
      "431/469 [==========================>...] - ETA: 0s - loss: 2.3055 - accuracy: 0.1073\n",
      "448/469 [===========================>..] - ETA: 0s - loss: 2.3055 - accuracy: 0.1072\n",
      "466/469 [============================>.] - ETA: 0s - loss: 2.3054 - accuracy: 0.1070\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3054 - accuracy: 0.1071 - val_loss: 2.3050 - val_accuracy: 0.1135\n",
      "\u001b[36m(train_mnist pid=2617307)\u001b[0m Epoch 4/12\n",
      " 11/469 [..............................] - ETA: 2s - loss: 2.3091 - accuracy: 0.1001\n",
      " 29/469 [>.............................] - ETA: 2s - loss: 2.3069 - accuracy: 0.1032\n",
      " 47/469 [==>...........................] - ETA: 2s - loss: 2.3049 - accuracy: 0.1092\n",
      " 56/469 [==>...........................] - ETA: 2s - loss: 2.3059 - accuracy: 0.1083\n",
      " 74/469 [===>..........................] - ETA: 2s - loss: 2.3059 - accuracy: 0.1101\n",
      " 92/469 [====>.........................] - ETA: 2s - loss: 2.3058 - accuracy: 0.1095\n",
      "110/469 [======>.......................] - ETA: 2s - loss: 2.3058 - accuracy: 0.1085\n",
      "128/469 [=======>......................] - ETA: 1s - loss: 2.3059 - accuracy: 0.1075\n",
      "146/469 [========>.....................] - ETA: 1s - loss: 2.3056 - accuracy: 0.1070\n",
      "164/469 [=========>....................] - ETA: 1s - loss: 2.3056 - accuracy: 0.1073\n",
      "182/469 [==========>...................] - ETA: 1s - loss: 2.3055 - accuracy: 0.1070\n",
      "199/469 [===========>..................] - ETA: 1s - loss: 2.3055 - accuracy: 0.1073\n",
      "216/469 [============>.................] - ETA: 1s - loss: 2.3055 - accuracy: 0.1075\n",
      "225/469 [=============>................] - ETA: 1s - loss: 2.3056 - accuracy: 0.1069\n",
      "243/469 [==============>...............] - ETA: 1s - loss: 2.3053 - accuracy: 0.1067\n",
      "260/469 [===============>..............] - ETA: 1s - loss: 2.3054 - accuracy: 0.1063\n",
      "278/469 [================>.............] - ETA: 1s - loss: 2.3053 - accuracy: 0.1062\n",
      "296/469 [=================>............] - ETA: 1s - loss: 2.3051 - accuracy: 0.1065\n",
      "314/469 [===================>..........] - ETA: 0s - loss: 2.3054 - accuracy: 0.1063\n",
      "332/469 [====================>.........] - ETA: 0s - loss: 2.3055 - accuracy: 0.1055\n",
      "341/469 [====================>.........] - ETA: 0s - loss: 2.3053 - accuracy: 0.1058\n",
      "360/469 [======================>.......] - ETA: 0s - loss: 2.3053 - accuracy: 0.1064\n",
      "378/469 [=======================>......] - ETA: 0s - loss: 2.3053 - accuracy: 0.1068\n",
      "396/469 [========================>.....] - ETA: 0s - loss: 2.3053 - accuracy: 0.1065\n",
      "415/469 [=========================>....] - ETA: 0s - loss: 2.3052 - accuracy: 0.1058\n",
      "435/469 [==========================>...] - ETA: 0s - loss: 2.3052 - accuracy: 0.1055\n",
      "453/469 [===========================>..] - ETA: 0s - loss: 2.3052 - accuracy: 0.1055\n",
      "462/469 [============================>.] - ETA: 0s - loss: 2.3052 - accuracy: 0.1058\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3052 - accuracy: 0.1059 - val_loss: 2.3076 - val_accuracy: 0.1135\n",
      "\u001b[36m(train_mnist pid=2617307)\u001b[0m Epoch 5/12\n",
      "  1/469 [..............................] - ETA: 2s - loss: 2.3260 - accuracy: 0.1328\n",
      " 10/469 [..............................] - ETA: 2s - loss: 2.3083 - accuracy: 0.1133\n",
      " 28/469 [>.............................] - ETA: 2s - loss: 2.3060 - accuracy: 0.1046\n",
      " 46/469 [=>............................] - ETA: 2s - loss: 2.3049 - accuracy: 0.1044\n",
      " 64/469 [===>..........................] - ETA: 2s - loss: 2.3056 - accuracy: 0.1013\n",
      " 81/469 [====>.........................] - ETA: 2s - loss: 2.3054 - accuracy: 0.1029\n",
      "100/469 [=====>........................] - ETA: 2s - loss: 2.3054 - accuracy: 0.1042\n",
      "119/469 [======>.......................] - ETA: 2s - loss: 2.3057 - accuracy: 0.1047\n",
      "137/469 [=======>......................] - ETA: 1s - loss: 2.3059 - accuracy: 0.1038\n",
      "155/469 [========>.....................] - ETA: 1s - loss: 2.3057 - accuracy: 0.1044\n",
      "173/469 [==========>...................] - ETA: 1s - loss: 2.3056 - accuracy: 0.1054\n",
      "182/469 [==========>...................] - ETA: 1s - loss: 2.3057 - accuracy: 0.1056\n",
      "200/469 [===========>..................] - ETA: 1s - loss: 2.3057 - accuracy: 0.1050\n",
      "218/469 [============>.................] - ETA: 1s - loss: 2.3056 - accuracy: 0.1058\n",
      "236/469 [==============>...............] - ETA: 1s - loss: 2.3055 - accuracy: 0.1061\n",
      "254/469 [===============>..............] - ETA: 1s - loss: 2.3057 - accuracy: 0.1056\n",
      "272/469 [================>.............] - ETA: 1s - loss: 2.3058 - accuracy: 0.1050\n",
      "290/469 [=================>............] - ETA: 1s - loss: 2.3057 - accuracy: 0.1054\n",
      "308/469 [==================>...........] - ETA: 0s - loss: 2.3059 - accuracy: 0.1049\n",
      "335/469 [====================>.........] - ETA: 0s - loss: 2.3058 - accuracy: 0.1053\n",
      "353/469 [=====================>........] - ETA: 0s - loss: 2.3059 - accuracy: 0.1048\n",
      "372/469 [======================>.......] - ETA: 0s - loss: 2.3059 - accuracy: 0.1048\n",
      "391/469 [========================>.....] - ETA: 0s - loss: 2.3056 - accuracy: 0.1054\n",
      "408/469 [=========================>....] - ETA: 0s - loss: 2.3057 - accuracy: 0.1050\n",
      "426/469 [==========================>...] - ETA: 0s - loss: 2.3057 - accuracy: 0.1044\n",
      "444/469 [===========================>..] - ETA: 0s - loss: 2.3057 - accuracy: 0.1048\n",
      "462/469 [============================>.] - ETA: 0s - loss: 2.3056 - accuracy: 0.1052\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3056 - accuracy: 0.1051 - val_loss: 2.3058 - val_accuracy: 0.1032\n",
      "\u001b[36m(train_mnist pid=2617307)\u001b[0m Epoch 6/12\n",
      " 10/469 [..............................] - ETA: 2s - loss: 2.3043 - accuracy: 0.1039\n",
      " 28/469 [>.............................] - ETA: 2s - loss: 2.3030 - accuracy: 0.1186\n",
      " 46/469 [=>............................] - ETA: 2s - loss: 2.3040 - accuracy: 0.1131\n",
      " 73/469 [===>..........................] - ETA: 2s - loss: 2.3045 - accuracy: 0.1106\n",
      " 91/469 [====>.........................] - ETA: 2s - loss: 2.3050 - accuracy: 0.1077\n",
      "109/469 [=====>........................] - ETA: 2s - loss: 2.3056 - accuracy: 0.1060\n",
      "127/469 [=======>......................] - ETA: 1s - loss: 2.3051 - accuracy: 0.1079\n",
      "146/469 [========>.....................] - ETA: 1s - loss: 2.3051 - accuracy: 0.1057\n",
      "164/469 [=========>....................] - ETA: 1s - loss: 2.3050 - accuracy: 0.1065\n",
      "182/469 [==========>...................] - ETA: 1s - loss: 2.3048 - accuracy: 0.1073\n",
      "200/469 [===========>..................] - ETA: 1s - loss: 2.3049 - accuracy: 0.1066\n",
      "218/469 [============>.................] - ETA: 1s - loss: 2.3049 - accuracy: 0.1058\n",
      "236/469 [==============>...............] - ETA: 1s - loss: 2.3045 - accuracy: 0.1063\n",
      "244/469 [==============>...............] - ETA: 1s - loss: 2.3044 - accuracy: 0.1071\n",
      "263/469 [===============>..............] - ETA: 1s - loss: 2.3044 - accuracy: 0.1075\n",
      "282/469 [=================>............] - ETA: 1s - loss: 2.3047 - accuracy: 0.1067\n",
      "300/469 [==================>...........] - ETA: 0s - loss: 2.3046 - accuracy: 0.1070\n",
      "318/469 [===================>..........] - ETA: 0s - loss: 2.3047 - accuracy: 0.1069\n",
      "336/469 [====================>.........] - ETA: 0s - loss: 2.3048 - accuracy: 0.1064\n",
      "354/469 [=====================>........] - ETA: 0s - loss: 2.3047 - accuracy: 0.1063\n",
      "372/469 [======================>.......] - ETA: 0s - loss: 2.3047 - accuracy: 0.1066\n",
      "390/469 [=======================>......] - ETA: 0s - loss: 2.3046 - accuracy: 0.1069\n",
      "409/469 [=========================>....] - ETA: 0s - loss: 2.3045 - accuracy: 0.1074\n",
      "418/469 [=========================>....] - ETA: 0s - loss: 2.3046 - accuracy: 0.1073\n",
      "427/469 [==========================>...] - ETA: 0s - loss: 2.3046 - accuracy: 0.1073\n",
      "437/469 [==========================>...] - ETA: 0s - loss: 2.3046 - accuracy: 0.1071\n",
      "455/469 [============================>.] - ETA: 0s - loss: 2.3045 - accuracy: 0.1073\n",
      "464/469 [============================>.] - ETA: 0s - loss: 2.3046 - accuracy: 0.1074\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3046 - accuracy: 0.1074 - val_loss: 2.3058 - val_accuracy: 0.1009\n",
      "\u001b[36m(train_mnist pid=2617307)\u001b[0m Epoch 7/12\n",
      "  1/469 [..............................] - ETA: 3s - loss: 2.3203 - accuracy: 0.0625\n",
      " 19/469 [>.............................] - ETA: 2s - loss: 2.3027 - accuracy: 0.0970\n",
      " 37/469 [=>............................] - ETA: 2s - loss: 2.3049 - accuracy: 0.0984\n",
      " 55/469 [==>...........................] - ETA: 2s - loss: 2.3039 - accuracy: 0.1048\n",
      " 73/469 [===>..........................] - ETA: 2s - loss: 2.3042 - accuracy: 0.1058\n",
      " 91/469 [====>.........................] - ETA: 2s - loss: 2.3044 - accuracy: 0.1054\n",
      "110/469 [======>.......................] - ETA: 2s - loss: 2.3045 - accuracy: 0.1067\n",
      "119/469 [======>.......................] - ETA: 2s - loss: 2.3045 - accuracy: 0.1070\n",
      "137/469 [=======>......................] - ETA: 1s - loss: 2.3040 - accuracy: 0.1073\n",
      "156/469 [========>.....................] - ETA: 1s - loss: 2.3046 - accuracy: 0.1065\n",
      "175/469 [==========>...................] - ETA: 1s - loss: 2.3046 - accuracy: 0.1066\n",
      "193/469 [===========>..................] - ETA: 1s - loss: 2.3046 - accuracy: 0.1063\n",
      "211/469 [============>.................] - ETA: 1s - loss: 2.3045 - accuracy: 0.1062\n",
      "229/469 [=============>................] - ETA: 1s - loss: 2.3048 - accuracy: 0.1063\n",
      "247/469 [==============>...............] - ETA: 1s - loss: 2.3050 - accuracy: 0.1059\n",
      "266/469 [================>.............] - ETA: 1s - loss: 2.3049 - accuracy: 0.1061\n",
      "275/469 [================>.............] - ETA: 1s - loss: 2.3049 - accuracy: 0.1058\n",
      "293/469 [=================>............] - ETA: 1s - loss: 2.3049 - accuracy: 0.1052\n",
      "311/469 [==================>...........] - ETA: 0s - loss: 2.3049 - accuracy: 0.1045\n",
      "329/469 [====================>.........] - ETA: 0s - loss: 2.3048 - accuracy: 0.1051\n",
      "347/469 [=====================>........] - ETA: 0s - loss: 2.3048 - accuracy: 0.1051\n",
      "365/469 [======================>.......] - ETA: 0s - loss: 2.3048 - accuracy: 0.1049\n",
      "383/469 [=======================>......] - ETA: 0s - loss: 2.3048 - accuracy: 0.1053\n",
      "401/469 [========================>.....] - ETA: 0s - loss: 2.3047 - accuracy: 0.1060\n",
      "410/469 [=========================>....] - ETA: 0s - loss: 2.3047 - accuracy: 0.1062\n",
      "428/469 [==========================>...] - ETA: 0s - loss: 2.3047 - accuracy: 0.1059\n",
      "446/469 [===========================>..] - ETA: 0s - loss: 2.3049 - accuracy: 0.1056\n",
      "465/469 [============================>.] - ETA: 0s - loss: 2.3049 - accuracy: 0.1050\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3049 - accuracy: 0.1049 - val_loss: 2.3027 - val_accuracy: 0.1028\n",
      "\u001b[36m(train_mnist pid=2617307)\u001b[0m Epoch 8/12\n",
      " 10/469 [..............................] - ETA: 2s - loss: 2.3018 - accuracy: 0.1180\n",
      " 28/469 [>.............................] - ETA: 2s - loss: 2.3052 - accuracy: 0.1124\n",
      " 46/469 [=>............................] - ETA: 2s - loss: 2.3052 - accuracy: 0.1089\n",
      " 73/469 [===>..........................] - ETA: 2s - loss: 2.3048 - accuracy: 0.1064\n",
      " 91/469 [====>.........................] - ETA: 2s - loss: 2.3048 - accuracy: 0.1084\n",
      "109/469 [=====>........................] - ETA: 2s - loss: 2.3042 - accuracy: 0.1101\n",
      "126/469 [=======>......................] - ETA: 1s - loss: 2.3044 - accuracy: 0.1088\n",
      "144/469 [========>.....................] - ETA: 1s - loss: 2.3047 - accuracy: 0.1066\n",
      "162/469 [=========>....................] - ETA: 1s - loss: 2.3050 - accuracy: 0.1066\n",
      "171/469 [=========>....................] - ETA: 1s - loss: 2.3051 - accuracy: 0.1071\n",
      "187/469 [==========>...................] - ETA: 1s - loss: 2.3048 - accuracy: 0.1085\n",
      "205/469 [============>.................] - ETA: 1s - loss: 2.3046 - accuracy: 0.1080\n",
      "223/469 [=============>................] - ETA: 1s - loss: 2.3046 - accuracy: 0.1072\n",
      "241/469 [==============>...............] - ETA: 1s - loss: 2.3048 - accuracy: 0.1064\n",
      "260/469 [===============>..............] - ETA: 1s - loss: 2.3046 - accuracy: 0.1068\n",
      "278/469 [================>.............] - ETA: 1s - loss: 2.3049 - accuracy: 0.1062\n",
      "296/469 [=================>............] - ETA: 1s - loss: 2.3049 - accuracy: 0.1062\n",
      "314/469 [===================>..........] - ETA: 0s - loss: 2.3049 - accuracy: 0.1065\n",
      "332/469 [====================>.........] - ETA: 0s - loss: 2.3050 - accuracy: 0.1056\n",
      "351/469 [=====================>........] - ETA: 0s - loss: 2.3051 - accuracy: 0.1052\n",
      "370/469 [======================>.......] - ETA: 0s - loss: 2.3051 - accuracy: 0.1051\n",
      "379/469 [=======================>......] - ETA: 0s - loss: 2.3051 - accuracy: 0.1049\n",
      "397/469 [========================>.....] - ETA: 0s - loss: 2.3051 - accuracy: 0.1046\n",
      "415/469 [=========================>....] - ETA: 0s - loss: 2.3051 - accuracy: 0.1050\n",
      "434/469 [==========================>...] - ETA: 0s - loss: 2.3052 - accuracy: 0.1049\n",
      "452/469 [===========================>..] - ETA: 0s - loss: 2.3052 - accuracy: 0.1046\n",
      "462/469 [============================>.] - ETA: 0s - loss: 2.3050 - accuracy: 0.1055\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3051 - accuracy: 0.1054 - val_loss: 2.3064 - val_accuracy: 0.1135\n",
      "\u001b[36m(train_mnist pid=2617307)\u001b[0m Epoch 9/12\n",
      "  1/469 [..............................] - ETA: 3s - loss: 2.3089 - accuracy: 0.0938\n",
      " 19/469 [>.............................] - ETA: 2s - loss: 2.3079 - accuracy: 0.1036\n",
      " 37/469 [=>............................] - ETA: 2s - loss: 2.3062 - accuracy: 0.1030\n",
      " 55/469 [==>...........................] - ETA: 2s - loss: 2.3059 - accuracy: 0.1095\n",
      " 64/469 [===>..........................] - ETA: 2s - loss: 2.3053 - accuracy: 0.1123\n",
      " 82/469 [====>.........................] - ETA: 2s - loss: 2.3059 - accuracy: 0.1116\n",
      "101/469 [=====>........................] - ETA: 2s - loss: 2.3054 - accuracy: 0.1093\n",
      "120/469 [======>.......................] - ETA: 2s - loss: 2.3053 - accuracy: 0.1110\n",
      "138/469 [=======>......................] - ETA: 1s - loss: 2.3055 - accuracy: 0.1102\n",
      "156/469 [========>.....................] - ETA: 1s - loss: 2.3056 - accuracy: 0.1095\n",
      "173/469 [==========>...................] - ETA: 1s - loss: 2.3057 - accuracy: 0.1089\n",
      "193/469 [===========>..................] - ETA: 1s - loss: 2.3055 - accuracy: 0.1082\n",
      "211/469 [============>.................] - ETA: 1s - loss: 2.3055 - accuracy: 0.1074\n",
      "230/469 [=============>................] - ETA: 1s - loss: 2.3053 - accuracy: 0.1081\n",
      "248/469 [==============>...............] - ETA: 1s - loss: 2.3051 - accuracy: 0.1086\n",
      "266/469 [================>.............] - ETA: 1s - loss: 2.3050 - accuracy: 0.1085\n",
      "275/469 [================>.............] - ETA: 1s - loss: 2.3050 - accuracy: 0.1084\n",
      "293/469 [=================>............] - ETA: 1s - loss: 2.3052 - accuracy: 0.1076\n",
      "311/469 [==================>...........] - ETA: 0s - loss: 2.3052 - accuracy: 0.1073\n",
      "329/469 [====================>.........] - ETA: 0s - loss: 2.3053 - accuracy: 0.1068\n",
      "347/469 [=====================>........] - ETA: 0s - loss: 2.3055 - accuracy: 0.1066\n",
      "365/469 [======================>.......] - ETA: 0s - loss: 2.3055 - accuracy: 0.1064\n",
      "383/469 [=======================>......] - ETA: 0s - loss: 2.3055 - accuracy: 0.1066\n",
      "411/469 [=========================>....] - ETA: 0s - loss: 2.3055 - accuracy: 0.1067\n",
      "430/469 [==========================>...] - ETA: 0s - loss: 2.3056 - accuracy: 0.1062\n",
      "448/469 [===========================>..] - ETA: 0s - loss: 2.3057 - accuracy: 0.1057\n",
      "465/469 [============================>.] - ETA: 0s - loss: 2.3058 - accuracy: 0.1052\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3057 - accuracy: 0.1053 - val_loss: 2.3028 - val_accuracy: 0.1135\n",
      "\u001b[36m(train_mnist pid=2617307)\u001b[0m Epoch 10/12\n",
      " 10/469 [..............................] - ETA: 2s - loss: 2.2984 - accuracy: 0.1180\n",
      " 28/469 [>.............................] - ETA: 2s - loss: 2.3022 - accuracy: 0.1130\n",
      " 48/469 [==>...........................] - ETA: 2s - loss: 2.3041 - accuracy: 0.1089\n",
      " 66/469 [===>..........................] - ETA: 2s - loss: 2.3040 - accuracy: 0.1097\n",
      " 84/469 [====>.........................] - ETA: 2s - loss: 2.3043 - accuracy: 0.1088\n",
      "102/469 [=====>........................] - ETA: 2s - loss: 2.3043 - accuracy: 0.1083\n",
      "111/469 [======>.......................] - ETA: 2s - loss: 2.3045 - accuracy: 0.1085\n",
      "130/469 [=======>......................] - ETA: 1s - loss: 2.3046 - accuracy: 0.1083\n",
      "148/469 [========>.....................] - ETA: 1s - loss: 2.3047 - accuracy: 0.1076\n",
      "165/469 [=========>....................] - ETA: 1s - loss: 2.3046 - accuracy: 0.1066\n",
      "183/469 [==========>...................] - ETA: 1s - loss: 2.3045 - accuracy: 0.1074\n",
      "202/469 [===========>..................] - ETA: 1s - loss: 2.3045 - accuracy: 0.1082\n",
      "221/469 [=============>................] - ETA: 1s - loss: 2.3043 - accuracy: 0.1087\n",
      "239/469 [==============>...............] - ETA: 1s - loss: 2.3044 - accuracy: 0.1092\n",
      "258/469 [===============>..............] - ETA: 1s - loss: 2.3046 - accuracy: 0.1089\n",
      "276/469 [================>.............] - ETA: 1s - loss: 2.3047 - accuracy: 0.1093\n",
      "285/469 [=================>............] - ETA: 1s - loss: 2.3046 - accuracy: 0.1096\n",
      "304/469 [==================>...........] - ETA: 0s - loss: 2.3046 - accuracy: 0.1098\n",
      "323/469 [===================>..........] - ETA: 0s - loss: 2.3048 - accuracy: 0.1088\n",
      "342/469 [====================>.........] - ETA: 0s - loss: 2.3050 - accuracy: 0.1085\n",
      "359/469 [=====================>........] - ETA: 0s - loss: 2.3050 - accuracy: 0.1081\n",
      "378/469 [=======================>......] - ETA: 0s - loss: 2.3050 - accuracy: 0.1081\n",
      "398/469 [========================>.....] - ETA: 0s - loss: 2.3049 - accuracy: 0.1080\n",
      "417/469 [=========================>....] - ETA: 0s - loss: 2.3050 - accuracy: 0.1078\n",
      "437/469 [==========================>...] - ETA: 0s - loss: 2.3049 - accuracy: 0.1074\n",
      "456/469 [============================>.] - ETA: 0s - loss: 2.3048 - accuracy: 0.1078\n",
      "465/469 [============================>.] - ETA: 0s - loss: 2.3048 - accuracy: 0.1080\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3047 - accuracy: 0.1082 - val_loss: 2.3033 - val_accuracy: 0.1135\n",
      "\u001b[36m(train_mnist pid=2617307)\u001b[0m Epoch 11/12\n",
      "  1/469 [..............................] - ETA: 3s - loss: 2.3238 - accuracy: 0.1328\n",
      " 10/469 [..............................] - ETA: 2s - loss: 2.3084 - accuracy: 0.1164\n",
      " 29/469 [>.............................] - ETA: 2s - loss: 2.3067 - accuracy: 0.1091\n",
      " 48/469 [==>...........................] - ETA: 2s - loss: 2.3054 - accuracy: 0.1037\n",
      " 66/469 [===>..........................] - ETA: 2s - loss: 2.3053 - accuracy: 0.1020\n",
      " 84/469 [====>.........................] - ETA: 2s - loss: 2.3054 - accuracy: 0.1048\n",
      "102/469 [=====>........................] - ETA: 2s - loss: 2.3051 - accuracy: 0.1046\n",
      "121/469 [======>.......................] - ETA: 1s - loss: 2.3052 - accuracy: 0.1050\n",
      "139/469 [=======>......................] - ETA: 1s - loss: 2.3056 - accuracy: 0.1052\n",
      "166/469 [=========>....................] - ETA: 1s - loss: 2.3055 - accuracy: 0.1042\n",
      "184/469 [==========>...................] - ETA: 1s - loss: 2.3055 - accuracy: 0.1038\n",
      "203/469 [===========>..................] - ETA: 1s - loss: 2.3054 - accuracy: 0.1036\n",
      "221/469 [=============>................] - ETA: 1s - loss: 2.3056 - accuracy: 0.1033\n",
      "239/469 [==============>...............] - ETA: 1s - loss: 2.3057 - accuracy: 0.1027\n",
      "257/469 [===============>..............] - ETA: 1s - loss: 2.3057 - accuracy: 0.1024\n",
      "275/469 [================>.............] - ETA: 1s - loss: 2.3058 - accuracy: 0.1022\n",
      "293/469 [=================>............] - ETA: 1s - loss: 2.3058 - accuracy: 0.1024\n",
      "311/469 [==================>...........] - ETA: 0s - loss: 2.3056 - accuracy: 0.1022\n",
      "321/469 [===================>..........] - ETA: 0s - loss: 2.3057 - accuracy: 0.1025\n",
      "339/469 [====================>.........] - ETA: 0s - loss: 2.3056 - accuracy: 0.1038\n",
      "357/469 [=====================>........] - ETA: 0s - loss: 2.3055 - accuracy: 0.1043\n",
      "375/469 [======================>.......] - ETA: 0s - loss: 2.3056 - accuracy: 0.1046\n",
      "395/469 [========================>.....] - ETA: 0s - loss: 2.3054 - accuracy: 0.1055\n",
      "413/469 [=========================>....] - ETA: 0s - loss: 2.3055 - accuracy: 0.1056\n",
      "431/469 [==========================>...] - ETA: 0s - loss: 2.3056 - accuracy: 0.1056\n",
      "450/469 [===========================>..] - ETA: 0s - loss: 2.3055 - accuracy: 0.1057\n",
      "459/469 [============================>.] - ETA: 0s - loss: 2.3055 - accuracy: 0.1057\n",
      "468/469 [============================>.] - ETA: 0s - loss: 2.3055 - accuracy: 0.1056\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3056 - accuracy: 0.1055 - val_loss: 2.3072 - val_accuracy: 0.0958\n",
      "\u001b[36m(train_mnist pid=2617307)\u001b[0m Epoch 12/12\n",
      "  1/469 [..............................] - ETA: 2s - loss: 2.3011 - accuracy: 0.1406\n",
      " 20/469 [>.............................] - ETA: 2s - loss: 2.3086 - accuracy: 0.0910\n",
      " 38/469 [=>............................] - ETA: 2s - loss: 2.3065 - accuracy: 0.1032\n",
      " 58/469 [==>...........................] - ETA: 2s - loss: 2.3075 - accuracy: 0.1032\n",
      " 75/469 [===>..........................] - ETA: 2s - loss: 2.3074 - accuracy: 0.1029\n",
      " 84/469 [====>.........................] - ETA: 2s - loss: 2.3073 - accuracy: 0.1023\n",
      "102/469 [=====>........................] - ETA: 2s - loss: 2.3074 - accuracy: 0.1026\n",
      "120/469 [======>.......................] - ETA: 2s - loss: 2.3068 - accuracy: 0.1038\n",
      "138/469 [=======>......................] - ETA: 1s - loss: 2.3066 - accuracy: 0.1039\n",
      "156/469 [========>.....................] - ETA: 1s - loss: 2.3062 - accuracy: 0.1030\n",
      "174/469 [==========>...................] - ETA: 1s - loss: 2.3064 - accuracy: 0.1023\n",
      "192/469 [===========>..................] - ETA: 1s - loss: 2.3062 - accuracy: 0.1031\n",
      "210/469 [============>.................] - ETA: 1s - loss: 2.3059 - accuracy: 0.1040\n",
      "219/469 [=============>................] - ETA: 1s - loss: 2.3058 - accuracy: 0.1038\n",
      "237/469 [==============>...............] - ETA: 1s - loss: 2.3057 - accuracy: 0.1037\n",
      "255/469 [===============>..............] - ETA: 1s - loss: 2.3054 - accuracy: 0.1053\n",
      "273/469 [================>.............] - ETA: 1s - loss: 2.3054 - accuracy: 0.1061\n",
      "291/469 [=================>............] - ETA: 1s - loss: 2.3054 - accuracy: 0.1058\n",
      "310/469 [==================>...........] - ETA: 0s - loss: 2.3055 - accuracy: 0.1058\n",
      "328/469 [===================>..........] - ETA: 0s - loss: 2.3055 - accuracy: 0.1052\n",
      "346/469 [=====================>........] - ETA: 0s - loss: 2.3054 - accuracy: 0.1057\n",
      "355/469 [=====================>........] - ETA: 0s - loss: 2.3056 - accuracy: 0.1053\n",
      "373/469 [======================>.......] - ETA: 0s - loss: 2.3054 - accuracy: 0.1057\n",
      "391/469 [========================>.....] - ETA: 0s - loss: 2.3056 - accuracy: 0.1055\n",
      "409/469 [=========================>....] - ETA: 0s - loss: 2.3056 - accuracy: 0.1048\n",
      "427/469 [==========================>...] - ETA: 0s - loss: 2.3057 - accuracy: 0.1048\n",
      "445/469 [===========================>..] - ETA: 0s - loss: 2.3058 - accuracy: 0.1046\n",
      "464/469 [============================>.] - ETA: 0s - loss: 2.3057 - accuracy: 0.1045\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3057 - accuracy: 0.1046 - val_loss: 2.3033 - val_accuracy: 0.1135\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"trialProgress\">\n",
       "  <h3>Trial Progress</h3>\n",
       "  <table>\n",
       "<thead>\n",
       "<tr><th>Trial name          </th><th style=\"text-align: right;\">  mean_accuracy</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_mnist_050b7b5d</td><td style=\"text-align: right;\">         0.9649</td></tr>\n",
       "<tr><td>train_mnist_0f0fb4fc</td><td style=\"text-align: right;\">         0.9589</td></tr>\n",
       "<tr><td>train_mnist_27ad4a92</td><td style=\"text-align: right;\">         0.101 </td></tr>\n",
       "<tr><td>train_mnist_36566aaa</td><td style=\"text-align: right;\">         0.9587</td></tr>\n",
       "<tr><td>train_mnist_3d3d47c2</td><td style=\"text-align: right;\">         0.9727</td></tr>\n",
       "<tr><td>train_mnist_460491b1</td><td style=\"text-align: right;\">         0.1135</td></tr>\n",
       "<tr><td>train_mnist_580f069e</td><td style=\"text-align: right;\">         0.1135</td></tr>\n",
       "<tr><td>train_mnist_a19e9cc9</td><td style=\"text-align: right;\">         0.1135</td></tr>\n",
       "<tr><td>train_mnist_b010433f</td><td style=\"text-align: right;\">         0.1032</td></tr>\n",
       "<tr><td>train_mnist_f53e8a34</td><td style=\"text-align: right;\">         0.9516</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".trialProgress {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".trialProgress h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".trialProgress td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=2621766)\u001b[0m 2023-12-05 09:45:21.403744: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=2621766)\u001b[0m 2023-12-05 09:45:21.443255: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=2621766)\u001b[0m 2023-12-05 09:45:21.443281: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=2621766)\u001b[0m 2023-12-05 09:45:21.444330: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=2621766)\u001b[0m 2023-12-05 09:45:21.450222: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=2621766)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=2621766)\u001b[0m 2023-12-05 09:45:22.156055: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=2621766)\u001b[0m 2023-12-05 09:45:23.634218: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_mnist pid=2621766)\u001b[0m Epoch 1/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_mnist pid=2621766)\u001b[0m 2023-12-05 09:45:25.316133: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=2621766)\u001b[0m 2023-12-05 09:45:26.460376: I external/local_xla/xla/service/service.cc:168] XLA service 0x1484018104b0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=2621766)\u001b[0m 2023-12-05 09:45:26.460404: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=2621766)\u001b[0m 2023-12-05 09:45:26.467439: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=2621766)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=2621766)\u001b[0m I0000 00:00:1701787526.581369 2621957 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 13/938 [..............................] - ETA: 4s - loss: 33.9118 - accuracy: 0.1130  \n",
      " 38/938 [>.............................] - ETA: 3s - loss: 13.1240 - accuracy: 0.1053\n",
      " 51/938 [>.............................] - ETA: 3s - loss: 10.3684 - accuracy: 0.1032\n",
      " 79/938 [=>............................] - ETA: 3s - loss: 7.5097 - accuracy: 0.1044\n",
      "105/938 [==>...........................] - ETA: 3s - loss: 6.2209 - accuracy: 0.1018\n",
      "132/938 [===>..........................] - ETA: 3s - loss: 5.4205 - accuracy: 0.1014\n",
      "157/938 [====>.........................] - ETA: 3s - loss: 4.9252 - accuracy: 0.1012\n",
      "182/938 [====>.........................] - ETA: 3s - loss: 4.5656 - accuracy: 0.1002\n",
      "207/938 [=====>........................] - ETA: 2s - loss: 4.2931 - accuracy: 0.0992\n",
      "220/938 [======>.......................] - ETA: 2s - loss: 4.1763 - accuracy: 0.0984\n",
      "247/938 [======>.......................] - ETA: 2s - loss: 3.9718 - accuracy: 0.0989\n",
      "272/938 [=======>......................] - ETA: 2s - loss: 3.8191 - accuracy: 0.0998\n",
      "298/938 [========>.....................] - ETA: 2s - loss: 3.6867 - accuracy: 0.1007\n",
      "324/938 [=========>....................] - ETA: 2s - loss: 3.5765 - accuracy: 0.0999\n",
      "351/938 [==========>...................] - ETA: 2s - loss: 3.4791 - accuracy: 0.1000\n",
      "377/938 [===========>..................] - ETA: 2s - loss: 3.3984 - accuracy: 0.1012\n",
      "402/938 [===========>..................] - ETA: 2s - loss: 3.3305 - accuracy: 0.1016\n",
      "439/938 [=============>................] - ETA: 2s - loss: 3.2442 - accuracy: 0.1014\n",
      "464/938 [=============>................] - ETA: 1s - loss: 3.1937 - accuracy: 0.1006\n",
      "490/938 [==============>...............] - ETA: 1s - loss: 3.1467 - accuracy: 0.1002\n",
      "515/938 [===============>..............] - ETA: 1s - loss: 3.1060 - accuracy: 0.1011\n",
      "541/938 [================>.............] - ETA: 1s - loss: 3.0678 - accuracy: 0.1009\n",
      "567/938 [=================>............] - ETA: 1s - loss: 3.0328 - accuracy: 0.1013\n",
      "606/938 [==================>...........] - ETA: 1s - loss: 2.9863 - accuracy: 0.1006\n",
      "631/938 [===================>..........] - ETA: 1s - loss: 2.9594 - accuracy: 0.1007\n",
      "656/938 [===================>..........] - ETA: 1s - loss: 2.9345 - accuracy: 0.1013\n",
      "682/938 [====================>.........] - ETA: 1s - loss: 2.9106 - accuracy: 0.1019\n",
      "707/938 [=====================>........] - ETA: 0s - loss: 2.8894 - accuracy: 0.1017\n",
      "734/938 [======================>.......] - ETA: 0s - loss: 2.8681 - accuracy: 0.1016\n",
      "761/938 [=======================>......] - ETA: 0s - loss: 2.8483 - accuracy: 0.1013\n",
      "774/938 [=======================>......] - ETA: 0s - loss: 2.8393 - accuracy: 0.1014\n",
      "799/938 [========================>.....] - ETA: 0s - loss: 2.8227 - accuracy: 0.1017\n",
      "825/938 [=========================>....] - ETA: 0s - loss: 2.8065 - accuracy: 0.1022\n",
      "851/938 [==========================>...] - ETA: 0s - loss: 2.7914 - accuracy: 0.1021\n",
      "878/938 [===========================>..] - ETA: 0s - loss: 2.7768 - accuracy: 0.1018\n",
      "903/938 [===========================>..] - ETA: 0s - loss: 2.7638 - accuracy: 0.1018\n",
      "915/938 [============================>.] - ETA: 0s - loss: 2.7577 - accuracy: 0.1024\n",
      "928/938 [============================>.] - ETA: 0s - loss: 2.7516 - accuracy: 0.1023\n",
      "938/938 [==============================] - ETA: 0s - loss: 2.7471 - accuracy: 0.1023\n",
      "938/938 [==============================] - 7s 5ms/step - loss: 2.7471 - accuracy: 0.1023 - val_loss: 2.3118 - val_accuracy: 0.0982\n",
      "\u001b[36m(train_mnist pid=2621766)\u001b[0m Epoch 2/12\n",
      "  1/938 [..............................] - ETA: 3s - loss: 2.3370 - accuracy: 0.0625\n",
      " 27/938 [..............................] - ETA: 3s - loss: 2.3093 - accuracy: 0.0938\n",
      " 39/938 [>.............................] - ETA: 3s - loss: 2.3096 - accuracy: 0.0893\n",
      " 68/938 [=>............................] - ETA: 3s - loss: 2.3091 - accuracy: 0.0960\n",
      " 94/938 [==>...........................] - ETA: 3s - loss: 2.3092 - accuracy: 0.0962\n",
      "120/938 [==>...........................] - ETA: 3s - loss: 2.3083 - accuracy: 0.0999\n",
      "145/938 [===>..........................] - ETA: 3s - loss: 2.3084 - accuracy: 0.0999\n",
      "171/938 [====>.........................] - ETA: 3s - loss: 2.3086 - accuracy: 0.0989\n",
      "209/938 [=====>........................] - ETA: 2s - loss: 2.3084 - accuracy: 0.0983\n",
      "235/938 [======>.......................] - ETA: 2s - loss: 2.3088 - accuracy: 0.0990\n",
      "261/938 [=======>......................] - ETA: 2s - loss: 2.3086 - accuracy: 0.1001\n",
      "287/938 [========>.....................] - ETA: 2s - loss: 2.3088 - accuracy: 0.1006\n",
      "313/938 [=========>....................] - ETA: 2s - loss: 2.3082 - accuracy: 0.1010\n",
      "338/938 [=========>....................] - ETA: 2s - loss: 2.3083 - accuracy: 0.1005\n",
      "365/938 [==========>...................] - ETA: 2s - loss: 2.3086 - accuracy: 0.0998\n",
      "377/938 [===========>..................] - ETA: 2s - loss: 2.3083 - accuracy: 0.0998\n",
      "403/938 [===========>..................] - ETA: 2s - loss: 2.3084 - accuracy: 0.1000\n",
      "430/938 [============>.................] - ETA: 2s - loss: 2.3084 - accuracy: 0.1001\n",
      "455/938 [=============>................] - ETA: 1s - loss: 2.3085 - accuracy: 0.1004\n",
      "480/938 [==============>...............] - ETA: 1s - loss: 2.3083 - accuracy: 0.1009\n",
      "505/938 [===============>..............] - ETA: 1s - loss: 2.3086 - accuracy: 0.1008\n",
      "530/938 [===============>..............] - ETA: 1s - loss: 2.3086 - accuracy: 0.1006\n",
      "569/938 [=================>............] - ETA: 1s - loss: 2.3087 - accuracy: 0.1008\n",
      "595/938 [==================>...........] - ETA: 1s - loss: 2.3086 - accuracy: 0.1012\n",
      "621/938 [==================>...........] - ETA: 1s - loss: 2.3086 - accuracy: 0.1012\n",
      "647/938 [===================>..........] - ETA: 1s - loss: 2.3086 - accuracy: 0.1017\n",
      "672/938 [====================>.........] - ETA: 1s - loss: 2.3085 - accuracy: 0.1017\n",
      "708/938 [=====================>........] - ETA: 0s - loss: 2.3084 - accuracy: 0.1016\n",
      "733/938 [======================>.......] - ETA: 0s - loss: 2.3084 - accuracy: 0.1013\n",
      "760/938 [=======================>......] - ETA: 0s - loss: 2.3085 - accuracy: 0.1013\n",
      "787/938 [========================>.....] - ETA: 0s - loss: 2.3084 - accuracy: 0.1012\n",
      "814/938 [=========================>....] - ETA: 0s - loss: 2.3084 - accuracy: 0.1016\n",
      "840/938 [=========================>....] - ETA: 0s - loss: 2.3083 - accuracy: 0.1019\n",
      "865/938 [==========================>...] - ETA: 0s - loss: 2.3085 - accuracy: 0.1019\n",
      "902/938 [===========================>..] - ETA: 0s - loss: 2.3085 - accuracy: 0.1017\n",
      "926/938 [============================>.] - ETA: 0s - loss: 2.3085 - accuracy: 0.1019\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 2.3086 - accuracy: 0.1020 - val_loss: 2.3132 - val_accuracy: 0.0958\n",
      "\u001b[36m(train_mnist pid=2621766)\u001b[0m Epoch 3/12\n",
      " 15/938 [..............................] - ETA: 3s - loss: 2.3147 - accuracy: 0.0969\n",
      " 40/938 [>.............................] - ETA: 3s - loss: 2.3096 - accuracy: 0.0922\n",
      " 67/938 [=>............................] - ETA: 3s - loss: 2.3112 - accuracy: 0.0924\n",
      " 92/938 [=>............................] - ETA: 3s - loss: 2.3104 - accuracy: 0.0932\n",
      "104/938 [==>...........................] - ETA: 3s - loss: 2.3099 - accuracy: 0.0933\n",
      "130/938 [===>..........................] - ETA: 3s - loss: 2.3095 - accuracy: 0.0963\n",
      "157/938 [====>.........................] - ETA: 3s - loss: 2.3095 - accuracy: 0.0976\n",
      "183/938 [====>.........................] - ETA: 3s - loss: 2.3097 - accuracy: 0.0976\n",
      "208/938 [=====>........................] - ETA: 2s - loss: 2.3095 - accuracy: 0.0991\n",
      "235/938 [======>.......................] - ETA: 2s - loss: 2.3098 - accuracy: 0.0985\n",
      "260/938 [=======>......................] - ETA: 2s - loss: 2.3097 - accuracy: 0.0984\n",
      "273/938 [=======>......................] - ETA: 2s - loss: 2.3095 - accuracy: 0.0984\n",
      "298/938 [========>.....................] - ETA: 2s - loss: 2.3094 - accuracy: 0.0983\n",
      "324/938 [=========>....................] - ETA: 2s - loss: 2.3095 - accuracy: 0.0992\n",
      "351/938 [==========>...................] - ETA: 2s - loss: 2.3094 - accuracy: 0.0987\n",
      "377/938 [===========>..................] - ETA: 2s - loss: 2.3095 - accuracy: 0.0995\n",
      "402/938 [===========>..................] - ETA: 2s - loss: 2.3096 - accuracy: 0.1004\n",
      "415/938 [============>.................] - ETA: 2s - loss: 2.3096 - accuracy: 0.1006\n",
      "442/938 [=============>................] - ETA: 1s - loss: 2.3096 - accuracy: 0.1006\n",
      "468/938 [=============>................] - ETA: 1s - loss: 2.3099 - accuracy: 0.0999\n",
      "494/938 [==============>...............] - ETA: 1s - loss: 2.3095 - accuracy: 0.1006\n",
      "520/938 [===============>..............] - ETA: 1s - loss: 2.3095 - accuracy: 0.1007\n",
      "546/938 [================>.............] - ETA: 1s - loss: 2.3092 - accuracy: 0.1008\n",
      "570/938 [=================>............] - ETA: 1s - loss: 2.3093 - accuracy: 0.1008\n",
      "596/938 [==================>...........] - ETA: 1s - loss: 2.3093 - accuracy: 0.1010\n",
      "609/938 [==================>...........] - ETA: 1s - loss: 2.3092 - accuracy: 0.1015\n",
      "633/938 [===================>..........] - ETA: 1s - loss: 2.3091 - accuracy: 0.1014\n",
      "659/938 [====================>.........] - ETA: 1s - loss: 2.3090 - accuracy: 0.1015\n",
      "684/938 [====================>.........] - ETA: 1s - loss: 2.3091 - accuracy: 0.1017\n",
      "709/938 [=====================>........] - ETA: 0s - loss: 2.3093 - accuracy: 0.1018\n",
      "734/938 [======================>.......] - ETA: 0s - loss: 2.3094 - accuracy: 0.1017\n",
      "759/938 [=======================>......] - ETA: 0s - loss: 2.3094 - accuracy: 0.1015\n",
      "772/938 [=======================>......] - ETA: 0s - loss: 2.3095 - accuracy: 0.1016\n",
      "799/938 [========================>.....] - ETA: 0s - loss: 2.3094 - accuracy: 0.1020\n",
      "824/938 [=========================>....] - ETA: 0s - loss: 2.3096 - accuracy: 0.1016\n",
      "849/938 [==========================>...] - ETA: 0s - loss: 2.3095 - accuracy: 0.1018\n",
      "874/938 [==========================>...] - ETA: 0s - loss: 2.3094 - accuracy: 0.1014\n",
      "898/938 [===========================>..] - ETA: 0s - loss: 2.3093 - accuracy: 0.1015\n",
      "924/938 [============================>.] - ETA: 0s - loss: 2.3092 - accuracy: 0.1017\n",
      "936/938 [============================>.] - ETA: 0s - loss: 2.3093 - accuracy: 0.1017\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 2.3093 - accuracy: 0.1016 - val_loss: 2.3093 - val_accuracy: 0.0974\n",
      "\u001b[36m(train_mnist pid=2621766)\u001b[0m Epoch 4/12\n",
      "  1/938 [..............................] - ETA: 3s - loss: 2.3043 - accuracy: 0.0938\n",
      " 28/938 [..............................] - ETA: 3s - loss: 2.3080 - accuracy: 0.0887\n",
      " 52/938 [>.............................] - ETA: 3s - loss: 2.3127 - accuracy: 0.0934\n",
      " 78/938 [=>............................] - ETA: 3s - loss: 2.3127 - accuracy: 0.0954\n",
      "103/938 [==>...........................] - ETA: 3s - loss: 2.3103 - accuracy: 0.0994\n",
      "139/938 [===>..........................] - ETA: 3s - loss: 2.3100 - accuracy: 0.1024\n",
      "164/938 [====>.........................] - ETA: 3s - loss: 2.3099 - accuracy: 0.1026\n",
      "191/938 [=====>........................] - ETA: 3s - loss: 2.3103 - accuracy: 0.1019\n",
      "218/938 [=====>........................] - ETA: 2s - loss: 2.3103 - accuracy: 0.1022\n",
      "245/938 [======>.......................] - ETA: 2s - loss: 2.3099 - accuracy: 0.1019\n",
      "272/938 [=======>......................] - ETA: 2s - loss: 2.3099 - accuracy: 0.1028\n",
      "297/938 [========>.....................] - ETA: 2s - loss: 2.3096 - accuracy: 0.1033\n",
      "310/938 [========>.....................] - ETA: 2s - loss: 2.3094 - accuracy: 0.1041\n",
      "336/938 [=========>....................] - ETA: 2s - loss: 2.3094 - accuracy: 0.1049\n",
      "360/938 [==========>...................] - ETA: 2s - loss: 2.3096 - accuracy: 0.1045\n",
      "387/938 [===========>..................] - ETA: 2s - loss: 2.3095 - accuracy: 0.1049\n",
      "411/938 [============>.................] - ETA: 2s - loss: 2.3096 - accuracy: 0.1049\n",
      "437/938 [============>.................] - ETA: 2s - loss: 2.3096 - accuracy: 0.1041\n",
      "462/938 [=============>................] - ETA: 1s - loss: 2.3097 - accuracy: 0.1041\n",
      "475/938 [==============>...............] - ETA: 1s - loss: 2.3096 - accuracy: 0.1041\n",
      "501/938 [===============>..............] - ETA: 1s - loss: 2.3094 - accuracy: 0.1045\n",
      "526/938 [===============>..............] - ETA: 1s - loss: 2.3092 - accuracy: 0.1040\n",
      "552/938 [================>.............] - ETA: 1s - loss: 2.3095 - accuracy: 0.1043\n",
      "577/938 [=================>............] - ETA: 1s - loss: 2.3094 - accuracy: 0.1039\n",
      "603/938 [==================>...........] - ETA: 1s - loss: 2.3093 - accuracy: 0.1047\n",
      "631/938 [===================>..........] - ETA: 1s - loss: 2.3093 - accuracy: 0.1040\n",
      "657/938 [====================>.........] - ETA: 1s - loss: 2.3094 - accuracy: 0.1039\n",
      "670/938 [====================>.........] - ETA: 1s - loss: 2.3093 - accuracy: 0.1039\n",
      "694/938 [=====================>........] - ETA: 0s - loss: 2.3093 - accuracy: 0.1040\n",
      "720/938 [======================>.......] - ETA: 0s - loss: 2.3092 - accuracy: 0.1040\n",
      "746/938 [======================>.......] - ETA: 0s - loss: 2.3091 - accuracy: 0.1040\n",
      "771/938 [=======================>......] - ETA: 0s - loss: 2.3091 - accuracy: 0.1036\n",
      "795/938 [========================>.....] - ETA: 0s - loss: 2.3091 - accuracy: 0.1035\n",
      "832/938 [=========================>....] - ETA: 0s - loss: 2.3089 - accuracy: 0.1040\n",
      "857/938 [==========================>...] - ETA: 0s - loss: 2.3091 - accuracy: 0.1039\n",
      "881/938 [===========================>..] - ETA: 0s - loss: 2.3092 - accuracy: 0.1038\n",
      "905/938 [===========================>..] - ETA: 0s - loss: 2.3093 - accuracy: 0.1036\n",
      "931/938 [============================>.] - ETA: 0s - loss: 2.3091 - accuracy: 0.1037\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 2.3091 - accuracy: 0.1036 - val_loss: 2.3056 - val_accuracy: 0.1032\n",
      "\u001b[36m(train_mnist pid=2621766)\u001b[0m Epoch 5/12\n",
      "  1/938 [..............................] - ETA: 4s - loss: 2.3175 - accuracy: 0.1094\n",
      " 28/938 [..............................] - ETA: 3s - loss: 2.3090 - accuracy: 0.1038\n",
      " 54/938 [>.............................] - ETA: 3s - loss: 2.3100 - accuracy: 0.1053\n",
      " 80/938 [=>............................] - ETA: 3s - loss: 2.3101 - accuracy: 0.1016\n",
      "106/938 [==>...........................] - ETA: 3s - loss: 2.3102 - accuracy: 0.1020\n",
      "119/938 [==>...........................] - ETA: 3s - loss: 2.3106 - accuracy: 0.1019\n",
      "146/938 [===>..........................] - ETA: 3s - loss: 2.3097 - accuracy: 0.1030\n",
      "171/938 [====>.........................] - ETA: 3s - loss: 2.3096 - accuracy: 0.1048\n",
      "197/938 [=====>........................] - ETA: 2s - loss: 2.3095 - accuracy: 0.1067\n",
      "223/938 [======>.......................] - ETA: 2s - loss: 2.3094 - accuracy: 0.1052\n",
      "247/938 [======>.......................] - ETA: 2s - loss: 2.3091 - accuracy: 0.1055\n",
      "270/938 [=======>......................] - ETA: 2s - loss: 2.3086 - accuracy: 0.1063\n",
      "283/938 [========>.....................] - ETA: 2s - loss: 2.3090 - accuracy: 0.1055\n",
      "309/938 [========>.....................] - ETA: 2s - loss: 2.3090 - accuracy: 0.1045\n",
      "334/938 [=========>....................] - ETA: 2s - loss: 2.3089 - accuracy: 0.1043\n",
      "359/938 [==========>...................] - ETA: 2s - loss: 2.3085 - accuracy: 0.1050\n",
      "384/938 [===========>..................] - ETA: 2s - loss: 2.3088 - accuracy: 0.1043\n",
      "411/938 [============>.................] - ETA: 2s - loss: 2.3089 - accuracy: 0.1050\n",
      "436/938 [============>.................] - ETA: 2s - loss: 2.3089 - accuracy: 0.1051\n",
      "473/938 [==============>...............] - ETA: 1s - loss: 2.3089 - accuracy: 0.1051\n",
      "499/938 [==============>...............] - ETA: 1s - loss: 2.3091 - accuracy: 0.1050\n",
      "524/938 [===============>..............] - ETA: 1s - loss: 2.3092 - accuracy: 0.1056\n",
      "549/938 [================>.............] - ETA: 1s - loss: 2.3089 - accuracy: 0.1063\n",
      "574/938 [=================>............] - ETA: 1s - loss: 2.3092 - accuracy: 0.1058\n",
      "600/938 [==================>...........] - ETA: 1s - loss: 2.3092 - accuracy: 0.1054\n",
      "637/938 [===================>..........] - ETA: 1s - loss: 2.3093 - accuracy: 0.1054\n",
      "665/938 [====================>.........] - ETA: 1s - loss: 2.3093 - accuracy: 0.1056\n",
      "693/938 [=====================>........] - ETA: 0s - loss: 2.3092 - accuracy: 0.1058\n",
      "719/938 [=====================>........] - ETA: 0s - loss: 2.3093 - accuracy: 0.1051\n",
      "743/938 [======================>.......] - ETA: 0s - loss: 2.3091 - accuracy: 0.1049\n",
      "768/938 [=======================>......] - ETA: 0s - loss: 2.3091 - accuracy: 0.1050\n",
      "794/938 [========================>.....] - ETA: 0s - loss: 2.3092 - accuracy: 0.1051\n",
      "808/938 [========================>.....] - ETA: 0s - loss: 2.3091 - accuracy: 0.1051\n",
      "833/938 [=========================>....] - ETA: 0s - loss: 2.3091 - accuracy: 0.1050\n",
      "858/938 [==========================>...] - ETA: 0s - loss: 2.3091 - accuracy: 0.1048\n",
      "884/938 [===========================>..] - ETA: 0s - loss: 2.3090 - accuracy: 0.1050\n",
      "910/938 [============================>.] - ETA: 0s - loss: 2.3089 - accuracy: 0.1050\n",
      "935/938 [============================>.] - ETA: 0s - loss: 2.3090 - accuracy: 0.1049\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 2.3090 - accuracy: 0.1049 - val_loss: 2.3049 - val_accuracy: 0.1135\n",
      "\u001b[36m(train_mnist pid=2621766)\u001b[0m Epoch 6/12\n",
      "  1/938 [..............................] - ETA: 3s - loss: 2.3266 - accuracy: 0.0469\n",
      " 41/938 [>.............................] - ETA: 3s - loss: 2.3103 - accuracy: 0.0922\n",
      " 67/938 [=>............................] - ETA: 3s - loss: 2.3095 - accuracy: 0.0928\n",
      " 94/938 [==>...........................] - ETA: 3s - loss: 2.3096 - accuracy: 0.0996\n",
      "120/938 [==>...........................] - ETA: 3s - loss: 2.3096 - accuracy: 0.1016\n",
      "143/938 [===>..........................] - ETA: 3s - loss: 2.3090 - accuracy: 0.1026\n",
      "169/938 [====>.........................] - ETA: 3s - loss: 2.3091 - accuracy: 0.1025\n",
      "180/938 [====>.........................] - ETA: 3s - loss: 2.3090 - accuracy: 0.1028\n",
      "205/938 [=====>........................] - ETA: 2s - loss: 2.3093 - accuracy: 0.1014\n",
      "232/938 [======>.......................] - ETA: 2s - loss: 2.3093 - accuracy: 0.1000\n",
      "258/938 [=======>......................] - ETA: 2s - loss: 2.3093 - accuracy: 0.1005\n",
      "282/938 [========>.....................] - ETA: 2s - loss: 2.3091 - accuracy: 0.1007\n",
      "307/938 [========>.....................] - ETA: 2s - loss: 2.3091 - accuracy: 0.1016\n",
      "331/938 [=========>....................] - ETA: 2s - loss: 2.3092 - accuracy: 0.1021\n",
      "357/938 [==========>...................] - ETA: 2s - loss: 2.3093 - accuracy: 0.1021\n",
      "369/938 [==========>...................] - ETA: 2s - loss: 2.3090 - accuracy: 0.1026\n",
      "394/938 [===========>..................] - ETA: 2s - loss: 2.3090 - accuracy: 0.1026\n",
      "418/938 [============>.................] - ETA: 2s - loss: 2.3091 - accuracy: 0.1023\n",
      "442/938 [=============>................] - ETA: 2s - loss: 2.3092 - accuracy: 0.1017\n",
      "467/938 [=============>................] - ETA: 1s - loss: 2.3092 - accuracy: 0.1026\n",
      "489/938 [==============>...............] - ETA: 1s - loss: 2.3091 - accuracy: 0.1030\n",
      "501/938 [===============>..............] - ETA: 1s - loss: 2.3092 - accuracy: 0.1034\n",
      "527/938 [===============>..............] - ETA: 1s - loss: 2.3090 - accuracy: 0.1037\n",
      "552/938 [================>.............] - ETA: 1s - loss: 2.3089 - accuracy: 0.1041\n",
      "578/938 [=================>............] - ETA: 1s - loss: 2.3089 - accuracy: 0.1040\n",
      "604/938 [==================>...........] - ETA: 1s - loss: 2.3089 - accuracy: 0.1039\n",
      "630/938 [===================>..........] - ETA: 1s - loss: 2.3089 - accuracy: 0.1038\n",
      "657/938 [====================>.........] - ETA: 1s - loss: 2.3088 - accuracy: 0.1038\n",
      "683/938 [====================>.........] - ETA: 1s - loss: 2.3089 - accuracy: 0.1040\n",
      "697/938 [=====================>........] - ETA: 0s - loss: 2.3089 - accuracy: 0.1042\n",
      "723/938 [======================>.......] - ETA: 0s - loss: 2.3089 - accuracy: 0.1044\n",
      "749/938 [======================>.......] - ETA: 0s - loss: 2.3089 - accuracy: 0.1039\n",
      "775/938 [=======================>......] - ETA: 0s - loss: 2.3087 - accuracy: 0.1039\n",
      "802/938 [========================>.....] - ETA: 0s - loss: 2.3088 - accuracy: 0.1036\n",
      "828/938 [=========================>....] - ETA: 0s - loss: 2.3090 - accuracy: 0.1031\n",
      "854/938 [==========================>...] - ETA: 0s - loss: 2.3091 - accuracy: 0.1025\n",
      "893/938 [===========================>..] - ETA: 0s - loss: 2.3092 - accuracy: 0.1025\n",
      "920/938 [============================>.] - ETA: 0s - loss: 2.3091 - accuracy: 0.1027\n",
      "933/938 [============================>.] - ETA: 0s - loss: 2.3091 - accuracy: 0.1028\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 2.3090 - accuracy: 0.1029 - val_loss: 2.3204 - val_accuracy: 0.0980\n",
      "\u001b[36m(train_mnist pid=2621766)\u001b[0m Epoch 7/12\n",
      " 13/938 [..............................] - ETA: 3s - loss: 2.3113 - accuracy: 0.1046\n",
      " 39/938 [>.............................] - ETA: 3s - loss: 2.3129 - accuracy: 0.1022\n",
      " 65/938 [=>............................] - ETA: 3s - loss: 2.3130 - accuracy: 0.1031\n",
      " 91/938 [=>............................] - ETA: 3s - loss: 2.3108 - accuracy: 0.1022\n",
      "117/938 [==>...........................] - ETA: 3s - loss: 2.3080 - accuracy: 0.1038\n",
      "143/938 [===>..........................] - ETA: 3s - loss: 2.3076 - accuracy: 0.1030\n",
      "156/938 [===>..........................] - ETA: 3s - loss: 2.3071 - accuracy: 0.1057\n",
      "182/938 [====>.........................] - ETA: 3s - loss: 2.3071 - accuracy: 0.1067\n",
      "207/938 [=====>........................] - ETA: 2s - loss: 2.3076 - accuracy: 0.1046\n",
      "233/938 [======>.......................] - ETA: 2s - loss: 2.3082 - accuracy: 0.1043\n",
      "259/938 [=======>......................] - ETA: 2s - loss: 2.3080 - accuracy: 0.1066\n",
      "284/938 [========>.....................] - ETA: 2s - loss: 2.3080 - accuracy: 0.1062\n",
      "309/938 [========>.....................] - ETA: 2s - loss: 2.3079 - accuracy: 0.1065\n",
      "336/938 [=========>....................] - ETA: 2s - loss: 2.3082 - accuracy: 0.1063\n",
      "349/938 [==========>...................] - ETA: 2s - loss: 2.3085 - accuracy: 0.1062\n",
      "375/938 [==========>...................] - ETA: 2s - loss: 2.3086 - accuracy: 0.1059\n",
      "401/938 [===========>..................] - ETA: 2s - loss: 2.3089 - accuracy: 0.1057\n",
      "427/938 [============>.................] - ETA: 2s - loss: 2.3088 - accuracy: 0.1057\n",
      "452/938 [=============>................] - ETA: 1s - loss: 2.3089 - accuracy: 0.1057\n",
      "476/938 [==============>...............] - ETA: 1s - loss: 2.3090 - accuracy: 0.1052\n",
      "512/938 [===============>..............] - ETA: 1s - loss: 2.3088 - accuracy: 0.1056\n",
      "536/938 [================>.............] - ETA: 1s - loss: 2.3091 - accuracy: 0.1055\n",
      "560/938 [================>.............] - ETA: 1s - loss: 2.3090 - accuracy: 0.1054\n",
      "586/938 [=================>............] - ETA: 1s - loss: 2.3091 - accuracy: 0.1052\n",
      "612/938 [==================>...........] - ETA: 1s - loss: 2.3089 - accuracy: 0.1048\n",
      "638/938 [===================>..........] - ETA: 1s - loss: 2.3088 - accuracy: 0.1055\n",
      "650/938 [===================>..........] - ETA: 1s - loss: 2.3087 - accuracy: 0.1053\n",
      "675/938 [====================>.........] - ETA: 1s - loss: 2.3086 - accuracy: 0.1053\n",
      "699/938 [=====================>........] - ETA: 0s - loss: 2.3086 - accuracy: 0.1053\n",
      "724/938 [======================>.......] - ETA: 0s - loss: 2.3086 - accuracy: 0.1054\n",
      "750/938 [======================>.......] - ETA: 0s - loss: 2.3088 - accuracy: 0.1052\n",
      "775/938 [=======================>......] - ETA: 0s - loss: 2.3088 - accuracy: 0.1052\n",
      "803/938 [========================>.....] - ETA: 0s - loss: 2.3090 - accuracy: 0.1047\n",
      "815/938 [=========================>....] - ETA: 0s - loss: 2.3089 - accuracy: 0.1049\n",
      "840/938 [=========================>....] - ETA: 0s - loss: 2.3089 - accuracy: 0.1046\n",
      "865/938 [==========================>...] - ETA: 0s - loss: 2.3088 - accuracy: 0.1048\n",
      "891/938 [===========================>..] - ETA: 0s - loss: 2.3089 - accuracy: 0.1047\n",
      "917/938 [============================>.] - ETA: 0s - loss: 2.3089 - accuracy: 0.1050\n",
      "930/938 [============================>.] - ETA: 0s - loss: 2.3089 - accuracy: 0.1049\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 2.3089 - accuracy: 0.1050 - val_loss: 2.3043 - val_accuracy: 0.1009\n",
      "\u001b[36m(train_mnist pid=2621766)\u001b[0m Epoch 8/12\n",
      " 14/938 [..............................] - ETA: 3s - loss: 2.3046 - accuracy: 0.1205\n",
      " 38/938 [>.............................] - ETA: 3s - loss: 2.3045 - accuracy: 0.1118\n",
      " 63/938 [=>............................] - ETA: 3s - loss: 2.3069 - accuracy: 0.1066\n",
      " 77/938 [=>............................] - ETA: 3s - loss: 2.3078 - accuracy: 0.1049\n",
      "105/938 [==>...........................] - ETA: 3s - loss: 2.3081 - accuracy: 0.1019\n",
      "130/938 [===>..........................] - ETA: 3s - loss: 2.3082 - accuracy: 0.1046\n",
      "154/938 [===>..........................] - ETA: 3s - loss: 2.3072 - accuracy: 0.1033\n",
      "179/938 [====>.........................] - ETA: 3s - loss: 2.3074 - accuracy: 0.1060\n",
      "204/938 [=====>........................] - ETA: 2s - loss: 2.3069 - accuracy: 0.1060\n",
      "230/938 [======>.......................] - ETA: 2s - loss: 2.3075 - accuracy: 0.1065\n",
      "268/938 [=======>......................] - ETA: 2s - loss: 2.3075 - accuracy: 0.1058\n",
      "294/938 [========>.....................] - ETA: 2s - loss: 2.3077 - accuracy: 0.1059\n",
      "320/938 [=========>....................] - ETA: 2s - loss: 2.3077 - accuracy: 0.1064\n",
      "346/938 [==========>...................] - ETA: 2s - loss: 2.3076 - accuracy: 0.1065\n",
      "372/938 [==========>...................] - ETA: 2s - loss: 2.3076 - accuracy: 0.1058\n",
      "398/938 [===========>..................] - ETA: 2s - loss: 2.3080 - accuracy: 0.1051\n",
      "434/938 [============>.................] - ETA: 2s - loss: 2.3080 - accuracy: 0.1049\n",
      "459/938 [=============>................] - ETA: 1s - loss: 2.3080 - accuracy: 0.1043\n",
      "485/938 [==============>...............] - ETA: 1s - loss: 2.3077 - accuracy: 0.1049\n",
      "511/938 [===============>..............] - ETA: 1s - loss: 2.3080 - accuracy: 0.1042\n",
      "539/938 [================>.............] - ETA: 1s - loss: 2.3080 - accuracy: 0.1038\n",
      "564/938 [=================>............] - ETA: 1s - loss: 2.3081 - accuracy: 0.1041\n",
      "604/938 [==================>...........] - ETA: 1s - loss: 2.3084 - accuracy: 0.1039\n",
      "628/938 [===================>..........] - ETA: 1s - loss: 2.3084 - accuracy: 0.1040\n",
      "654/938 [===================>..........] - ETA: 1s - loss: 2.3086 - accuracy: 0.1036\n",
      "681/938 [====================>.........] - ETA: 1s - loss: 2.3090 - accuracy: 0.1028\n",
      "705/938 [=====================>........] - ETA: 0s - loss: 2.3090 - accuracy: 0.1030\n",
      "732/938 [======================>.......] - ETA: 0s - loss: 2.3089 - accuracy: 0.1032\n",
      "758/938 [=======================>......] - ETA: 0s - loss: 2.3089 - accuracy: 0.1028\n",
      "797/938 [========================>.....] - ETA: 0s - loss: 2.3089 - accuracy: 0.1029\n",
      "822/938 [=========================>....] - ETA: 0s - loss: 2.3088 - accuracy: 0.1030\n",
      "848/938 [==========================>...] - ETA: 0s - loss: 2.3087 - accuracy: 0.1027\n",
      "876/938 [===========================>..] - ETA: 0s - loss: 2.3088 - accuracy: 0.1022\n",
      "900/938 [===========================>..] - ETA: 0s - loss: 2.3087 - accuracy: 0.1022\n",
      "927/938 [============================>.] - ETA: 0s - loss: 2.3088 - accuracy: 0.1023\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 2.3088 - accuracy: 0.1023 - val_loss: 2.3087 - val_accuracy: 0.1028\n",
      "\u001b[36m(train_mnist pid=2621766)\u001b[0m Epoch 9/12\n",
      "  1/938 [..............................] - ETA: 3s - loss: 2.3172 - accuracy: 0.0781\n",
      " 29/938 [..............................] - ETA: 3s - loss: 2.3117 - accuracy: 0.1067\n",
      " 54/938 [>.............................] - ETA: 3s - loss: 2.3121 - accuracy: 0.1059\n",
      " 81/938 [=>............................] - ETA: 3s - loss: 2.3088 - accuracy: 0.1073\n",
      "106/938 [==>...........................] - ETA: 3s - loss: 2.3102 - accuracy: 0.1016\n",
      "132/938 [===>..........................] - ETA: 3s - loss: 2.3100 - accuracy: 0.1025\n",
      "160/938 [====>.........................] - ETA: 3s - loss: 2.3097 - accuracy: 0.1043\n",
      "173/938 [====>.........................] - ETA: 3s - loss: 2.3097 - accuracy: 0.1035\n",
      "199/938 [=====>........................] - ETA: 2s - loss: 2.3087 - accuracy: 0.1045\n",
      "226/938 [======>.......................] - ETA: 2s - loss: 2.3084 - accuracy: 0.1059\n",
      "252/938 [=======>......................] - ETA: 2s - loss: 2.3087 - accuracy: 0.1062\n",
      "278/938 [=======>......................] - ETA: 2s - loss: 2.3082 - accuracy: 0.1083\n",
      "304/938 [========>.....................] - ETA: 2s - loss: 2.3084 - accuracy: 0.1072\n",
      "330/938 [=========>....................] - ETA: 2s - loss: 2.3084 - accuracy: 0.1066\n",
      "369/938 [==========>...................] - ETA: 2s - loss: 2.3082 - accuracy: 0.1070\n",
      "396/938 [===========>..................] - ETA: 2s - loss: 2.3081 - accuracy: 0.1074\n",
      "421/938 [============>.................] - ETA: 2s - loss: 2.3087 - accuracy: 0.1058\n",
      "445/938 [=============>................] - ETA: 1s - loss: 2.3088 - accuracy: 0.1053\n",
      "470/938 [==============>...............] - ETA: 1s - loss: 2.3089 - accuracy: 0.1050\n",
      "494/938 [==============>...............] - ETA: 1s - loss: 2.3091 - accuracy: 0.1047\n",
      "506/938 [===============>..............] - ETA: 1s - loss: 2.3091 - accuracy: 0.1049\n",
      "532/938 [================>.............] - ETA: 1s - loss: 2.3089 - accuracy: 0.1050\n",
      "558/938 [================>.............] - ETA: 1s - loss: 2.3087 - accuracy: 0.1055\n",
      "583/938 [=================>............] - ETA: 1s - loss: 2.3087 - accuracy: 0.1052\n",
      "610/938 [==================>...........] - ETA: 1s - loss: 2.3086 - accuracy: 0.1049\n",
      "637/938 [===================>..........] - ETA: 1s - loss: 2.3084 - accuracy: 0.1047\n",
      "676/938 [====================>.........] - ETA: 1s - loss: 2.3085 - accuracy: 0.1045\n",
      "702/938 [=====================>........] - ETA: 0s - loss: 2.3086 - accuracy: 0.1047\n",
      "730/938 [======================>.......] - ETA: 0s - loss: 2.3088 - accuracy: 0.1042\n",
      "757/938 [=======================>......] - ETA: 0s - loss: 2.3088 - accuracy: 0.1038\n",
      "782/938 [========================>.....] - ETA: 0s - loss: 2.3088 - accuracy: 0.1038\n",
      "809/938 [========================>.....] - ETA: 0s - loss: 2.3089 - accuracy: 0.1039\n",
      "846/938 [==========================>...] - ETA: 0s - loss: 2.3088 - accuracy: 0.1039\n",
      "871/938 [==========================>...] - ETA: 0s - loss: 2.3088 - accuracy: 0.1041\n",
      "898/938 [===========================>..] - ETA: 0s - loss: 2.3088 - accuracy: 0.1038\n",
      "924/938 [============================>.] - ETA: 0s - loss: 2.3088 - accuracy: 0.1036\n",
      "937/938 [============================>.] - ETA: 0s - loss: 2.3089 - accuracy: 0.1036\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 2.3089 - accuracy: 0.1036 - val_loss: 2.3160 - val_accuracy: 0.0958\n",
      "\u001b[36m(train_mnist pid=2621766)\u001b[0m Epoch 10/12\n",
      " 14/938 [..............................] - ETA: 3s - loss: 2.3036 - accuracy: 0.1127\n",
      " 38/938 [>.............................] - ETA: 3s - loss: 2.3059 - accuracy: 0.1143\n",
      " 65/938 [=>............................] - ETA: 3s - loss: 2.3061 - accuracy: 0.1125\n",
      " 78/938 [=>............................] - ETA: 3s - loss: 2.3071 - accuracy: 0.1102\n",
      "107/938 [==>...........................] - ETA: 3s - loss: 2.3075 - accuracy: 0.1054\n",
      "134/938 [===>..........................] - ETA: 3s - loss: 2.3077 - accuracy: 0.1030\n",
      "160/938 [====>.........................] - ETA: 3s - loss: 2.3084 - accuracy: 0.1031\n",
      "187/938 [====>.........................] - ETA: 2s - loss: 2.3077 - accuracy: 0.1036\n",
      "212/938 [=====>........................] - ETA: 2s - loss: 2.3080 - accuracy: 0.1046\n",
      "239/938 [======>.......................] - ETA: 2s - loss: 2.3078 - accuracy: 0.1050\n",
      "264/938 [=======>......................] - ETA: 2s - loss: 2.3081 - accuracy: 0.1043\n",
      "292/938 [========>.....................] - ETA: 2s - loss: 2.3081 - accuracy: 0.1041\n",
      "333/938 [=========>....................] - ETA: 2s - loss: 2.3086 - accuracy: 0.1038\n",
      "359/938 [==========>...................] - ETA: 2s - loss: 2.3088 - accuracy: 0.1035\n",
      "387/938 [===========>..................] - ETA: 2s - loss: 2.3086 - accuracy: 0.1038\n",
      "411/938 [============>.................] - ETA: 2s - loss: 2.3084 - accuracy: 0.1041\n",
      "437/938 [============>.................] - ETA: 1s - loss: 2.3084 - accuracy: 0.1042\n",
      "465/938 [=============>................] - ETA: 1s - loss: 2.3083 - accuracy: 0.1048\n",
      "491/938 [==============>...............] - ETA: 1s - loss: 2.3085 - accuracy: 0.1041\n",
      "504/938 [===============>..............] - ETA: 1s - loss: 2.3086 - accuracy: 0.1036\n",
      "530/938 [===============>..............] - ETA: 1s - loss: 2.3088 - accuracy: 0.1030\n",
      "555/938 [================>.............] - ETA: 1s - loss: 2.3089 - accuracy: 0.1028\n",
      "581/938 [=================>............] - ETA: 1s - loss: 2.3088 - accuracy: 0.1028\n",
      "608/938 [==================>...........] - ETA: 1s - loss: 2.3088 - accuracy: 0.1031\n",
      "633/938 [===================>..........] - ETA: 1s - loss: 2.3089 - accuracy: 0.1029\n",
      "659/938 [====================>.........] - ETA: 1s - loss: 2.3089 - accuracy: 0.1029\n",
      "672/938 [====================>.........] - ETA: 1s - loss: 2.3090 - accuracy: 0.1027\n",
      "699/938 [=====================>........] - ETA: 0s - loss: 2.3090 - accuracy: 0.1023\n",
      "723/938 [======================>.......] - ETA: 0s - loss: 2.3090 - accuracy: 0.1023\n",
      "750/938 [======================>.......] - ETA: 0s - loss: 2.3089 - accuracy: 0.1026\n",
      "775/938 [=======================>......] - ETA: 0s - loss: 2.3090 - accuracy: 0.1026\n",
      "802/938 [========================>.....] - ETA: 0s - loss: 2.3090 - accuracy: 0.1023\n",
      "828/938 [=========================>....] - ETA: 0s - loss: 2.3087 - accuracy: 0.1030\n",
      "841/938 [=========================>....] - ETA: 0s - loss: 2.3090 - accuracy: 0.1030\n",
      "867/938 [==========================>...] - ETA: 0s - loss: 2.3089 - accuracy: 0.1029\n",
      "893/938 [===========================>..] - ETA: 0s - loss: 2.3087 - accuracy: 0.1031\n",
      "919/938 [============================>.] - ETA: 0s - loss: 2.3086 - accuracy: 0.1034\n",
      "932/938 [============================>.] - ETA: 0s - loss: 2.3086 - accuracy: 0.1033\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 2.3086 - accuracy: 0.1032 - val_loss: 2.3111 - val_accuracy: 0.0982\n",
      "\u001b[36m(train_mnist pid=2621766)\u001b[0m Epoch 11/12\n",
      " 13/938 [..............................] - ETA: 3s - loss: 2.3030 - accuracy: 0.1058\n",
      " 38/938 [>.............................] - ETA: 3s - loss: 2.3084 - accuracy: 0.0975\n",
      " 64/938 [=>............................] - ETA: 3s - loss: 2.3084 - accuracy: 0.1040\n",
      " 91/938 [=>............................] - ETA: 3s - loss: 2.3071 - accuracy: 0.1089\n",
      "129/938 [===>..........................] - ETA: 3s - loss: 2.3077 - accuracy: 0.1085\n",
      "154/938 [===>..........................] - ETA: 3s - loss: 2.3073 - accuracy: 0.1093\n",
      "180/938 [====>.........................] - ETA: 3s - loss: 2.3077 - accuracy: 0.1084\n",
      "207/938 [=====>........................] - ETA: 2s - loss: 2.3079 - accuracy: 0.1080\n",
      "232/938 [======>.......................] - ETA: 2s - loss: 2.3080 - accuracy: 0.1088\n",
      "259/938 [=======>......................] - ETA: 2s - loss: 2.3080 - accuracy: 0.1077\n",
      "285/938 [========>.....................] - ETA: 2s - loss: 2.3080 - accuracy: 0.1059\n",
      "298/938 [========>.....................] - ETA: 2s - loss: 2.3081 - accuracy: 0.1050\n",
      "324/938 [=========>....................] - ETA: 2s - loss: 2.3081 - accuracy: 0.1053\n",
      "350/938 [==========>...................] - ETA: 2s - loss: 2.3083 - accuracy: 0.1041\n",
      "376/938 [===========>..................] - ETA: 2s - loss: 2.3084 - accuracy: 0.1033\n",
      "400/938 [===========>..................] - ETA: 2s - loss: 2.3084 - accuracy: 0.1032\n",
      "425/938 [============>.................] - ETA: 2s - loss: 2.3084 - accuracy: 0.1040\n",
      "465/938 [=============>................] - ETA: 1s - loss: 2.3082 - accuracy: 0.1050\n",
      "490/938 [==============>...............] - ETA: 1s - loss: 2.3082 - accuracy: 0.1054\n",
      "517/938 [===============>..............] - ETA: 1s - loss: 2.3084 - accuracy: 0.1049\n",
      "544/938 [================>.............] - ETA: 1s - loss: 2.3084 - accuracy: 0.1047\n",
      "570/938 [=================>............] - ETA: 1s - loss: 2.3086 - accuracy: 0.1041\n",
      "594/938 [=================>............] - ETA: 1s - loss: 2.3087 - accuracy: 0.1039\n",
      "632/938 [===================>..........] - ETA: 1s - loss: 2.3088 - accuracy: 0.1039\n",
      "657/938 [====================>.........] - ETA: 1s - loss: 2.3087 - accuracy: 0.1048\n",
      "681/938 [====================>.........] - ETA: 1s - loss: 2.3087 - accuracy: 0.1047\n",
      "706/938 [=====================>........] - ETA: 0s - loss: 2.3087 - accuracy: 0.1051\n",
      "732/938 [======================>.......] - ETA: 0s - loss: 2.3086 - accuracy: 0.1053\n",
      "756/938 [=======================>......] - ETA: 0s - loss: 2.3087 - accuracy: 0.1053\n",
      "768/938 [=======================>......] - ETA: 0s - loss: 2.3087 - accuracy: 0.1053\n",
      "793/938 [========================>.....] - ETA: 0s - loss: 2.3086 - accuracy: 0.1056\n",
      "817/938 [=========================>....] - ETA: 0s - loss: 2.3085 - accuracy: 0.1057\n",
      "844/938 [=========================>....] - ETA: 0s - loss: 2.3087 - accuracy: 0.1052\n",
      "871/938 [==========================>...] - ETA: 0s - loss: 2.3086 - accuracy: 0.1051\n",
      "897/938 [===========================>..] - ETA: 0s - loss: 2.3086 - accuracy: 0.1055\n",
      "922/938 [============================>.] - ETA: 0s - loss: 2.3085 - accuracy: 0.1058\n",
      "935/938 [============================>.] - ETA: 0s - loss: 2.3084 - accuracy: 0.1058\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 2.3084 - accuracy: 0.1059 - val_loss: 2.3064 - val_accuracy: 0.1010\n",
      "\u001b[36m(train_mnist pid=2621766)\u001b[0m Epoch 12/12\n",
      "  1/938 [..............................] - ETA: 3s - loss: 2.3038 - accuracy: 0.0781\n",
      " 27/938 [..............................] - ETA: 3s - loss: 2.3090 - accuracy: 0.0955\n",
      " 53/938 [>.............................] - ETA: 3s - loss: 2.3103 - accuracy: 0.1064\n",
      " 78/938 [=>............................] - ETA: 3s - loss: 2.3119 - accuracy: 0.1026\n",
      "104/938 [==>...........................] - ETA: 3s - loss: 2.3127 - accuracy: 0.1017\n",
      "130/938 [===>..........................] - ETA: 3s - loss: 2.3112 - accuracy: 0.1038\n",
      "155/938 [===>..........................] - ETA: 3s - loss: 2.3111 - accuracy: 0.1035\n",
      "167/938 [====>.........................] - ETA: 3s - loss: 2.3111 - accuracy: 0.1025\n",
      "193/938 [=====>........................] - ETA: 3s - loss: 2.3103 - accuracy: 0.1035\n",
      "218/938 [=====>........................] - ETA: 2s - loss: 2.3105 - accuracy: 0.1021\n",
      "244/938 [======>.......................] - ETA: 2s - loss: 2.3100 - accuracy: 0.1017\n",
      "269/938 [=======>......................] - ETA: 2s - loss: 2.3107 - accuracy: 0.1010\n",
      "295/938 [========>.....................] - ETA: 2s - loss: 2.3105 - accuracy: 0.1013\n",
      "319/938 [=========>....................] - ETA: 2s - loss: 2.3104 - accuracy: 0.1020\n",
      "332/938 [=========>....................] - ETA: 2s - loss: 2.3101 - accuracy: 0.1017\n",
      "358/938 [==========>...................] - ETA: 2s - loss: 2.3098 - accuracy: 0.1024\n",
      "384/938 [===========>..................] - ETA: 2s - loss: 2.3101 - accuracy: 0.1036\n",
      "410/938 [============>.................] - ETA: 2s - loss: 2.3100 - accuracy: 0.1038\n",
      "436/938 [============>.................] - ETA: 2s - loss: 2.3101 - accuracy: 0.1028\n",
      "462/938 [=============>................] - ETA: 1s - loss: 2.3101 - accuracy: 0.1035\n",
      "487/938 [==============>...............] - ETA: 1s - loss: 2.3100 - accuracy: 0.1032\n",
      "512/938 [===============>..............] - ETA: 1s - loss: 2.3099 - accuracy: 0.1028\n",
      "525/938 [===============>..............] - ETA: 1s - loss: 2.3099 - accuracy: 0.1027\n",
      "552/938 [================>.............] - ETA: 1s - loss: 2.3098 - accuracy: 0.1024\n",
      "577/938 [=================>............] - ETA: 1s - loss: 2.3097 - accuracy: 0.1023\n",
      "602/938 [==================>...........] - ETA: 1s - loss: 2.3094 - accuracy: 0.1027\n",
      "627/938 [===================>..........] - ETA: 1s - loss: 2.3094 - accuracy: 0.1021\n",
      "653/938 [===================>..........] - ETA: 1s - loss: 2.3095 - accuracy: 0.1014\n",
      "679/938 [====================>.........] - ETA: 1s - loss: 2.3096 - accuracy: 0.1014\n",
      "705/938 [=====================>........] - ETA: 0s - loss: 2.3096 - accuracy: 0.1016\n",
      "744/938 [======================>.......] - ETA: 0s - loss: 2.3094 - accuracy: 0.1021\n",
      "770/938 [=======================>......] - ETA: 0s - loss: 2.3095 - accuracy: 0.1023\n",
      "795/938 [========================>.....] - ETA: 0s - loss: 2.3094 - accuracy: 0.1023\n",
      "820/938 [=========================>....] - ETA: 0s - loss: 2.3094 - accuracy: 0.1020\n",
      "844/938 [=========================>....] - ETA: 0s - loss: 2.3094 - accuracy: 0.1024\n",
      "870/938 [==========================>...] - ETA: 0s - loss: 2.3094 - accuracy: 0.1026\n",
      "895/938 [===========================>..] - ETA: 0s - loss: 2.3094 - accuracy: 0.1026\n",
      "908/938 [============================>.] - ETA: 0s - loss: 2.3093 - accuracy: 0.1028\n",
      "934/938 [============================>.] - ETA: 0s - loss: 2.3092 - accuracy: 0.1029\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 2.3092 - accuracy: 0.1028 - val_loss: 2.3047 - val_accuracy: 0.1135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=2626033)\u001b[0m 2023-12-05 09:46:19.333735: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=2626033)\u001b[0m 2023-12-05 09:46:19.373178: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=2626033)\u001b[0m 2023-12-05 09:46:19.373203: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=2626033)\u001b[0m 2023-12-05 09:46:19.374227: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=2626033)\u001b[0m 2023-12-05 09:46:19.380138: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=2626033)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=2626033)\u001b[0m 2023-12-05 09:46:20.080262: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=2626033)\u001b[0m 2023-12-05 09:46:21.493565: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_mnist pid=2626033)\u001b[0m Epoch 1/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_mnist pid=2626033)\u001b[0m 2023-12-05 09:46:23.191254: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=2626033)\u001b[0m 2023-12-05 09:46:24.204022: I external/local_xla/xla/service/service.cc:168] XLA service 0x15063553cbe0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=2626033)\u001b[0m 2023-12-05 09:46:24.204075: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=2626033)\u001b[0m 2023-12-05 09:46:24.212268: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=2626033)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=2626033)\u001b[0m I0000 00:00:1701787584.326535 2626358 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1/469 [..............................] - ETA: 17:58 - loss: 2.3066 - accuracy: 0.1016\n",
      " 20/469 [>.............................] - ETA: 2s - loss: 28.0685 - accuracy: 0.1066 \n",
      " 40/469 [=>............................] - ETA: 2s - loss: 15.1894 - accuracy: 0.1023\n",
      " 60/469 [==>...........................] - ETA: 2s - loss: 10.8950 - accuracy: 0.1007\n",
      " 81/469 [====>.........................] - ETA: 2s - loss: 8.6671 - accuracy: 0.1059\n",
      " 92/469 [====>.........................] - ETA: 1s - loss: 7.9065 - accuracy: 0.1052\n",
      "114/469 [======>.......................] - ETA: 1s - loss: 6.8258 - accuracy: 0.1042\n",
      "133/469 [=======>......................] - ETA: 1s - loss: 6.1801 - accuracy: 0.1061\n",
      "155/469 [========>.....................] - ETA: 1s - loss: 5.6298 - accuracy: 0.1063\n",
      "177/469 [==========>...................] - ETA: 1s - loss: 5.2168 - accuracy: 0.1058\n",
      "199/469 [===========>..................] - ETA: 1s - loss: 4.8951 - accuracy: 0.1063\n",
      "219/469 [=============>................] - ETA: 1s - loss: 4.6589 - accuracy: 0.1063\n",
      "239/469 [==============>...............] - ETA: 1s - loss: 4.4618 - accuracy: 0.1061\n",
      "260/469 [===============>..............] - ETA: 1s - loss: 4.2878 - accuracy: 0.1051\n",
      "280/469 [================>.............] - ETA: 0s - loss: 4.1462 - accuracy: 0.1054\n",
      "290/469 [=================>............] - ETA: 0s - loss: 4.0827 - accuracy: 0.1056\n",
      "311/469 [==================>...........] - ETA: 0s - loss: 3.9627 - accuracy: 0.1057\n",
      "330/469 [====================>.........] - ETA: 0s - loss: 3.8674 - accuracy: 0.1054\n",
      "350/469 [=====================>........] - ETA: 0s - loss: 3.7780 - accuracy: 0.1052\n",
      "371/469 [======================>.......] - ETA: 0s - loss: 3.6948 - accuracy: 0.1051\n",
      "391/469 [========================>.....] - ETA: 0s - loss: 3.6237 - accuracy: 0.1046\n",
      "411/469 [=========================>....] - ETA: 0s - loss: 3.5595 - accuracy: 0.1043\n",
      "433/469 [==========================>...] - ETA: 0s - loss: 3.4956 - accuracy: 0.1054\n",
      "444/469 [===========================>..] - ETA: 0s - loss: 3.4662 - accuracy: 0.1050\n",
      "464/469 [============================>.] - ETA: 0s - loss: 3.4163 - accuracy: 0.1044\n",
      "469/469 [==============================] - ETA: 0s - loss: 3.4050 - accuracy: 0.1044\n",
      "469/469 [==============================] - 5s 6ms/step - loss: 3.4050 - accuracy: 0.1044 - val_loss: 2.3027 - val_accuracy: 0.1135\n",
      "\u001b[36m(train_mnist pid=2626033)\u001b[0m Epoch 2/12\n",
      " 11/469 [..............................] - ETA: 2s - loss: 2.3079 - accuracy: 0.0966\n",
      " 31/469 [>.............................] - ETA: 2s - loss: 2.3064 - accuracy: 0.0988\n",
      " 51/469 [==>...........................] - ETA: 2s - loss: 2.3061 - accuracy: 0.1048\n",
      " 61/469 [==>...........................] - ETA: 2s - loss: 2.3061 - accuracy: 0.1031\n",
      " 82/469 [====>.........................] - ETA: 2s - loss: 2.3057 - accuracy: 0.1023\n",
      "103/469 [=====>........................] - ETA: 1s - loss: 2.3061 - accuracy: 0.1029\n",
      "123/469 [======>.......................] - ETA: 1s - loss: 2.3063 - accuracy: 0.1038\n",
      "143/469 [========>.....................] - ETA: 1s - loss: 2.3061 - accuracy: 0.1041\n",
      "163/469 [=========>....................] - ETA: 1s - loss: 2.3061 - accuracy: 0.1063\n",
      "185/469 [==========>...................] - ETA: 1s - loss: 2.3061 - accuracy: 0.1072\n",
      "206/469 [============>.................] - ETA: 1s - loss: 2.3060 - accuracy: 0.1066\n",
      "216/469 [============>.................] - ETA: 1s - loss: 2.3058 - accuracy: 0.1067\n",
      "236/469 [==============>...............] - ETA: 1s - loss: 2.3062 - accuracy: 0.1062\n",
      "257/469 [===============>..............] - ETA: 1s - loss: 2.3061 - accuracy: 0.1064\n",
      "277/469 [================>.............] - ETA: 0s - loss: 2.3064 - accuracy: 0.1051\n",
      "297/469 [=================>............] - ETA: 0s - loss: 2.3066 - accuracy: 0.1053\n",
      "317/469 [===================>..........] - ETA: 0s - loss: 2.3064 - accuracy: 0.1063\n",
      "337/469 [====================>.........] - ETA: 0s - loss: 2.3065 - accuracy: 0.1062\n",
      "358/469 [=====================>........] - ETA: 0s - loss: 2.3064 - accuracy: 0.1066\n",
      "368/469 [======================>.......] - ETA: 0s - loss: 2.3064 - accuracy: 0.1062\n",
      "390/469 [=======================>......] - ETA: 0s - loss: 2.3064 - accuracy: 0.1056\n",
      "410/469 [=========================>....] - ETA: 0s - loss: 2.3065 - accuracy: 0.1054\n",
      "431/469 [==========================>...] - ETA: 0s - loss: 2.3065 - accuracy: 0.1050\n",
      "452/469 [===========================>..] - ETA: 0s - loss: 2.3065 - accuracy: 0.1050\n",
      "462/469 [============================>.] - ETA: 0s - loss: 2.3065 - accuracy: 0.1048\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3064 - accuracy: 0.1051 - val_loss: 2.3059 - val_accuracy: 0.1135\n",
      "\u001b[36m(train_mnist pid=2626033)\u001b[0m Epoch 3/12\n",
      "  1/469 [..............................] - ETA: 2s - loss: 2.3033 - accuracy: 0.0938\n",
      " 23/469 [>.............................] - ETA: 2s - loss: 2.3102 - accuracy: 0.1053\n",
      " 43/469 [=>............................] - ETA: 2s - loss: 2.3079 - accuracy: 0.1056\n",
      " 53/469 [==>...........................] - ETA: 2s - loss: 2.3079 - accuracy: 0.1048\n",
      " 75/469 [===>..........................] - ETA: 1s - loss: 2.3080 - accuracy: 0.1066\n",
      " 96/469 [=====>........................] - ETA: 1s - loss: 2.3079 - accuracy: 0.1060\n",
      "117/469 [======>.......................] - ETA: 1s - loss: 2.3080 - accuracy: 0.1062\n",
      "136/469 [=======>......................] - ETA: 1s - loss: 2.3081 - accuracy: 0.1044\n",
      "156/469 [========>.....................] - ETA: 1s - loss: 2.3079 - accuracy: 0.1055\n",
      "176/469 [==========>...................] - ETA: 1s - loss: 2.3079 - accuracy: 0.1046\n",
      "197/469 [===========>..................] - ETA: 1s - loss: 2.3075 - accuracy: 0.1051\n",
      "217/469 [============>.................] - ETA: 1s - loss: 2.3074 - accuracy: 0.1049\n",
      "238/469 [==============>...............] - ETA: 1s - loss: 2.3073 - accuracy: 0.1063\n",
      "258/469 [===============>..............] - ETA: 1s - loss: 2.3071 - accuracy: 0.1061\n",
      "269/469 [================>.............] - ETA: 1s - loss: 2.3070 - accuracy: 0.1056\n",
      "289/469 [=================>............] - ETA: 0s - loss: 2.3067 - accuracy: 0.1058\n",
      "309/469 [==================>...........] - ETA: 0s - loss: 2.3068 - accuracy: 0.1056\n",
      "329/469 [====================>.........] - ETA: 0s - loss: 2.3067 - accuracy: 0.1065\n",
      "351/469 [=====================>........] - ETA: 0s - loss: 2.3068 - accuracy: 0.1060\n",
      "373/469 [======================>.......] - ETA: 0s - loss: 2.3067 - accuracy: 0.1058\n",
      "395/469 [========================>.....] - ETA: 0s - loss: 2.3067 - accuracy: 0.1060\n",
      "417/469 [=========================>....] - ETA: 0s - loss: 2.3067 - accuracy: 0.1058\n",
      "439/469 [===========================>..] - ETA: 0s - loss: 2.3068 - accuracy: 0.1059\n",
      "461/469 [============================>.] - ETA: 0s - loss: 2.3068 - accuracy: 0.1057\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3068 - accuracy: 0.1058 - val_loss: 2.3058 - val_accuracy: 0.1135\n",
      "\u001b[36m(train_mnist pid=2626033)\u001b[0m Epoch 4/12\n",
      " 10/469 [..............................] - ETA: 2s - loss: 2.3052 - accuracy: 0.1047\n",
      " 30/469 [>.............................] - ETA: 2s - loss: 2.3063 - accuracy: 0.0971\n",
      " 41/469 [=>............................] - ETA: 2s - loss: 2.3058 - accuracy: 0.1018\n",
      " 62/469 [==>...........................] - ETA: 2s - loss: 2.3057 - accuracy: 0.1026\n",
      " 82/469 [====>.........................] - ETA: 1s - loss: 2.3049 - accuracy: 0.1033\n",
      "102/469 [=====>........................] - ETA: 1s - loss: 2.3046 - accuracy: 0.1051\n",
      "121/469 [======>.......................] - ETA: 1s - loss: 2.3054 - accuracy: 0.1055\n",
      "141/469 [========>.....................] - ETA: 1s - loss: 2.3054 - accuracy: 0.1058\n",
      "162/469 [=========>....................] - ETA: 1s - loss: 2.3060 - accuracy: 0.1038\n",
      "181/469 [==========>...................] - ETA: 1s - loss: 2.3062 - accuracy: 0.1043\n",
      "190/469 [===========>..................] - ETA: 1s - loss: 2.3064 - accuracy: 0.1042\n",
      "211/469 [============>.................] - ETA: 1s - loss: 2.3066 - accuracy: 0.1045\n",
      "231/469 [=============>................] - ETA: 1s - loss: 2.3065 - accuracy: 0.1042\n",
      "252/469 [===============>..............] - ETA: 1s - loss: 2.3066 - accuracy: 0.1043\n",
      "273/469 [================>.............] - ETA: 1s - loss: 2.3067 - accuracy: 0.1038\n",
      "293/469 [=================>............] - ETA: 0s - loss: 2.3067 - accuracy: 0.1041\n",
      "313/469 [===================>..........] - ETA: 0s - loss: 2.3066 - accuracy: 0.1054\n",
      "333/469 [====================>.........] - ETA: 0s - loss: 2.3067 - accuracy: 0.1053\n",
      "364/469 [======================>.......] - ETA: 0s - loss: 2.3068 - accuracy: 0.1050\n",
      "385/469 [=======================>......] - ETA: 0s - loss: 2.3067 - accuracy: 0.1051\n",
      "405/469 [========================>.....] - ETA: 0s - loss: 2.3067 - accuracy: 0.1047\n",
      "425/469 [==========================>...] - ETA: 0s - loss: 2.3068 - accuracy: 0.1039\n",
      "445/469 [===========================>..] - ETA: 0s - loss: 2.3068 - accuracy: 0.1040\n",
      "466/469 [============================>.] - ETA: 0s - loss: 2.3069 - accuracy: 0.1035\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3069 - accuracy: 0.1035 - val_loss: 2.3047 - val_accuracy: 0.1135\n",
      "\u001b[36m(train_mnist pid=2626033)\u001b[0m Epoch 5/12\n",
      "  1/469 [..............................] - ETA: 2s - loss: 2.3049 - accuracy: 0.1250\n",
      " 22/469 [>.............................] - ETA: 2s - loss: 2.3081 - accuracy: 0.1048\n",
      " 44/469 [=>............................] - ETA: 2s - loss: 2.3061 - accuracy: 0.1096\n",
      " 65/469 [===>..........................] - ETA: 1s - loss: 2.3054 - accuracy: 0.1123\n",
      " 85/469 [====>.........................] - ETA: 1s - loss: 2.3055 - accuracy: 0.1124\n",
      "105/469 [=====>........................] - ETA: 1s - loss: 2.3050 - accuracy: 0.1122\n",
      "125/469 [======>.......................] - ETA: 1s - loss: 2.3051 - accuracy: 0.1094\n",
      "146/469 [========>.....................] - ETA: 1s - loss: 2.3054 - accuracy: 0.1087\n",
      "166/469 [=========>....................] - ETA: 1s - loss: 2.3056 - accuracy: 0.1084\n",
      "176/469 [==========>...................] - ETA: 1s - loss: 2.3056 - accuracy: 0.1076\n",
      "197/469 [===========>..................] - ETA: 1s - loss: 2.3059 - accuracy: 0.1072\n",
      "217/469 [============>.................] - ETA: 1s - loss: 2.3061 - accuracy: 0.1058\n",
      "237/469 [==============>...............] - ETA: 1s - loss: 2.3066 - accuracy: 0.1047\n",
      "257/469 [===============>..............] - ETA: 1s - loss: 2.3064 - accuracy: 0.1051\n",
      "278/469 [================>.............] - ETA: 0s - loss: 2.3064 - accuracy: 0.1058\n",
      "299/469 [==================>...........] - ETA: 0s - loss: 2.3065 - accuracy: 0.1062\n",
      "309/469 [==================>...........] - ETA: 0s - loss: 2.3066 - accuracy: 0.1061\n",
      "330/469 [====================>.........] - ETA: 0s - loss: 2.3067 - accuracy: 0.1055\n",
      "350/469 [=====================>........] - ETA: 0s - loss: 2.3067 - accuracy: 0.1050\n",
      "372/469 [======================>.......] - ETA: 0s - loss: 2.3066 - accuracy: 0.1050\n",
      "393/469 [========================>.....] - ETA: 0s - loss: 2.3067 - accuracy: 0.1050\n",
      "413/469 [=========================>....] - ETA: 0s - loss: 2.3066 - accuracy: 0.1050\n",
      "434/469 [==========================>...] - ETA: 0s - loss: 2.3067 - accuracy: 0.1051\n",
      "455/469 [============================>.] - ETA: 0s - loss: 2.3069 - accuracy: 0.1048\n",
      "465/469 [============================>.] - ETA: 0s - loss: 2.3069 - accuracy: 0.1046\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3068 - accuracy: 0.1050 - val_loss: 2.3047 - val_accuracy: 0.1135\n",
      "\u001b[36m(train_mnist pid=2626033)\u001b[0m Epoch 6/12\n",
      " 12/469 [..............................] - ETA: 2s - loss: 2.3065 - accuracy: 0.1198\n",
      " 33/469 [=>............................] - ETA: 2s - loss: 2.3068 - accuracy: 0.1054\n",
      " 54/469 [==>...........................] - ETA: 2s - loss: 2.3084 - accuracy: 0.1030\n",
      " 74/469 [===>..........................] - ETA: 1s - loss: 2.3075 - accuracy: 0.1058\n",
      " 95/469 [=====>........................] - ETA: 1s - loss: 2.3073 - accuracy: 0.1055\n",
      "115/469 [======>.......................] - ETA: 1s - loss: 2.3069 - accuracy: 0.1054\n",
      "136/469 [=======>......................] - ETA: 1s - loss: 2.3070 - accuracy: 0.1048\n",
      "156/469 [========>.....................] - ETA: 1s - loss: 2.3072 - accuracy: 0.1055\n",
      "166/469 [=========>....................] - ETA: 1s - loss: 2.3071 - accuracy: 0.1055\n",
      "186/469 [==========>...................] - ETA: 1s - loss: 2.3070 - accuracy: 0.1061\n",
      "207/469 [============>.................] - ETA: 1s - loss: 2.3068 - accuracy: 0.1064\n",
      "227/469 [=============>................] - ETA: 1s - loss: 2.3069 - accuracy: 0.1067\n",
      "248/469 [==============>...............] - ETA: 1s - loss: 2.3067 - accuracy: 0.1070\n",
      "269/469 [================>.............] - ETA: 1s - loss: 2.3068 - accuracy: 0.1064\n",
      "289/469 [=================>............] - ETA: 0s - loss: 2.3066 - accuracy: 0.1071\n",
      "308/469 [==================>...........] - ETA: 0s - loss: 2.3063 - accuracy: 0.1077\n",
      "318/469 [===================>..........] - ETA: 0s - loss: 2.3064 - accuracy: 0.1076\n",
      "328/469 [===================>..........] - ETA: 0s - loss: 2.3064 - accuracy: 0.1070\n",
      "338/469 [====================>.........] - ETA: 0s - loss: 2.3065 - accuracy: 0.1068\n",
      "358/469 [=====================>........] - ETA: 0s - loss: 2.3066 - accuracy: 0.1060\n",
      "378/469 [=======================>......] - ETA: 0s - loss: 2.3067 - accuracy: 0.1062\n",
      "397/469 [========================>.....] - ETA: 0s - loss: 2.3065 - accuracy: 0.1063\n",
      "418/469 [=========================>....] - ETA: 0s - loss: 2.3066 - accuracy: 0.1063\n",
      "437/469 [==========================>...] - ETA: 0s - loss: 2.3066 - accuracy: 0.1062\n",
      "458/469 [============================>.] - ETA: 0s - loss: 2.3066 - accuracy: 0.1055\n",
      "468/469 [============================>.] - ETA: 0s - loss: 2.3066 - accuracy: 0.1055\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3066 - accuracy: 0.1053 - val_loss: 2.3041 - val_accuracy: 0.1028\n",
      "\u001b[36m(train_mnist pid=2626033)\u001b[0m Epoch 7/12\n",
      " 10/469 [..............................] - ETA: 2s - loss: 2.3023 - accuracy: 0.0945\n",
      " 30/469 [>.............................] - ETA: 2s - loss: 2.3065 - accuracy: 0.1052\n",
      " 41/469 [=>............................] - ETA: 2s - loss: 2.3073 - accuracy: 0.1021\n",
      " 62/469 [==>...........................] - ETA: 2s - loss: 2.3072 - accuracy: 0.0983\n",
      " 82/469 [====>.........................] - ETA: 1s - loss: 2.3078 - accuracy: 0.1017\n",
      "102/469 [=====>........................] - ETA: 1s - loss: 2.3076 - accuracy: 0.1026\n",
      "123/469 [======>.......................] - ETA: 1s - loss: 2.3076 - accuracy: 0.1044\n",
      "145/469 [========>.....................] - ETA: 1s - loss: 2.3083 - accuracy: 0.1032\n",
      "166/469 [=========>....................] - ETA: 1s - loss: 2.3080 - accuracy: 0.1037\n",
      "176/469 [==========>...................] - ETA: 1s - loss: 2.3081 - accuracy: 0.1034\n",
      "197/469 [===========>..................] - ETA: 1s - loss: 2.3077 - accuracy: 0.1053\n",
      "218/469 [============>.................] - ETA: 1s - loss: 2.3079 - accuracy: 0.1046\n",
      "239/469 [==============>...............] - ETA: 1s - loss: 2.3079 - accuracy: 0.1041\n",
      "259/469 [===============>..............] - ETA: 1s - loss: 2.3077 - accuracy: 0.1033\n",
      "278/469 [================>.............] - ETA: 0s - loss: 2.3075 - accuracy: 0.1039\n",
      "300/469 [==================>...........] - ETA: 0s - loss: 2.3074 - accuracy: 0.1038\n",
      "319/469 [===================>..........] - ETA: 0s - loss: 2.3075 - accuracy: 0.1040\n",
      "340/469 [====================>.........] - ETA: 0s - loss: 2.3075 - accuracy: 0.1045\n",
      "361/469 [======================>.......] - ETA: 0s - loss: 2.3076 - accuracy: 0.1043\n",
      "382/469 [=======================>......] - ETA: 0s - loss: 2.3074 - accuracy: 0.1043\n",
      "402/469 [========================>.....] - ETA: 0s - loss: 2.3074 - accuracy: 0.1044\n",
      "413/469 [=========================>....] - ETA: 0s - loss: 2.3074 - accuracy: 0.1046\n",
      "435/469 [==========================>...] - ETA: 0s - loss: 2.3074 - accuracy: 0.1044\n",
      "456/469 [============================>.] - ETA: 0s - loss: 2.3073 - accuracy: 0.1047\n",
      "466/469 [============================>.] - ETA: 0s - loss: 2.3073 - accuracy: 0.1046\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3073 - accuracy: 0.1046 - val_loss: 2.3056 - val_accuracy: 0.1135\n",
      "\u001b[36m(train_mnist pid=2626033)\u001b[0m Epoch 8/12\n",
      "  1/469 [..............................] - ETA: 2s - loss: 2.3092 - accuracy: 0.0859\n",
      " 11/469 [..............................] - ETA: 2s - loss: 2.3054 - accuracy: 0.1122\n",
      " 31/469 [>.............................] - ETA: 2s - loss: 2.3073 - accuracy: 0.1076\n",
      " 50/469 [==>...........................] - ETA: 2s - loss: 2.3063 - accuracy: 0.1098\n",
      " 72/469 [===>..........................] - ETA: 2s - loss: 2.3073 - accuracy: 0.1077\n",
      " 92/469 [====>.........................] - ETA: 1s - loss: 2.3081 - accuracy: 0.1073\n",
      "113/469 [======>.......................] - ETA: 1s - loss: 2.3081 - accuracy: 0.1071\n",
      "133/469 [=======>......................] - ETA: 1s - loss: 2.3087 - accuracy: 0.1057\n",
      "153/469 [========>.....................] - ETA: 1s - loss: 2.3098 - accuracy: 0.1055\n",
      "173/469 [==========>...................] - ETA: 1s - loss: 2.3099 - accuracy: 0.1051\n",
      "184/469 [==========>...................] - ETA: 1s - loss: 2.3098 - accuracy: 0.1048\n",
      "204/469 [============>.................] - ETA: 1s - loss: 2.3097 - accuracy: 0.1040\n",
      "224/469 [=============>................] - ETA: 1s - loss: 2.3096 - accuracy: 0.1042\n",
      "244/469 [==============>...............] - ETA: 1s - loss: 2.3092 - accuracy: 0.1047\n",
      "264/469 [===============>..............] - ETA: 1s - loss: 2.3092 - accuracy: 0.1042\n",
      "283/469 [=================>............] - ETA: 0s - loss: 2.3092 - accuracy: 0.1036\n",
      "304/469 [==================>...........] - ETA: 0s - loss: 2.3093 - accuracy: 0.1035\n",
      "334/469 [====================>.........] - ETA: 0s - loss: 2.3093 - accuracy: 0.1030\n",
      "355/469 [=====================>........] - ETA: 0s - loss: 2.3090 - accuracy: 0.1036\n",
      "376/469 [=======================>......] - ETA: 0s - loss: 2.3089 - accuracy: 0.1034\n",
      "396/469 [========================>.....] - ETA: 0s - loss: 2.3087 - accuracy: 0.1037\n",
      "417/469 [=========================>....] - ETA: 0s - loss: 2.3086 - accuracy: 0.1043\n",
      "437/469 [==========================>...] - ETA: 0s - loss: 2.3084 - accuracy: 0.1049\n",
      "456/469 [============================>.] - ETA: 0s - loss: 2.3083 - accuracy: 0.1050\n",
      "466/469 [============================>.] - ETA: 0s - loss: 2.3083 - accuracy: 0.1049\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3083 - accuracy: 0.1048 - val_loss: 2.3100 - val_accuracy: 0.0958\n",
      "\u001b[36m(train_mnist pid=2626033)\u001b[0m Epoch 9/12\n",
      " 12/469 [..............................] - ETA: 2s - loss: 2.3083 - accuracy: 0.1126\n",
      " 32/469 [=>............................] - ETA: 2s - loss: 2.3050 - accuracy: 0.1235\n",
      " 43/469 [=>............................] - ETA: 2s - loss: 2.3069 - accuracy: 0.1185\n",
      " 64/469 [===>..........................] - ETA: 2s - loss: 2.3073 - accuracy: 0.1101\n",
      " 85/469 [====>.........................] - ETA: 1s - loss: 2.3077 - accuracy: 0.1082\n",
      "106/469 [=====>........................] - ETA: 1s - loss: 2.3071 - accuracy: 0.1072\n",
      "127/469 [=======>......................] - ETA: 1s - loss: 2.3074 - accuracy: 0.1064\n",
      "149/469 [========>.....................] - ETA: 1s - loss: 2.3070 - accuracy: 0.1069\n",
      "170/469 [=========>....................] - ETA: 1s - loss: 2.3080 - accuracy: 0.1051\n",
      "192/469 [===========>..................] - ETA: 1s - loss: 2.3080 - accuracy: 0.1052\n",
      "212/469 [============>.................] - ETA: 1s - loss: 2.3080 - accuracy: 0.1044\n",
      "222/469 [=============>................] - ETA: 1s - loss: 2.3078 - accuracy: 0.1042\n",
      "243/469 [==============>...............] - ETA: 1s - loss: 2.3078 - accuracy: 0.1042\n",
      "262/469 [===============>..............] - ETA: 1s - loss: 2.3079 - accuracy: 0.1045\n",
      "282/469 [=================>............] - ETA: 0s - loss: 2.3077 - accuracy: 0.1054\n",
      "304/469 [==================>...........] - ETA: 0s - loss: 2.3074 - accuracy: 0.1052\n",
      "325/469 [===================>..........] - ETA: 0s - loss: 2.3077 - accuracy: 0.1054\n",
      "345/469 [=====================>........] - ETA: 0s - loss: 2.3079 - accuracy: 0.1053\n",
      "366/469 [======================>.......] - ETA: 0s - loss: 2.3077 - accuracy: 0.1051\n",
      "376/469 [=======================>......] - ETA: 0s - loss: 2.3078 - accuracy: 0.1045\n",
      "396/469 [========================>.....] - ETA: 0s - loss: 2.3077 - accuracy: 0.1054\n",
      "417/469 [=========================>....] - ETA: 0s - loss: 2.3079 - accuracy: 0.1054\n",
      "439/469 [===========================>..] - ETA: 0s - loss: 2.3080 - accuracy: 0.1047\n",
      "458/469 [============================>.] - ETA: 0s - loss: 2.3079 - accuracy: 0.1045\n",
      "468/469 [============================>.] - ETA: 0s - loss: 2.3079 - accuracy: 0.1045\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3079 - accuracy: 0.1045 - val_loss: 2.3163 - val_accuracy: 0.0958\n",
      "\u001b[36m(train_mnist pid=2626033)\u001b[0m Epoch 10/12\n",
      " 12/469 [..............................] - ETA: 2s - loss: 2.3102 - accuracy: 0.1035\n",
      " 32/469 [=>............................] - ETA: 2s - loss: 2.3076 - accuracy: 0.0999\n",
      " 54/469 [==>...........................] - ETA: 2s - loss: 2.3073 - accuracy: 0.1059\n",
      " 74/469 [===>..........................] - ETA: 2s - loss: 2.3078 - accuracy: 0.1054\n",
      " 94/469 [=====>........................] - ETA: 1s - loss: 2.3074 - accuracy: 0.1066\n",
      "105/469 [=====>........................] - ETA: 1s - loss: 2.3068 - accuracy: 0.1076\n",
      "126/469 [=======>......................] - ETA: 1s - loss: 2.3073 - accuracy: 0.1068\n",
      "148/469 [========>.....................] - ETA: 1s - loss: 2.3078 - accuracy: 0.1054\n",
      "170/469 [=========>....................] - ETA: 1s - loss: 2.3073 - accuracy: 0.1047\n",
      "192/469 [===========>..................] - ETA: 1s - loss: 2.3074 - accuracy: 0.1039\n",
      "213/469 [============>.................] - ETA: 1s - loss: 2.3074 - accuracy: 0.1041\n",
      "234/469 [=============>................] - ETA: 1s - loss: 2.3072 - accuracy: 0.1050\n",
      "255/469 [===============>..............] - ETA: 1s - loss: 2.3074 - accuracy: 0.1044\n",
      "277/469 [================>.............] - ETA: 0s - loss: 2.3074 - accuracy: 0.1043\n",
      "287/469 [=================>............] - ETA: 0s - loss: 2.3074 - accuracy: 0.1050\n",
      "307/469 [==================>...........] - ETA: 0s - loss: 2.3074 - accuracy: 0.1045\n",
      "327/469 [===================>..........] - ETA: 0s - loss: 2.3073 - accuracy: 0.1044\n",
      "348/469 [=====================>........] - ETA: 0s - loss: 2.3074 - accuracy: 0.1039\n",
      "369/469 [======================>.......] - ETA: 0s - loss: 2.3073 - accuracy: 0.1041\n",
      "390/469 [=======================>......] - ETA: 0s - loss: 2.3074 - accuracy: 0.1038\n",
      "411/469 [=========================>....] - ETA: 0s - loss: 2.3075 - accuracy: 0.1034\n",
      "431/469 [==========================>...] - ETA: 0s - loss: 2.3074 - accuracy: 0.1039\n",
      "450/469 [===========================>..] - ETA: 0s - loss: 2.3074 - accuracy: 0.1045\n",
      "460/469 [============================>.] - ETA: 0s - loss: 2.3074 - accuracy: 0.1043\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3073 - accuracy: 0.1043 - val_loss: 2.3039 - val_accuracy: 0.1135\n",
      "\u001b[36m(train_mnist pid=2626033)\u001b[0m Epoch 11/12\n",
      "  1/469 [..............................] - ETA: 2s - loss: 2.2878 - accuracy: 0.1484\n",
      " 10/469 [..............................] - ETA: 2s - loss: 2.3065 - accuracy: 0.1023\n",
      " 32/469 [=>............................] - ETA: 2s - loss: 2.3068 - accuracy: 0.1077\n",
      " 53/469 [==>...........................] - ETA: 2s - loss: 2.3092 - accuracy: 0.1041\n",
      " 74/469 [===>..........................] - ETA: 2s - loss: 2.3087 - accuracy: 0.1028\n",
      " 96/469 [=====>........................] - ETA: 1s - loss: 2.3087 - accuracy: 0.1011\n",
      "117/469 [======>.......................] - ETA: 1s - loss: 2.3087 - accuracy: 0.1024\n",
      "137/469 [=======>......................] - ETA: 1s - loss: 2.3082 - accuracy: 0.1029\n",
      "156/469 [========>.....................] - ETA: 1s - loss: 2.3083 - accuracy: 0.1013\n",
      "177/469 [==========>...................] - ETA: 1s - loss: 2.3079 - accuracy: 0.1024\n",
      "199/469 [===========>..................] - ETA: 1s - loss: 2.3078 - accuracy: 0.1028\n",
      "209/469 [============>.................] - ETA: 1s - loss: 2.3080 - accuracy: 0.1026\n",
      "229/469 [=============>................] - ETA: 1s - loss: 2.3080 - accuracy: 0.1022\n",
      "250/469 [==============>...............] - ETA: 1s - loss: 2.3078 - accuracy: 0.1026\n",
      "271/469 [================>.............] - ETA: 1s - loss: 2.3078 - accuracy: 0.1027\n",
      "292/469 [=================>............] - ETA: 0s - loss: 2.3077 - accuracy: 0.1037\n",
      "312/469 [==================>...........] - ETA: 0s - loss: 2.3078 - accuracy: 0.1035\n",
      "333/469 [====================>.........] - ETA: 0s - loss: 2.3078 - accuracy: 0.1034\n",
      "353/469 [=====================>........] - ETA: 0s - loss: 2.3076 - accuracy: 0.1031\n",
      "373/469 [======================>.......] - ETA: 0s - loss: 2.3075 - accuracy: 0.1030\n",
      "393/469 [========================>.....] - ETA: 0s - loss: 2.3075 - accuracy: 0.1031\n",
      "403/469 [========================>.....] - ETA: 0s - loss: 2.3074 - accuracy: 0.1032\n",
      "423/469 [==========================>...] - ETA: 0s - loss: 2.3073 - accuracy: 0.1038\n",
      "441/469 [===========================>..] - ETA: 0s - loss: 2.3072 - accuracy: 0.1043\n",
      "461/469 [============================>.] - ETA: 0s - loss: 2.3070 - accuracy: 0.1040\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3071 - accuracy: 0.1040 - val_loss: 2.3131 - val_accuracy: 0.0958\n",
      "\u001b[36m(train_mnist pid=2626033)\u001b[0m Epoch 12/12\n",
      " 11/469 [..............................] - ETA: 2s - loss: 2.3049 - accuracy: 0.1051\n",
      " 32/469 [=>............................] - ETA: 2s - loss: 2.3066 - accuracy: 0.1067\n",
      " 43/469 [=>............................] - ETA: 2s - loss: 2.3085 - accuracy: 0.1045\n",
      " 63/469 [===>..........................] - ETA: 2s - loss: 2.3084 - accuracy: 0.1075\n",
      " 85/469 [====>.........................] - ETA: 1s - loss: 2.3078 - accuracy: 0.1091\n",
      "105/469 [=====>........................] - ETA: 1s - loss: 2.3081 - accuracy: 0.1072\n",
      "125/469 [======>.......................] - ETA: 1s - loss: 2.3079 - accuracy: 0.1085\n",
      "147/469 [========>.....................] - ETA: 1s - loss: 2.3083 - accuracy: 0.1070\n",
      "167/469 [=========>....................] - ETA: 1s - loss: 2.3081 - accuracy: 0.1064\n",
      "188/469 [===========>..................] - ETA: 1s - loss: 2.3081 - accuracy: 0.1059\n",
      "209/469 [============>.................] - ETA: 1s - loss: 2.3083 - accuracy: 0.1043\n",
      "219/469 [=============>................] - ETA: 1s - loss: 2.3083 - accuracy: 0.1045\n",
      "240/469 [==============>...............] - ETA: 1s - loss: 2.3082 - accuracy: 0.1054\n",
      "261/469 [===============>..............] - ETA: 1s - loss: 2.3081 - accuracy: 0.1053\n",
      "281/469 [================>.............] - ETA: 0s - loss: 2.3079 - accuracy: 0.1058\n",
      "301/469 [==================>...........] - ETA: 0s - loss: 2.3078 - accuracy: 0.1057\n",
      "321/469 [===================>..........] - ETA: 0s - loss: 2.3075 - accuracy: 0.1057\n",
      "342/469 [====================>.........] - ETA: 0s - loss: 2.3074 - accuracy: 0.1056\n",
      "362/469 [======================>.......] - ETA: 0s - loss: 2.3074 - accuracy: 0.1055\n",
      "383/469 [=======================>......] - ETA: 0s - loss: 2.3074 - accuracy: 0.1053\n",
      "393/469 [========================>.....] - ETA: 0s - loss: 2.3074 - accuracy: 0.1057\n",
      "414/469 [=========================>....] - ETA: 0s - loss: 2.3074 - accuracy: 0.1057\n",
      "434/469 [==========================>...] - ETA: 0s - loss: 2.3074 - accuracy: 0.1061\n",
      "454/469 [============================>.] - ETA: 0s - loss: 2.3074 - accuracy: 0.1061\n",
      "464/469 [============================>.] - ETA: 0s - loss: 2.3075 - accuracy: 0.1062\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3075 - accuracy: 0.1063 - val_loss: 2.3078 - val_accuracy: 0.1010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=2628692)\u001b[0m 2023-12-05 09:46:59.393135: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=2628692)\u001b[0m 2023-12-05 09:46:59.432068: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=2628692)\u001b[0m 2023-12-05 09:46:59.432092: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=2628692)\u001b[0m 2023-12-05 09:46:59.433131: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=2628692)\u001b[0m 2023-12-05 09:46:59.438990: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=2628692)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=2628692)\u001b[0m 2023-12-05 09:47:00.141829: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=2628692)\u001b[0m 2023-12-05 09:47:01.459016: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_mnist pid=2628692)\u001b[0m Epoch 1/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_mnist pid=2628692)\u001b[0m 2023-12-05 09:47:03.163106: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=2628692)\u001b[0m 2023-12-05 09:47:04.169716: I external/local_xla/xla/service/service.cc:168] XLA service 0x148b7dd153a0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=2628692)\u001b[0m 2023-12-05 09:47:04.169742: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=2628692)\u001b[0m 2023-12-05 09:47:04.175343: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=2628692)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=2628692)\u001b[0m I0000 00:00:1701787624.290322 2629239 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1/235 [..............................] - ETA: 8:56 - loss: 2.3047 - accuracy: 0.0859\n",
      " 29/235 [==>...........................] - ETA: 1s - loss: 2.0288 - accuracy: 0.4535\n",
      " 48/235 [=====>........................] - ETA: 1s - loss: 1.4468 - accuracy: 0.5966\n",
      " 68/235 [=======>......................] - ETA: 0s - loss: 1.1493 - accuracy: 0.6751\n",
      " 88/235 [==========>...................] - ETA: 0s - loss: 0.9694 - accuracy: 0.7227\n",
      "108/235 [============>.................] - ETA: 0s - loss: 0.8537 - accuracy: 0.7538\n",
      "128/235 [===============>..............] - ETA: 0s - loss: 0.7692 - accuracy: 0.7769\n",
      "157/235 [===================>..........] - ETA: 0s - loss: 0.6861 - accuracy: 0.7990\n",
      "177/235 [=====================>........] - ETA: 0s - loss: 0.6433 - accuracy: 0.8103\n",
      "197/235 [========================>.....] - ETA: 0s - loss: 0.6071 - accuracy: 0.8204\n",
      "215/235 [==========================>...] - ETA: 0s - loss: 0.5779 - accuracy: 0.8283\n",
      "233/235 [============================>.] - ETA: 0s - loss: 0.5546 - accuracy: 0.8347\n",
      "235/235 [==============================] - ETA: 0s - loss: 0.5529 - accuracy: 0.8353\n",
      "235/235 [==============================] - 4s 7ms/step - loss: 0.5529 - accuracy: 0.8353 - val_loss: 0.2108 - val_accuracy: 0.9321\n",
      "\u001b[36m(train_mnist pid=2628692)\u001b[0m Epoch 2/12\n",
      "  1/235 [..............................] - ETA: 1s - loss: 0.2874 - accuracy: 0.9062\n",
      " 20/235 [=>............................] - ETA: 1s - loss: 0.2498 - accuracy: 0.9223\n",
      " 39/235 [===>..........................] - ETA: 1s - loss: 0.2500 - accuracy: 0.9197\n",
      " 59/235 [======>.......................] - ETA: 0s - loss: 0.2522 - accuracy: 0.9211\n",
      " 79/235 [=========>....................] - ETA: 0s - loss: 0.2485 - accuracy: 0.9221\n",
      " 99/235 [===========>..................] - ETA: 0s - loss: 0.2442 - accuracy: 0.9235\n",
      "109/235 [============>.................] - ETA: 0s - loss: 0.2450 - accuracy: 0.9227\n",
      "129/235 [===============>..............] - ETA: 0s - loss: 0.2420 - accuracy: 0.9234\n",
      "149/235 [==================>...........] - ETA: 0s - loss: 0.2396 - accuracy: 0.9237\n",
      "169/235 [====================>.........] - ETA: 0s - loss: 0.2402 - accuracy: 0.9238\n",
      "190/235 [=======================>......] - ETA: 0s - loss: 0.2384 - accuracy: 0.9245\n",
      "210/235 [=========================>....] - ETA: 0s - loss: 0.2376 - accuracy: 0.9250\n",
      "230/235 [============================>.] - ETA: 0s - loss: 0.2374 - accuracy: 0.9252\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.2378 - accuracy: 0.9251 - val_loss: 0.1726 - val_accuracy: 0.9448\n",
      "\u001b[36m(train_mnist pid=2628692)\u001b[0m Epoch 3/12\n",
      " 11/235 [>.............................] - ETA: 1s - loss: 0.2161 - accuracy: 0.9215\n",
      " 31/235 [==>...........................] - ETA: 1s - loss: 0.2087 - accuracy: 0.9309\n",
      " 51/235 [=====>........................] - ETA: 0s - loss: 0.2074 - accuracy: 0.9320\n",
      " 71/235 [========>.....................] - ETA: 0s - loss: 0.2070 - accuracy: 0.9324\n",
      " 90/235 [==========>...................] - ETA: 0s - loss: 0.2059 - accuracy: 0.9342\n",
      "100/235 [===========>..................] - ETA: 0s - loss: 0.2046 - accuracy: 0.9347\n",
      "120/235 [==============>...............] - ETA: 0s - loss: 0.2045 - accuracy: 0.9352\n",
      "138/235 [================>.............] - ETA: 0s - loss: 0.2031 - accuracy: 0.9355\n",
      "157/235 [===================>..........] - ETA: 0s - loss: 0.2035 - accuracy: 0.9358\n",
      "177/235 [=====================>........] - ETA: 0s - loss: 0.2019 - accuracy: 0.9366\n",
      "197/235 [========================>.....] - ETA: 0s - loss: 0.2031 - accuracy: 0.9362\n",
      "216/235 [==========================>...] - ETA: 0s - loss: 0.2051 - accuracy: 0.9358\n",
      "226/235 [===========================>..] - ETA: 0s - loss: 0.2047 - accuracy: 0.9360\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.2048 - accuracy: 0.9360 - val_loss: 0.1612 - val_accuracy: 0.9492\n",
      "\u001b[36m(train_mnist pid=2628692)\u001b[0m Epoch 4/12\n",
      "  1/235 [..............................] - ETA: 1s - loss: 0.1574 - accuracy: 0.9492\n",
      " 21/235 [=>............................] - ETA: 1s - loss: 0.1768 - accuracy: 0.9435\n",
      " 41/235 [====>.........................] - ETA: 1s - loss: 0.1804 - accuracy: 0.9416\n",
      " 51/235 [=====>........................] - ETA: 0s - loss: 0.1787 - accuracy: 0.9422\n",
      " 71/235 [========>.....................] - ETA: 0s - loss: 0.1802 - accuracy: 0.9408\n",
      " 89/235 [==========>...................] - ETA: 0s - loss: 0.1804 - accuracy: 0.9404\n",
      "107/235 [============>.................] - ETA: 0s - loss: 0.1840 - accuracy: 0.9392\n",
      "128/235 [===============>..............] - ETA: 0s - loss: 0.1830 - accuracy: 0.9395\n",
      "147/235 [=================>............] - ETA: 0s - loss: 0.1827 - accuracy: 0.9398\n",
      "167/235 [====================>.........] - ETA: 0s - loss: 0.1833 - accuracy: 0.9402\n",
      "187/235 [======================>.......] - ETA: 0s - loss: 0.1837 - accuracy: 0.9402\n",
      "207/235 [=========================>....] - ETA: 0s - loss: 0.1843 - accuracy: 0.9397\n",
      "227/235 [===========================>..] - ETA: 0s - loss: 0.1847 - accuracy: 0.9395\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.1845 - accuracy: 0.9396 - val_loss: 0.1535 - val_accuracy: 0.9507\n",
      "\u001b[36m(train_mnist pid=2628692)\u001b[0m Epoch 5/12\n",
      " 11/235 [>.............................] - ETA: 1s - loss: 0.1793 - accuracy: 0.9460\n",
      " 31/235 [==>...........................] - ETA: 1s - loss: 0.1784 - accuracy: 0.9448\n",
      " 50/235 [=====>........................] - ETA: 0s - loss: 0.1752 - accuracy: 0.9449\n",
      " 59/235 [======>.......................] - ETA: 0s - loss: 0.1750 - accuracy: 0.9449\n",
      " 78/235 [========>.....................] - ETA: 0s - loss: 0.1769 - accuracy: 0.9441\n",
      " 98/235 [===========>..................] - ETA: 0s - loss: 0.1748 - accuracy: 0.9443\n",
      "118/235 [==============>...............] - ETA: 0s - loss: 0.1751 - accuracy: 0.9442\n",
      "137/235 [================>.............] - ETA: 0s - loss: 0.1731 - accuracy: 0.9443\n",
      "156/235 [==================>...........] - ETA: 0s - loss: 0.1724 - accuracy: 0.9446\n",
      "176/235 [=====================>........] - ETA: 0s - loss: 0.1730 - accuracy: 0.9445\n",
      "195/235 [=======================>......] - ETA: 0s - loss: 0.1754 - accuracy: 0.9440\n",
      "216/235 [==========================>...] - ETA: 0s - loss: 0.1750 - accuracy: 0.9440\n",
      "226/235 [===========================>..] - ETA: 0s - loss: 0.1752 - accuracy: 0.9438\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.1752 - accuracy: 0.9440 - val_loss: 0.1416 - val_accuracy: 0.9543\n",
      "\u001b[36m(train_mnist pid=2628692)\u001b[0m Epoch 6/12\n",
      "  1/235 [..............................] - ETA: 1s - loss: 0.1687 - accuracy: 0.9414\n",
      " 20/235 [=>............................] - ETA: 1s - loss: 0.1620 - accuracy: 0.9477\n",
      " 40/235 [====>.........................] - ETA: 1s - loss: 0.1526 - accuracy: 0.9508\n",
      " 60/235 [======>.......................] - ETA: 0s - loss: 0.1609 - accuracy: 0.9485\n",
      " 70/235 [=======>......................] - ETA: 0s - loss: 0.1619 - accuracy: 0.9479\n",
      " 89/235 [==========>...................] - ETA: 0s - loss: 0.1609 - accuracy: 0.9472\n",
      "107/235 [============>.................] - ETA: 0s - loss: 0.1611 - accuracy: 0.9476\n",
      "128/235 [===============>..............] - ETA: 0s - loss: 0.1626 - accuracy: 0.9474\n",
      "147/235 [=================>............] - ETA: 0s - loss: 0.1618 - accuracy: 0.9475\n",
      "166/235 [====================>.........] - ETA: 0s - loss: 0.1652 - accuracy: 0.9472\n",
      "193/235 [=======================>......] - ETA: 0s - loss: 0.1655 - accuracy: 0.9466\n",
      "213/235 [==========================>...] - ETA: 0s - loss: 0.1639 - accuracy: 0.9472\n",
      "232/235 [============================>.] - ETA: 0s - loss: 0.1649 - accuracy: 0.9470\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.1648 - accuracy: 0.9470 - val_loss: 0.1480 - val_accuracy: 0.9528\n",
      "\u001b[36m(train_mnist pid=2628692)\u001b[0m Epoch 7/12\n",
      " 10/235 [>.............................] - ETA: 1s - loss: 0.1459 - accuracy: 0.9508\n",
      " 28/235 [==>...........................] - ETA: 1s - loss: 0.1339 - accuracy: 0.9552\n",
      " 47/235 [=====>........................] - ETA: 1s - loss: 0.1464 - accuracy: 0.9525\n",
      " 67/235 [=======>......................] - ETA: 0s - loss: 0.1454 - accuracy: 0.9526\n",
      " 87/235 [==========>...................] - ETA: 0s - loss: 0.1497 - accuracy: 0.9511\n",
      "107/235 [============>.................] - ETA: 0s - loss: 0.1499 - accuracy: 0.9508\n",
      "117/235 [=============>................] - ETA: 0s - loss: 0.1536 - accuracy: 0.9499\n",
      "136/235 [================>.............] - ETA: 0s - loss: 0.1540 - accuracy: 0.9496\n",
      "156/235 [==================>...........] - ETA: 0s - loss: 0.1552 - accuracy: 0.9496\n",
      "176/235 [=====================>........] - ETA: 0s - loss: 0.1572 - accuracy: 0.9492\n",
      "196/235 [========================>.....] - ETA: 0s - loss: 0.1583 - accuracy: 0.9489\n",
      "216/235 [==========================>...] - ETA: 0s - loss: 0.1583 - accuracy: 0.9490\n",
      "226/235 [===========================>..] - ETA: 0s - loss: 0.1582 - accuracy: 0.9492\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.1578 - accuracy: 0.9493 - val_loss: 0.1321 - val_accuracy: 0.9603\n",
      "\u001b[36m(train_mnist pid=2628692)\u001b[0m Epoch 8/12\n",
      "  1/235 [..............................] - ETA: 1s - loss: 0.1477 - accuracy: 0.9609\n",
      " 19/235 [=>............................] - ETA: 1s - loss: 0.1462 - accuracy: 0.9521\n",
      " 38/235 [===>..........................] - ETA: 1s - loss: 0.1436 - accuracy: 0.9536\n",
      " 47/235 [=====>........................] - ETA: 1s - loss: 0.1462 - accuracy: 0.9530\n",
      " 67/235 [=======>......................] - ETA: 0s - loss: 0.1471 - accuracy: 0.9516\n",
      " 87/235 [==========>...................] - ETA: 0s - loss: 0.1487 - accuracy: 0.9517\n",
      "106/235 [============>.................] - ETA: 0s - loss: 0.1515 - accuracy: 0.9507\n",
      "126/235 [===============>..............] - ETA: 0s - loss: 0.1516 - accuracy: 0.9501\n",
      "146/235 [=================>............] - ETA: 0s - loss: 0.1506 - accuracy: 0.9502\n",
      "167/235 [====================>.........] - ETA: 0s - loss: 0.1501 - accuracy: 0.9508\n",
      "177/235 [=====================>........] - ETA: 0s - loss: 0.1497 - accuracy: 0.9509\n",
      "197/235 [========================>.....] - ETA: 0s - loss: 0.1483 - accuracy: 0.9511\n",
      "217/235 [==========================>...] - ETA: 0s - loss: 0.1500 - accuracy: 0.9506\n",
      "227/235 [===========================>..] - ETA: 0s - loss: 0.1498 - accuracy: 0.9509\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.1505 - accuracy: 0.9507 - val_loss: 0.1387 - val_accuracy: 0.9574\n",
      "\u001b[36m(train_mnist pid=2628692)\u001b[0m Epoch 9/12\n",
      "  1/235 [..............................] - ETA: 1s - loss: 0.1327 - accuracy: 0.9570\n",
      " 21/235 [=>............................] - ETA: 1s - loss: 0.1312 - accuracy: 0.9572\n",
      " 41/235 [====>.........................] - ETA: 1s - loss: 0.1364 - accuracy: 0.9545\n",
      " 60/235 [======>.......................] - ETA: 0s - loss: 0.1362 - accuracy: 0.9556\n",
      " 79/235 [=========>....................] - ETA: 0s - loss: 0.1405 - accuracy: 0.9550\n",
      "108/235 [============>.................] - ETA: 0s - loss: 0.1440 - accuracy: 0.9540\n",
      "127/235 [===============>..............] - ETA: 0s - loss: 0.1447 - accuracy: 0.9543\n",
      "146/235 [=================>............] - ETA: 0s - loss: 0.1465 - accuracy: 0.9539\n",
      "166/235 [====================>.........] - ETA: 0s - loss: 0.1475 - accuracy: 0.9532\n",
      "187/235 [======================>.......] - ETA: 0s - loss: 0.1475 - accuracy: 0.9533\n",
      "207/235 [=========================>....] - ETA: 0s - loss: 0.1468 - accuracy: 0.9533\n",
      "225/235 [===========================>..] - ETA: 0s - loss: 0.1475 - accuracy: 0.9531\n",
      "235/235 [==============================] - ETA: 0s - loss: 0.1473 - accuracy: 0.9531\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.1473 - accuracy: 0.9531 - val_loss: 0.1348 - val_accuracy: 0.9575\n",
      "\u001b[36m(train_mnist pid=2628692)\u001b[0m Epoch 10/12\n",
      " 12/235 [>.............................] - ETA: 1s - loss: 0.1422 - accuracy: 0.9521\n",
      " 32/235 [===>..........................] - ETA: 1s - loss: 0.1451 - accuracy: 0.9512\n",
      " 53/235 [=====>........................] - ETA: 0s - loss: 0.1454 - accuracy: 0.9533\n",
      " 73/235 [========>.....................] - ETA: 0s - loss: 0.1408 - accuracy: 0.9549\n",
      "102/235 [============>.................] - ETA: 0s - loss: 0.1432 - accuracy: 0.9545\n",
      "121/235 [==============>...............] - ETA: 0s - loss: 0.1422 - accuracy: 0.9547\n",
      "142/235 [=================>............] - ETA: 0s - loss: 0.1397 - accuracy: 0.9552\n",
      "162/235 [===================>..........] - ETA: 0s - loss: 0.1408 - accuracy: 0.9549\n",
      "182/235 [======================>.......] - ETA: 0s - loss: 0.1408 - accuracy: 0.9551\n",
      "202/235 [========================>.....] - ETA: 0s - loss: 0.1423 - accuracy: 0.9546\n",
      "222/235 [===========================>..] - ETA: 0s - loss: 0.1428 - accuracy: 0.9545\n",
      "231/235 [============================>.] - ETA: 0s - loss: 0.1436 - accuracy: 0.9542\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.1445 - accuracy: 0.9539 - val_loss: 0.1407 - val_accuracy: 0.9566\n",
      "\u001b[36m(train_mnist pid=2628692)\u001b[0m Epoch 11/12\n",
      " 10/235 [>.............................] - ETA: 1s - loss: 0.1294 - accuracy: 0.9555\n",
      " 30/235 [==>...........................] - ETA: 1s - loss: 0.1415 - accuracy: 0.9540\n",
      " 50/235 [=====>........................] - ETA: 0s - loss: 0.1431 - accuracy: 0.9541\n",
      " 71/235 [========>.....................] - ETA: 0s - loss: 0.1422 - accuracy: 0.9543\n",
      " 90/235 [==========>...................] - ETA: 0s - loss: 0.1406 - accuracy: 0.9544\n",
      "110/235 [=============>................] - ETA: 0s - loss: 0.1438 - accuracy: 0.9529\n",
      "120/235 [==============>...............] - ETA: 0s - loss: 0.1431 - accuracy: 0.9528\n",
      "140/235 [================>.............] - ETA: 0s - loss: 0.1429 - accuracy: 0.9529\n",
      "161/235 [===================>..........] - ETA: 0s - loss: 0.1432 - accuracy: 0.9531\n",
      "180/235 [=====================>........] - ETA: 0s - loss: 0.1417 - accuracy: 0.9538\n",
      "200/235 [========================>.....] - ETA: 0s - loss: 0.1413 - accuracy: 0.9542\n",
      "219/235 [==========================>...] - ETA: 0s - loss: 0.1406 - accuracy: 0.9544\n",
      "229/235 [============================>.] - ETA: 0s - loss: 0.1403 - accuracy: 0.9546\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.1403 - accuracy: 0.9546 - val_loss: 0.1320 - val_accuracy: 0.9590\n",
      "\u001b[36m(train_mnist pid=2628692)\u001b[0m Epoch 12/12\n",
      "  1/235 [..............................] - ETA: 1s - loss: 0.1492 - accuracy: 0.9453\n",
      " 21/235 [=>............................] - ETA: 1s - loss: 0.1222 - accuracy: 0.9608\n",
      " 41/235 [====>.........................] - ETA: 1s - loss: 0.1262 - accuracy: 0.9583\n",
      " 61/235 [======>.......................] - ETA: 0s - loss: 0.1255 - accuracy: 0.9596\n",
      " 71/235 [========>.....................] - ETA: 0s - loss: 0.1252 - accuracy: 0.9599\n",
      " 91/235 [==========>...................] - ETA: 0s - loss: 0.1296 - accuracy: 0.9584\n",
      "112/235 [=============>................] - ETA: 0s - loss: 0.1313 - accuracy: 0.9580\n",
      "132/235 [===============>..............] - ETA: 0s - loss: 0.1318 - accuracy: 0.9575\n",
      "152/235 [==================>...........] - ETA: 0s - loss: 0.1342 - accuracy: 0.9570\n",
      "173/235 [=====================>........] - ETA: 0s - loss: 0.1331 - accuracy: 0.9571\n",
      "193/235 [=======================>......] - ETA: 0s - loss: 0.1343 - accuracy: 0.9566\n",
      "202/235 [========================>.....] - ETA: 0s - loss: 0.1355 - accuracy: 0.9562\n",
      "222/235 [===========================>..] - ETA: 0s - loss: 0.1364 - accuracy: 0.9562\n",
      "232/235 [============================>.] - ETA: 0s - loss: 0.1366 - accuracy: 0.9562\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.1367 - accuracy: 0.9561 - val_loss: 0.1347 - val_accuracy: 0.9587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=2630824)\u001b[0m 2023-12-05 09:47:24.379179: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=2630824)\u001b[0m 2023-12-05 09:47:24.418271: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=2630824)\u001b[0m 2023-12-05 09:47:24.418295: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=2630824)\u001b[0m 2023-12-05 09:47:24.419349: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=2630824)\u001b[0m 2023-12-05 09:47:24.425276: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=2630824)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=2630824)\u001b[0m 2023-12-05 09:47:25.132788: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=2630824)\u001b[0m 2023-12-05 09:47:26.462233: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_mnist pid=2630824)\u001b[0m Epoch 1/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_mnist pid=2630824)\u001b[0m 2023-12-05 09:47:28.158403: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=2630824)\u001b[0m 2023-12-05 09:47:29.161821: I external/local_xla/xla/service/service.cc:168] XLA service 0x14b6e86d0b10 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=2630824)\u001b[0m 2023-12-05 09:47:29.161864: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=2630824)\u001b[0m 2023-12-05 09:47:29.168858: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=2630824)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=2630824)\u001b[0m I0000 00:00:1701787649.283083 2630978 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1/469 [..............................] - ETA: 18:05 - loss: 2.3033 - accuracy: 0.0859\n",
      " 21/469 [>.............................] - ETA: 2s - loss: 3.5186 - accuracy: 0.5409 \n",
      " 43/469 [=>............................] - ETA: 2s - loss: 1.9969 - accuracy: 0.6919\n",
      " 65/469 [===>..........................] - ETA: 2s - loss: 1.4598 - accuracy: 0.7563\n",
      " 87/469 [====>.........................] - ETA: 1s - loss: 1.1749 - accuracy: 0.7915\n",
      " 99/469 [=====>........................] - ETA: 1s - loss: 1.0663 - accuracy: 0.8066\n",
      "121/469 [======>.......................] - ETA: 1s - loss: 0.9210 - accuracy: 0.8266\n",
      "142/469 [========>.....................] - ETA: 1s - loss: 0.8257 - accuracy: 0.8406\n",
      "164/469 [=========>....................] - ETA: 1s - loss: 0.7492 - accuracy: 0.8516\n",
      "185/469 [==========>...................] - ETA: 1s - loss: 0.6876 - accuracy: 0.8618\n",
      "207/469 [============>.................] - ETA: 1s - loss: 0.6394 - accuracy: 0.8696\n",
      "230/469 [=============>................] - ETA: 1s - loss: 0.5979 - accuracy: 0.8762\n",
      "241/469 [==============>...............] - ETA: 1s - loss: 0.5803 - accuracy: 0.8786\n",
      "262/469 [===============>..............] - ETA: 1s - loss: 0.5548 - accuracy: 0.8823\n",
      "284/469 [=================>............] - ETA: 0s - loss: 0.5277 - accuracy: 0.8863\n",
      "305/469 [==================>...........] - ETA: 0s - loss: 0.5058 - accuracy: 0.8899\n",
      "327/469 [===================>..........] - ETA: 0s - loss: 0.4852 - accuracy: 0.8932\n",
      "350/469 [=====================>........] - ETA: 0s - loss: 0.4659 - accuracy: 0.8962\n",
      "374/469 [======================>.......] - ETA: 0s - loss: 0.4500 - accuracy: 0.8990\n",
      "397/469 [========================>.....] - ETA: 0s - loss: 0.4338 - accuracy: 0.9019\n",
      "408/469 [=========================>....] - ETA: 0s - loss: 0.4265 - accuracy: 0.9033\n",
      "431/469 [==========================>...] - ETA: 0s - loss: 0.4140 - accuracy: 0.9052\n",
      "453/469 [===========================>..] - ETA: 0s - loss: 0.4029 - accuracy: 0.9071\n",
      "464/469 [============================>.] - ETA: 0s - loss: 0.3974 - accuracy: 0.9080\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.3959 - accuracy: 0.9082\n",
      "469/469 [==============================] - 5s 6ms/step - loss: 0.3959 - accuracy: 0.9082 - val_loss: 0.1037 - val_accuracy: 0.9680\n",
      "\u001b[36m(train_mnist pid=2630824)\u001b[0m Epoch 2/12\n",
      " 12/469 [..............................] - ETA: 2s - loss: 0.1673 - accuracy: 0.9525\n",
      " 47/469 [==>...........................] - ETA: 1s - loss: 0.1754 - accuracy: 0.9480\n",
      " 70/469 [===>..........................] - ETA: 1s - loss: 0.1733 - accuracy: 0.9485\n",
      " 91/469 [====>.........................] - ETA: 1s - loss: 0.1700 - accuracy: 0.9491\n",
      "112/469 [======>.......................] - ETA: 1s - loss: 0.1676 - accuracy: 0.9501\n",
      "135/469 [=======>......................] - ETA: 1s - loss: 0.1728 - accuracy: 0.9490\n",
      "158/469 [=========>....................] - ETA: 1s - loss: 0.1686 - accuracy: 0.9505\n",
      "179/469 [==========>...................] - ETA: 1s - loss: 0.1682 - accuracy: 0.9509\n",
      "190/469 [===========>..................] - ETA: 1s - loss: 0.1688 - accuracy: 0.9508\n",
      "212/469 [============>.................] - ETA: 1s - loss: 0.1692 - accuracy: 0.9510\n",
      "233/469 [=============>................] - ETA: 1s - loss: 0.1708 - accuracy: 0.9504\n",
      "255/469 [===============>..............] - ETA: 1s - loss: 0.1711 - accuracy: 0.9506\n",
      "277/469 [================>.............] - ETA: 0s - loss: 0.1718 - accuracy: 0.9508\n",
      "299/469 [==================>...........] - ETA: 0s - loss: 0.1729 - accuracy: 0.9503\n",
      "322/469 [===================>..........] - ETA: 0s - loss: 0.1722 - accuracy: 0.9501\n",
      "343/469 [====================>.........] - ETA: 0s - loss: 0.1718 - accuracy: 0.9502\n",
      "354/469 [=====================>........] - ETA: 0s - loss: 0.1722 - accuracy: 0.9502\n",
      "376/469 [=======================>......] - ETA: 0s - loss: 0.1726 - accuracy: 0.9501\n",
      "400/469 [========================>.....] - ETA: 0s - loss: 0.1725 - accuracy: 0.9501\n",
      "422/469 [=========================>....] - ETA: 0s - loss: 0.1725 - accuracy: 0.9502\n",
      "444/469 [===========================>..] - ETA: 0s - loss: 0.1721 - accuracy: 0.9501\n",
      "467/469 [============================>.] - ETA: 0s - loss: 0.1730 - accuracy: 0.9501\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1731 - accuracy: 0.9500 - val_loss: 0.1064 - val_accuracy: 0.9687\n",
      "\u001b[36m(train_mnist pid=2630824)\u001b[0m Epoch 3/12\n",
      "  1/469 [..............................] - ETA: 2s - loss: 0.1186 - accuracy: 0.9453\n",
      " 24/469 [>.............................] - ETA: 2s - loss: 0.1648 - accuracy: 0.9508\n",
      " 48/469 [==>...........................] - ETA: 1s - loss: 0.1449 - accuracy: 0.9564\n",
      " 71/469 [===>..........................] - ETA: 1s - loss: 0.1435 - accuracy: 0.9571\n",
      " 82/469 [====>.........................] - ETA: 1s - loss: 0.1434 - accuracy: 0.9567\n",
      "104/469 [=====>........................] - ETA: 1s - loss: 0.1491 - accuracy: 0.9561\n",
      "127/469 [=======>......................] - ETA: 1s - loss: 0.1465 - accuracy: 0.9568\n",
      "149/469 [========>.....................] - ETA: 1s - loss: 0.1462 - accuracy: 0.9571\n",
      "171/469 [=========>....................] - ETA: 1s - loss: 0.1477 - accuracy: 0.9571\n",
      "195/469 [===========>..................] - ETA: 1s - loss: 0.1473 - accuracy: 0.9569\n",
      "216/469 [============>.................] - ETA: 1s - loss: 0.1489 - accuracy: 0.9562\n",
      "249/469 [==============>...............] - ETA: 1s - loss: 0.1498 - accuracy: 0.9556\n",
      "271/469 [================>.............] - ETA: 0s - loss: 0.1522 - accuracy: 0.9551\n",
      "294/469 [=================>............] - ETA: 0s - loss: 0.1533 - accuracy: 0.9548\n",
      "316/469 [===================>..........] - ETA: 0s - loss: 0.1546 - accuracy: 0.9544\n",
      "337/469 [====================>.........] - ETA: 0s - loss: 0.1550 - accuracy: 0.9547\n",
      "361/469 [======================>.......] - ETA: 0s - loss: 0.1557 - accuracy: 0.9545\n",
      "383/469 [=======================>......] - ETA: 0s - loss: 0.1569 - accuracy: 0.9541\n",
      "416/469 [=========================>....] - ETA: 0s - loss: 0.1589 - accuracy: 0.9538\n",
      "440/469 [===========================>..] - ETA: 0s - loss: 0.1595 - accuracy: 0.9536\n",
      "464/469 [============================>.] - ETA: 0s - loss: 0.1607 - accuracy: 0.9535\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1610 - accuracy: 0.9534 - val_loss: 0.0954 - val_accuracy: 0.9722\n",
      "\u001b[36m(train_mnist pid=2630824)\u001b[0m Epoch 4/12\n",
      "  1/469 [..............................] - ETA: 2s - loss: 0.1457 - accuracy: 0.9297\n",
      " 23/469 [>.............................] - ETA: 2s - loss: 0.1245 - accuracy: 0.9620\n",
      " 43/469 [=>............................] - ETA: 2s - loss: 0.1401 - accuracy: 0.9589\n",
      " 65/469 [===>..........................] - ETA: 2s - loss: 0.1450 - accuracy: 0.9573\n",
      " 88/469 [====>.........................] - ETA: 1s - loss: 0.1421 - accuracy: 0.9578\n",
      "110/469 [======>.......................] - ETA: 1s - loss: 0.1536 - accuracy: 0.9538\n",
      "133/469 [=======>......................] - ETA: 1s - loss: 0.1570 - accuracy: 0.9537\n",
      "156/469 [========>.....................] - ETA: 1s - loss: 0.1579 - accuracy: 0.9532\n",
      "178/469 [==========>...................] - ETA: 1s - loss: 0.1562 - accuracy: 0.9539\n",
      "189/469 [===========>..................] - ETA: 1s - loss: 0.1549 - accuracy: 0.9542\n",
      "210/469 [============>.................] - ETA: 1s - loss: 0.1569 - accuracy: 0.9538\n",
      "234/469 [=============>................] - ETA: 1s - loss: 0.1572 - accuracy: 0.9540\n",
      "256/469 [===============>..............] - ETA: 1s - loss: 0.1583 - accuracy: 0.9538\n",
      "277/469 [================>.............] - ETA: 0s - loss: 0.1580 - accuracy: 0.9540\n",
      "299/469 [==================>...........] - ETA: 0s - loss: 0.1587 - accuracy: 0.9540\n",
      "321/469 [===================>..........] - ETA: 0s - loss: 0.1588 - accuracy: 0.9538\n",
      "352/469 [=====================>........] - ETA: 0s - loss: 0.1590 - accuracy: 0.9539\n",
      "374/469 [======================>.......] - ETA: 0s - loss: 0.1588 - accuracy: 0.9543\n",
      "397/469 [========================>.....] - ETA: 0s - loss: 0.1596 - accuracy: 0.9541\n",
      "418/469 [=========================>....] - ETA: 0s - loss: 0.1600 - accuracy: 0.9540\n",
      "438/469 [===========================>..] - ETA: 0s - loss: 0.1615 - accuracy: 0.9538\n",
      "459/469 [============================>.] - ETA: 0s - loss: 0.1631 - accuracy: 0.9534\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1634 - accuracy: 0.9534 - val_loss: 0.1039 - val_accuracy: 0.9709\n",
      "\u001b[36m(train_mnist pid=2630824)\u001b[0m Epoch 5/12\n",
      "  1/469 [..............................] - ETA: 2s - loss: 0.2938 - accuracy: 0.9297\n",
      " 23/469 [>.............................] - ETA: 2s - loss: 0.1365 - accuracy: 0.9586\n",
      " 45/469 [=>............................] - ETA: 2s - loss: 0.1490 - accuracy: 0.9557\n",
      " 66/469 [===>..........................] - ETA: 1s - loss: 0.1467 - accuracy: 0.9589\n",
      " 88/469 [====>.........................] - ETA: 1s - loss: 0.1455 - accuracy: 0.9579\n",
      " 99/469 [=====>........................] - ETA: 1s - loss: 0.1507 - accuracy: 0.9575\n",
      "120/469 [======>.......................] - ETA: 1s - loss: 0.1547 - accuracy: 0.9570\n",
      "141/469 [========>.....................] - ETA: 1s - loss: 0.1531 - accuracy: 0.9569\n",
      "163/469 [=========>....................] - ETA: 1s - loss: 0.1603 - accuracy: 0.9549\n",
      "186/469 [==========>...................] - ETA: 1s - loss: 0.1593 - accuracy: 0.9556\n",
      "209/469 [============>.................] - ETA: 1s - loss: 0.1631 - accuracy: 0.9542\n",
      "231/469 [=============>................] - ETA: 1s - loss: 0.1638 - accuracy: 0.9542\n",
      "253/469 [===============>..............] - ETA: 1s - loss: 0.1624 - accuracy: 0.9545\n",
      "286/469 [=================>............] - ETA: 0s - loss: 0.1628 - accuracy: 0.9542\n",
      "308/469 [==================>...........] - ETA: 0s - loss: 0.1626 - accuracy: 0.9542\n",
      "331/469 [====================>.........] - ETA: 0s - loss: 0.1632 - accuracy: 0.9542\n",
      "352/469 [=====================>........] - ETA: 0s - loss: 0.1629 - accuracy: 0.9543\n",
      "375/469 [======================>.......] - ETA: 0s - loss: 0.1634 - accuracy: 0.9543\n",
      "395/469 [========================>.....] - ETA: 0s - loss: 0.1638 - accuracy: 0.9545\n",
      "419/469 [=========================>....] - ETA: 0s - loss: 0.1633 - accuracy: 0.9547\n",
      "442/469 [===========================>..] - ETA: 0s - loss: 0.1622 - accuracy: 0.9549\n",
      "453/469 [===========================>..] - ETA: 0s - loss: 0.1634 - accuracy: 0.9546\n",
      "464/469 [============================>.] - ETA: 0s - loss: 0.1641 - accuracy: 0.9544\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1646 - accuracy: 0.9542 - val_loss: 0.0928 - val_accuracy: 0.9733\n",
      "\u001b[36m(train_mnist pid=2630824)\u001b[0m Epoch 6/12\n",
      "  1/469 [..............................] - ETA: 2s - loss: 0.2333 - accuracy: 0.9531\n",
      " 12/469 [..............................] - ETA: 2s - loss: 0.1481 - accuracy: 0.9570\n",
      " 34/469 [=>............................] - ETA: 2s - loss: 0.1323 - accuracy: 0.9598\n",
      " 56/469 [==>...........................] - ETA: 1s - loss: 0.1482 - accuracy: 0.9569\n",
      " 79/469 [====>.........................] - ETA: 1s - loss: 0.1500 - accuracy: 0.9568\n",
      "101/469 [=====>........................] - ETA: 1s - loss: 0.1484 - accuracy: 0.9569\n",
      "124/469 [======>.......................] - ETA: 1s - loss: 0.1502 - accuracy: 0.9559\n",
      "157/469 [=========>....................] - ETA: 1s - loss: 0.1502 - accuracy: 0.9563\n",
      "180/469 [==========>...................] - ETA: 1s - loss: 0.1470 - accuracy: 0.9567\n",
      "202/469 [===========>..................] - ETA: 1s - loss: 0.1463 - accuracy: 0.9574\n",
      "223/469 [=============>................] - ETA: 1s - loss: 0.1489 - accuracy: 0.9571\n",
      "245/469 [==============>...............] - ETA: 1s - loss: 0.1512 - accuracy: 0.9573\n",
      "266/469 [================>.............] - ETA: 0s - loss: 0.1524 - accuracy: 0.9571\n",
      "288/469 [=================>............] - ETA: 0s - loss: 0.1527 - accuracy: 0.9571\n",
      "299/469 [==================>...........] - ETA: 0s - loss: 0.1527 - accuracy: 0.9570\n",
      "321/469 [===================>..........] - ETA: 0s - loss: 0.1526 - accuracy: 0.9573\n",
      "345/469 [=====================>........] - ETA: 0s - loss: 0.1531 - accuracy: 0.9573\n",
      "367/469 [======================>.......] - ETA: 0s - loss: 0.1527 - accuracy: 0.9573\n",
      "389/469 [=======================>......] - ETA: 0s - loss: 0.1527 - accuracy: 0.9575\n",
      "411/469 [=========================>....] - ETA: 0s - loss: 0.1528 - accuracy: 0.9575\n",
      "432/469 [==========================>...] - ETA: 0s - loss: 0.1543 - accuracy: 0.9572\n",
      "453/469 [===========================>..] - ETA: 0s - loss: 0.1561 - accuracy: 0.9569\n",
      "463/469 [============================>.] - ETA: 0s - loss: 0.1558 - accuracy: 0.9569\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1563 - accuracy: 0.9570 - val_loss: 0.1299 - val_accuracy: 0.9699\n",
      "\u001b[36m(train_mnist pid=2630824)\u001b[0m Epoch 7/12\n",
      " 11/469 [..............................] - ETA: 2s - loss: 0.1580 - accuracy: 0.9524\n",
      " 32/469 [=>............................] - ETA: 2s - loss: 0.1376 - accuracy: 0.9583\n",
      " 44/469 [=>............................] - ETA: 2s - loss: 0.1413 - accuracy: 0.9590\n",
      " 66/469 [===>..........................] - ETA: 1s - loss: 0.1369 - accuracy: 0.9609\n",
      " 88/469 [====>.........................] - ETA: 1s - loss: 0.1509 - accuracy: 0.9596\n",
      "110/469 [======>.......................] - ETA: 1s - loss: 0.1503 - accuracy: 0.9587\n",
      "132/469 [=======>......................] - ETA: 1s - loss: 0.1519 - accuracy: 0.9581\n",
      "154/469 [========>.....................] - ETA: 1s - loss: 0.1498 - accuracy: 0.9593\n",
      "176/469 [==========>...................] - ETA: 1s - loss: 0.1504 - accuracy: 0.9586\n",
      "187/469 [==========>...................] - ETA: 1s - loss: 0.1501 - accuracy: 0.9585\n",
      "208/469 [============>.................] - ETA: 1s - loss: 0.1512 - accuracy: 0.9583\n",
      "228/469 [=============>................] - ETA: 1s - loss: 0.1539 - accuracy: 0.9577\n",
      "250/469 [==============>...............] - ETA: 1s - loss: 0.1545 - accuracy: 0.9574\n",
      "271/469 [================>.............] - ETA: 0s - loss: 0.1562 - accuracy: 0.9567\n",
      "294/469 [=================>............] - ETA: 0s - loss: 0.1557 - accuracy: 0.9570\n",
      "305/469 [==================>...........] - ETA: 0s - loss: 0.1554 - accuracy: 0.9570\n",
      "327/469 [===================>..........] - ETA: 0s - loss: 0.1556 - accuracy: 0.9567\n",
      "349/469 [=====================>........] - ETA: 0s - loss: 0.1574 - accuracy: 0.9563\n",
      "370/469 [======================>.......] - ETA: 0s - loss: 0.1580 - accuracy: 0.9560\n",
      "392/469 [========================>.....] - ETA: 0s - loss: 0.1596 - accuracy: 0.9556\n",
      "414/469 [=========================>....] - ETA: 0s - loss: 0.1640 - accuracy: 0.9547\n",
      "435/469 [==========================>...] - ETA: 0s - loss: 0.1672 - accuracy: 0.9542\n",
      "445/469 [===========================>..] - ETA: 0s - loss: 0.1664 - accuracy: 0.9541\n",
      "467/469 [============================>.] - ETA: 0s - loss: 0.1678 - accuracy: 0.9541\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1683 - accuracy: 0.9540 - val_loss: 0.1225 - val_accuracy: 0.9683\n",
      "\u001b[36m(train_mnist pid=2630824)\u001b[0m Epoch 8/12\n",
      "  1/469 [..............................] - ETA: 2s - loss: 0.2384 - accuracy: 0.9219\n",
      " 22/469 [>.............................] - ETA: 2s - loss: 0.1602 - accuracy: 0.9553\n",
      " 44/469 [=>............................] - ETA: 2s - loss: 0.1855 - accuracy: 0.9496\n",
      " 68/469 [===>..........................] - ETA: 1s - loss: 0.1755 - accuracy: 0.9509\n",
      " 90/469 [====>.........................] - ETA: 1s - loss: 0.1664 - accuracy: 0.9536\n",
      "112/469 [======>.......................] - ETA: 1s - loss: 0.1669 - accuracy: 0.9537\n",
      "135/469 [=======>......................] - ETA: 1s - loss: 0.1636 - accuracy: 0.9551\n",
      "158/469 [=========>....................] - ETA: 1s - loss: 0.1649 - accuracy: 0.9556\n",
      "169/469 [=========>....................] - ETA: 1s - loss: 0.1626 - accuracy: 0.9562\n",
      "192/469 [===========>..................] - ETA: 1s - loss: 0.1623 - accuracy: 0.9564\n",
      "213/469 [============>.................] - ETA: 1s - loss: 0.1631 - accuracy: 0.9562\n",
      "235/469 [==============>...............] - ETA: 1s - loss: 0.1656 - accuracy: 0.9558\n",
      "256/469 [===============>..............] - ETA: 1s - loss: 0.1646 - accuracy: 0.9558\n",
      "278/469 [================>.............] - ETA: 0s - loss: 0.1637 - accuracy: 0.9559\n",
      "300/469 [==================>...........] - ETA: 0s - loss: 0.1612 - accuracy: 0.9565\n",
      "333/469 [====================>.........] - ETA: 0s - loss: 0.1610 - accuracy: 0.9564\n",
      "356/469 [=====================>........] - ETA: 0s - loss: 0.1627 - accuracy: 0.9559\n",
      "379/469 [=======================>......] - ETA: 0s - loss: 0.1624 - accuracy: 0.9562\n",
      "401/469 [========================>.....] - ETA: 0s - loss: 0.1609 - accuracy: 0.9564\n",
      "423/469 [==========================>...] - ETA: 0s - loss: 0.1606 - accuracy: 0.9565\n",
      "445/469 [===========================>..] - ETA: 0s - loss: 0.1608 - accuracy: 0.9565\n",
      "466/469 [============================>.] - ETA: 0s - loss: 0.1612 - accuracy: 0.9564\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1609 - accuracy: 0.9564 - val_loss: 0.1192 - val_accuracy: 0.9717\n",
      "\u001b[36m(train_mnist pid=2630824)\u001b[0m Epoch 9/12\n",
      "  1/469 [..............................] - ETA: 2s - loss: 0.0823 - accuracy: 0.9688\n",
      " 24/469 [>.............................] - ETA: 2s - loss: 0.1376 - accuracy: 0.9629\n",
      " 47/469 [==>...........................] - ETA: 1s - loss: 0.1533 - accuracy: 0.9603\n",
      " 68/469 [===>..........................] - ETA: 1s - loss: 0.1481 - accuracy: 0.9592\n",
      "102/469 [=====>........................] - ETA: 1s - loss: 0.1535 - accuracy: 0.9573\n",
      "124/469 [======>.......................] - ETA: 1s - loss: 0.1533 - accuracy: 0.9573\n",
      "146/469 [========>.....................] - ETA: 1s - loss: 0.1524 - accuracy: 0.9570\n",
      "168/469 [=========>....................] - ETA: 1s - loss: 0.1558 - accuracy: 0.9561\n",
      "190/469 [===========>..................] - ETA: 1s - loss: 0.1562 - accuracy: 0.9562\n",
      "214/469 [============>.................] - ETA: 1s - loss: 0.1627 - accuracy: 0.9553\n",
      "234/469 [=============>................] - ETA: 1s - loss: 0.1627 - accuracy: 0.9555\n",
      "256/469 [===============>..............] - ETA: 1s - loss: 0.1599 - accuracy: 0.9561\n",
      "278/469 [================>.............] - ETA: 0s - loss: 0.1591 - accuracy: 0.9564\n",
      "301/469 [==================>...........] - ETA: 0s - loss: 0.1578 - accuracy: 0.9565\n",
      "322/469 [===================>..........] - ETA: 0s - loss: 0.1576 - accuracy: 0.9567\n",
      "333/469 [====================>.........] - ETA: 0s - loss: 0.1569 - accuracy: 0.9567\n",
      "344/469 [=====================>........] - ETA: 0s - loss: 0.1572 - accuracy: 0.9567\n",
      "355/469 [=====================>........] - ETA: 0s - loss: 0.1564 - accuracy: 0.9571\n",
      "378/469 [=======================>......] - ETA: 0s - loss: 0.1573 - accuracy: 0.9568\n",
      "399/469 [========================>.....] - ETA: 0s - loss: 0.1586 - accuracy: 0.9565\n",
      "422/469 [=========================>....] - ETA: 0s - loss: 0.1584 - accuracy: 0.9565\n",
      "444/469 [===========================>..] - ETA: 0s - loss: 0.1601 - accuracy: 0.9565\n",
      "465/469 [============================>.] - ETA: 0s - loss: 0.1608 - accuracy: 0.9563\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1606 - accuracy: 0.9564 - val_loss: 0.1155 - val_accuracy: 0.9751\n",
      "\u001b[36m(train_mnist pid=2630824)\u001b[0m Epoch 10/12\n",
      "  1/469 [..............................] - ETA: 2s - loss: 0.3685 - accuracy: 0.9375\n",
      " 23/469 [>.............................] - ETA: 2s - loss: 0.1434 - accuracy: 0.9565\n",
      " 45/469 [=>............................] - ETA: 2s - loss: 0.1365 - accuracy: 0.9597\n",
      " 66/469 [===>..........................] - ETA: 1s - loss: 0.1381 - accuracy: 0.9607\n",
      " 89/469 [====>.........................] - ETA: 1s - loss: 0.1400 - accuracy: 0.9607\n",
      "100/469 [=====>........................] - ETA: 1s - loss: 0.1445 - accuracy: 0.9609\n",
      "121/469 [======>.......................] - ETA: 1s - loss: 0.1555 - accuracy: 0.9586\n",
      "144/469 [========>.....................] - ETA: 1s - loss: 0.1570 - accuracy: 0.9575\n",
      "166/469 [=========>....................] - ETA: 1s - loss: 0.1529 - accuracy: 0.9583\n",
      "188/469 [===========>..................] - ETA: 1s - loss: 0.1572 - accuracy: 0.9571\n",
      "211/469 [============>.................] - ETA: 1s - loss: 0.1641 - accuracy: 0.9562\n",
      "232/469 [=============>................] - ETA: 1s - loss: 0.1667 - accuracy: 0.9552\n",
      "255/469 [===============>..............] - ETA: 1s - loss: 0.1731 - accuracy: 0.9537\n",
      "278/469 [================>.............] - ETA: 0s - loss: 0.1749 - accuracy: 0.9535\n",
      "310/469 [==================>...........] - ETA: 0s - loss: 0.1752 - accuracy: 0.9531\n",
      "332/469 [====================>.........] - ETA: 0s - loss: 0.1746 - accuracy: 0.9532\n",
      "354/469 [=====================>........] - ETA: 0s - loss: 0.1748 - accuracy: 0.9528\n",
      "375/469 [======================>.......] - ETA: 0s - loss: 0.1750 - accuracy: 0.9526\n",
      "396/469 [========================>.....] - ETA: 0s - loss: 0.1774 - accuracy: 0.9518\n",
      "418/469 [=========================>....] - ETA: 0s - loss: 0.1785 - accuracy: 0.9516\n",
      "451/469 [===========================>..] - ETA: 0s - loss: 0.1800 - accuracy: 0.9512\n",
      "461/469 [============================>.] - ETA: 0s - loss: 0.1814 - accuracy: 0.9508\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1814 - accuracy: 0.9507 - val_loss: 0.1268 - val_accuracy: 0.9696\n",
      "\u001b[36m(train_mnist pid=2630824)\u001b[0m Epoch 11/12\n",
      "  1/469 [..............................] - ETA: 2s - loss: 0.2641 - accuracy: 0.9141\n",
      " 23/469 [>.............................] - ETA: 2s - loss: 0.1777 - accuracy: 0.9514\n",
      " 34/469 [=>............................] - ETA: 2s - loss: 0.1822 - accuracy: 0.9506\n",
      " 56/469 [==>...........................] - ETA: 1s - loss: 0.1764 - accuracy: 0.9492\n",
      " 78/469 [===>..........................] - ETA: 1s - loss: 0.1684 - accuracy: 0.9521\n",
      "100/469 [=====>........................] - ETA: 1s - loss: 0.1765 - accuracy: 0.9523\n",
      "124/469 [======>.......................] - ETA: 1s - loss: 0.1764 - accuracy: 0.9522\n",
      "145/469 [========>.....................] - ETA: 1s - loss: 0.1715 - accuracy: 0.9528\n",
      "165/469 [=========>....................] - ETA: 1s - loss: 0.1673 - accuracy: 0.9537\n",
      "188/469 [===========>..................] - ETA: 1s - loss: 0.1655 - accuracy: 0.9544\n",
      "211/469 [============>.................] - ETA: 1s - loss: 0.1658 - accuracy: 0.9543\n",
      "233/469 [=============>................] - ETA: 1s - loss: 0.1642 - accuracy: 0.9544\n",
      "244/469 [==============>...............] - ETA: 1s - loss: 0.1647 - accuracy: 0.9542\n",
      "266/469 [================>.............] - ETA: 0s - loss: 0.1672 - accuracy: 0.9538\n",
      "287/469 [=================>............] - ETA: 0s - loss: 0.1672 - accuracy: 0.9541\n",
      "308/469 [==================>...........] - ETA: 0s - loss: 0.1689 - accuracy: 0.9535\n",
      "331/469 [====================>.........] - ETA: 0s - loss: 0.1688 - accuracy: 0.9532\n",
      "353/469 [=====================>........] - ETA: 0s - loss: 0.1710 - accuracy: 0.9525\n",
      "376/469 [=======================>......] - ETA: 0s - loss: 0.1714 - accuracy: 0.9525\n",
      "397/469 [========================>.....] - ETA: 0s - loss: 0.1708 - accuracy: 0.9527\n",
      "420/469 [=========================>....] - ETA: 0s - loss: 0.1708 - accuracy: 0.9527\n",
      "430/469 [==========================>...] - ETA: 0s - loss: 0.1708 - accuracy: 0.9527\n",
      "454/469 [============================>.] - ETA: 0s - loss: 0.1695 - accuracy: 0.9530\n",
      "466/469 [============================>.] - ETA: 0s - loss: 0.1694 - accuracy: 0.9529\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1690 - accuracy: 0.9530 - val_loss: 0.1645 - val_accuracy: 0.9668\n",
      "\u001b[36m(train_mnist pid=2630824)\u001b[0m Epoch 12/12\n",
      " 11/469 [..............................] - ETA: 2s - loss: 0.2253 - accuracy: 0.9418\n",
      " 31/469 [>.............................] - ETA: 2s - loss: 0.2360 - accuracy: 0.9393\n",
      " 53/469 [==>...........................] - ETA: 2s - loss: 0.2092 - accuracy: 0.9421\n",
      " 73/469 [===>..........................] - ETA: 1s - loss: 0.1953 - accuracy: 0.9455\n",
      " 94/469 [=====>........................] - ETA: 1s - loss: 0.1834 - accuracy: 0.9475\n",
      "116/469 [======>.......................] - ETA: 1s - loss: 0.1798 - accuracy: 0.9477\n",
      "149/469 [========>.....................] - ETA: 1s - loss: 0.1705 - accuracy: 0.9507\n",
      "172/469 [==========>...................] - ETA: 1s - loss: 0.1671 - accuracy: 0.9523\n",
      "193/469 [===========>..................] - ETA: 1s - loss: 0.1634 - accuracy: 0.9528\n",
      "216/469 [============>.................] - ETA: 1s - loss: 0.1636 - accuracy: 0.9527\n",
      "239/469 [==============>...............] - ETA: 1s - loss: 0.1629 - accuracy: 0.9536\n",
      "261/469 [===============>..............] - ETA: 0s - loss: 0.1626 - accuracy: 0.9536\n",
      "283/469 [=================>............] - ETA: 0s - loss: 0.1624 - accuracy: 0.9539\n",
      "317/469 [===================>..........] - ETA: 0s - loss: 0.1616 - accuracy: 0.9540\n",
      "339/469 [====================>.........] - ETA: 0s - loss: 0.1632 - accuracy: 0.9536\n",
      "361/469 [======================>.......] - ETA: 0s - loss: 0.1617 - accuracy: 0.9539\n",
      "384/469 [=======================>......] - ETA: 0s - loss: 0.1617 - accuracy: 0.9540\n",
      "407/469 [=========================>....] - ETA: 0s - loss: 0.1603 - accuracy: 0.9542\n",
      "429/469 [==========================>...] - ETA: 0s - loss: 0.1614 - accuracy: 0.9540\n",
      "451/469 [===========================>..] - ETA: 0s - loss: 0.1627 - accuracy: 0.9540\n",
      "462/469 [============================>.] - ETA: 0s - loss: 0.1622 - accuracy: 0.9539\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1612 - accuracy: 0.9543 - val_loss: 0.1221 - val_accuracy: 0.9727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=2634070)\u001b[0m 2023-12-05 09:48:02.428293: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=2634070)\u001b[0m 2023-12-05 09:48:02.467157: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=2634070)\u001b[0m 2023-12-05 09:48:02.467182: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=2634070)\u001b[0m 2023-12-05 09:48:02.468205: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=2634070)\u001b[0m 2023-12-05 09:48:02.474090: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=2634070)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=2634070)\u001b[0m 2023-12-05 09:48:03.177990: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=2634070)\u001b[0m 2023-12-05 09:48:04.500986: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_mnist pid=2634070)\u001b[0m Epoch 1/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_mnist pid=2634070)\u001b[0m 2023-12-05 09:48:06.210753: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=2634070)\u001b[0m 2023-12-05 09:48:07.172116: I external/local_xla/xla/service/service.cc:168] XLA service 0x15393c6d1b50 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=2634070)\u001b[0m 2023-12-05 09:48:07.172161: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=2634070)\u001b[0m 2023-12-05 09:48:07.184929: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=2634070)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=2634070)\u001b[0m I0000 00:00:1701787687.303039 2634428 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1/469 [..............................] - ETA: 17:47 - loss: 2.3120 - accuracy: 0.0859\n",
      " 25/469 [>.............................] - ETA: 1s - loss: 3.1347 - accuracy: 0.4759 \n",
      " 61/469 [==>...........................] - ETA: 1s - loss: 1.6042 - accuracy: 0.6887\n",
      " 87/469 [====>.........................] - ETA: 1s - loss: 1.2495 - accuracy: 0.7443\n",
      "115/469 [======>.......................] - ETA: 1s - loss: 1.0376 - accuracy: 0.7774\n",
      "142/469 [========>.....................] - ETA: 1s - loss: 0.9032 - accuracy: 0.7998\n",
      "167/469 [=========>....................] - ETA: 1s - loss: 0.8216 - accuracy: 0.8143\n",
      "190/469 [===========>..................] - ETA: 1s - loss: 0.7582 - accuracy: 0.8259\n",
      "216/469 [============>.................] - ETA: 1s - loss: 0.7024 - accuracy: 0.8363\n",
      "240/469 [==============>...............] - ETA: 0s - loss: 0.6606 - accuracy: 0.8440\n",
      "252/469 [===============>..............] - ETA: 0s - loss: 0.6430 - accuracy: 0.8469\n",
      "279/469 [================>.............] - ETA: 0s - loss: 0.6086 - accuracy: 0.8537\n",
      "305/469 [==================>...........] - ETA: 0s - loss: 0.5840 - accuracy: 0.8586\n",
      "329/469 [====================>.........] - ETA: 0s - loss: 0.5600 - accuracy: 0.8634\n",
      "355/469 [=====================>........] - ETA: 0s - loss: 0.5376 - accuracy: 0.8680\n",
      "379/469 [=======================>......] - ETA: 0s - loss: 0.5209 - accuracy: 0.8712\n",
      "404/469 [========================>.....] - ETA: 0s - loss: 0.5053 - accuracy: 0.8739\n",
      "429/469 [==========================>...] - ETA: 0s - loss: 0.4907 - accuracy: 0.8771\n",
      "442/469 [===========================>..] - ETA: 0s - loss: 0.4852 - accuracy: 0.8782\n",
      "456/469 [============================>.] - ETA: 0s - loss: 0.4795 - accuracy: 0.8794\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.4750 - accuracy: 0.8800\n",
      "469/469 [==============================] - 5s 5ms/step - loss: 0.4750 - accuracy: 0.8800 - val_loss: 0.2224 - val_accuracy: 0.9319\n",
      "\u001b[36m(train_mnist pid=2634070)\u001b[0m Epoch 2/12\n",
      "  1/469 [..............................] - ETA: 2s - loss: 0.5610 - accuracy: 0.8828\n",
      " 27/469 [>.............................] - ETA: 1s - loss: 0.2812 - accuracy: 0.9161\n",
      " 39/469 [=>............................] - ETA: 1s - loss: 0.2652 - accuracy: 0.9211\n",
      " 64/469 [===>..........................] - ETA: 1s - loss: 0.2425 - accuracy: 0.9276\n",
      " 89/469 [====>.........................] - ETA: 1s - loss: 0.2476 - accuracy: 0.9257\n",
      "115/469 [======>.......................] - ETA: 1s - loss: 0.2476 - accuracy: 0.9256\n",
      "140/469 [=======>......................] - ETA: 1s - loss: 0.2405 - accuracy: 0.9272\n",
      "165/469 [=========>....................] - ETA: 1s - loss: 0.2388 - accuracy: 0.9275\n",
      "190/469 [===========>..................] - ETA: 1s - loss: 0.2401 - accuracy: 0.9266\n",
      "202/469 [===========>..................] - ETA: 1s - loss: 0.2389 - accuracy: 0.9269\n",
      "228/469 [=============>................] - ETA: 0s - loss: 0.2375 - accuracy: 0.9277\n",
      "253/469 [===============>..............] - ETA: 0s - loss: 0.2368 - accuracy: 0.9276\n",
      "278/469 [================>.............] - ETA: 0s - loss: 0.2363 - accuracy: 0.9282\n",
      "303/469 [==================>...........] - ETA: 0s - loss: 0.2349 - accuracy: 0.9286\n",
      "330/469 [====================>.........] - ETA: 0s - loss: 0.2372 - accuracy: 0.9280\n",
      "355/469 [=====================>........] - ETA: 0s - loss: 0.2404 - accuracy: 0.9273\n",
      "367/469 [======================>.......] - ETA: 0s - loss: 0.2405 - accuracy: 0.9275\n",
      "392/469 [========================>.....] - ETA: 0s - loss: 0.2389 - accuracy: 0.9279\n",
      "416/469 [=========================>....] - ETA: 0s - loss: 0.2391 - accuracy: 0.9277\n",
      "441/469 [===========================>..] - ETA: 0s - loss: 0.2397 - accuracy: 0.9278\n",
      "466/469 [============================>.] - ETA: 0s - loss: 0.2402 - accuracy: 0.9277\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.2401 - accuracy: 0.9277 - val_loss: 0.1915 - val_accuracy: 0.9433\n",
      "\u001b[36m(train_mnist pid=2634070)\u001b[0m Epoch 3/12\n",
      "  1/469 [..............................] - ETA: 2s - loss: 0.2284 - accuracy: 0.9375\n",
      " 14/469 [..............................] - ETA: 1s - loss: 0.2376 - accuracy: 0.9275\n",
      " 39/469 [=>............................] - ETA: 1s - loss: 0.2205 - accuracy: 0.9337\n",
      " 64/469 [===>..........................] - ETA: 1s - loss: 0.2179 - accuracy: 0.9325\n",
      " 88/469 [====>.........................] - ETA: 1s - loss: 0.2198 - accuracy: 0.9317\n",
      "114/469 [======>.......................] - ETA: 1s - loss: 0.2196 - accuracy: 0.9327\n",
      "140/469 [=======>......................] - ETA: 1s - loss: 0.2209 - accuracy: 0.9324\n",
      "165/469 [=========>....................] - ETA: 1s - loss: 0.2172 - accuracy: 0.9339\n",
      "178/469 [==========>...................] - ETA: 1s - loss: 0.2168 - accuracy: 0.9339\n",
      "203/469 [===========>..................] - ETA: 1s - loss: 0.2162 - accuracy: 0.9344\n",
      "228/469 [=============>................] - ETA: 0s - loss: 0.2136 - accuracy: 0.9349\n",
      "252/469 [===============>..............] - ETA: 0s - loss: 0.2156 - accuracy: 0.9345\n",
      "279/469 [================>.............] - ETA: 0s - loss: 0.2170 - accuracy: 0.9343\n",
      "305/469 [==================>...........] - ETA: 0s - loss: 0.2173 - accuracy: 0.9343\n",
      "317/469 [===================>..........] - ETA: 0s - loss: 0.2176 - accuracy: 0.9341\n",
      "342/469 [====================>.........] - ETA: 0s - loss: 0.2206 - accuracy: 0.9333\n",
      "367/469 [======================>.......] - ETA: 0s - loss: 0.2207 - accuracy: 0.9335\n",
      "393/469 [========================>.....] - ETA: 0s - loss: 0.2212 - accuracy: 0.9334\n",
      "419/469 [=========================>....] - ETA: 0s - loss: 0.2213 - accuracy: 0.9336\n",
      "444/469 [===========================>..] - ETA: 0s - loss: 0.2211 - accuracy: 0.9339\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.2215 - accuracy: 0.9339\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.2215 - accuracy: 0.9339 - val_loss: 0.1543 - val_accuracy: 0.9545\n",
      "\u001b[36m(train_mnist pid=2634070)\u001b[0m Epoch 4/12\n",
      " 14/469 [..............................] - ETA: 1s - loss: 0.1901 - accuracy: 0.9436\n",
      " 39/469 [=>............................] - ETA: 1s - loss: 0.1974 - accuracy: 0.9407\n",
      " 65/469 [===>..........................] - ETA: 1s - loss: 0.1971 - accuracy: 0.9411\n",
      " 78/469 [===>..........................] - ETA: 1s - loss: 0.1944 - accuracy: 0.9412\n",
      "104/469 [=====>........................] - ETA: 1s - loss: 0.1950 - accuracy: 0.9404\n",
      "129/469 [=======>......................] - ETA: 1s - loss: 0.2045 - accuracy: 0.9376\n",
      "152/469 [========>.....................] - ETA: 1s - loss: 0.2058 - accuracy: 0.9374\n",
      "176/469 [==========>...................] - ETA: 1s - loss: 0.2077 - accuracy: 0.9378\n",
      "201/469 [===========>..................] - ETA: 1s - loss: 0.2074 - accuracy: 0.9381\n",
      "226/469 [=============>................] - ETA: 1s - loss: 0.2057 - accuracy: 0.9382\n",
      "238/469 [==============>...............] - ETA: 0s - loss: 0.2071 - accuracy: 0.9379\n",
      "263/469 [===============>..............] - ETA: 0s - loss: 0.2096 - accuracy: 0.9374\n",
      "289/469 [=================>............] - ETA: 0s - loss: 0.2143 - accuracy: 0.9365\n",
      "315/469 [===================>..........] - ETA: 0s - loss: 0.2147 - accuracy: 0.9366\n",
      "341/469 [====================>.........] - ETA: 0s - loss: 0.2162 - accuracy: 0.9361\n",
      "367/469 [======================>.......] - ETA: 0s - loss: 0.2150 - accuracy: 0.9365\n",
      "392/469 [========================>.....] - ETA: 0s - loss: 0.2146 - accuracy: 0.9367\n",
      "428/469 [==========================>...] - ETA: 0s - loss: 0.2114 - accuracy: 0.9372\n",
      "454/469 [============================>.] - ETA: 0s - loss: 0.2113 - accuracy: 0.9373\n",
      "466/469 [============================>.] - ETA: 0s - loss: 0.2112 - accuracy: 0.9372\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.2111 - accuracy: 0.9372 - val_loss: 0.1481 - val_accuracy: 0.9594\n",
      "\u001b[36m(train_mnist pid=2634070)\u001b[0m Epoch 5/12\n",
      " 15/469 [..............................] - ETA: 1s - loss: 0.2399 - accuracy: 0.9354\n",
      " 40/469 [=>............................] - ETA: 1s - loss: 0.2247 - accuracy: 0.9344\n",
      " 63/469 [===>..........................] - ETA: 1s - loss: 0.2162 - accuracy: 0.9355\n",
      " 76/469 [===>..........................] - ETA: 1s - loss: 0.2070 - accuracy: 0.9381\n",
      "101/469 [=====>........................] - ETA: 1s - loss: 0.1982 - accuracy: 0.9396\n",
      "125/469 [======>.......................] - ETA: 1s - loss: 0.1992 - accuracy: 0.9396\n",
      "150/469 [========>.....................] - ETA: 1s - loss: 0.1955 - accuracy: 0.9404\n",
      "174/469 [==========>...................] - ETA: 1s - loss: 0.1955 - accuracy: 0.9410\n",
      "198/469 [===========>..................] - ETA: 1s - loss: 0.2000 - accuracy: 0.9404\n",
      "210/469 [============>.................] - ETA: 1s - loss: 0.1985 - accuracy: 0.9408\n",
      "235/469 [==============>...............] - ETA: 0s - loss: 0.1982 - accuracy: 0.9406\n",
      "260/469 [===============>..............] - ETA: 0s - loss: 0.1944 - accuracy: 0.9410\n",
      "285/469 [=================>............] - ETA: 0s - loss: 0.1949 - accuracy: 0.9408\n",
      "310/469 [==================>...........] - ETA: 0s - loss: 0.1971 - accuracy: 0.9405\n",
      "334/469 [====================>.........] - ETA: 0s - loss: 0.1950 - accuracy: 0.9411\n",
      "371/469 [======================>.......] - ETA: 0s - loss: 0.1943 - accuracy: 0.9414\n",
      "398/469 [========================>.....] - ETA: 0s - loss: 0.1945 - accuracy: 0.9414\n",
      "422/469 [=========================>....] - ETA: 0s - loss: 0.1954 - accuracy: 0.9413\n",
      "446/469 [===========================>..] - ETA: 0s - loss: 0.1986 - accuracy: 0.9407\n",
      "458/469 [============================>.] - ETA: 0s - loss: 0.1996 - accuracy: 0.9406\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.2004 - accuracy: 0.9402 - val_loss: 0.1401 - val_accuracy: 0.9629\n",
      "\u001b[36m(train_mnist pid=2634070)\u001b[0m Epoch 6/12\n",
      " 14/469 [..............................] - ETA: 1s - loss: 0.2092 - accuracy: 0.9386\n",
      " 39/469 [=>............................] - ETA: 1s - loss: 0.2184 - accuracy: 0.9379\n",
      " 75/469 [===>..........................] - ETA: 1s - loss: 0.2133 - accuracy: 0.9396\n",
      " 99/469 [=====>........................] - ETA: 1s - loss: 0.1979 - accuracy: 0.9424\n",
      "124/469 [======>.......................] - ETA: 1s - loss: 0.1941 - accuracy: 0.9426\n",
      "150/469 [========>.....................] - ETA: 1s - loss: 0.1953 - accuracy: 0.9430\n",
      "176/469 [==========>...................] - ETA: 1s - loss: 0.1994 - accuracy: 0.9418\n",
      "200/469 [===========>..................] - ETA: 1s - loss: 0.2041 - accuracy: 0.9414\n",
      "212/469 [============>.................] - ETA: 1s - loss: 0.2057 - accuracy: 0.9411\n",
      "238/469 [==============>...............] - ETA: 0s - loss: 0.2095 - accuracy: 0.9404\n",
      "264/469 [===============>..............] - ETA: 0s - loss: 0.2091 - accuracy: 0.9403\n",
      "290/469 [=================>............] - ETA: 0s - loss: 0.2109 - accuracy: 0.9398\n",
      "317/469 [===================>..........] - ETA: 0s - loss: 0.2098 - accuracy: 0.9401\n",
      "341/469 [====================>.........] - ETA: 0s - loss: 0.2107 - accuracy: 0.9400\n",
      "366/469 [======================>.......] - ETA: 0s - loss: 0.2091 - accuracy: 0.9403\n",
      "391/469 [========================>.....] - ETA: 0s - loss: 0.2081 - accuracy: 0.9407\n",
      "416/469 [=========================>....] - ETA: 0s - loss: 0.2078 - accuracy: 0.9406\n",
      "428/469 [==========================>...] - ETA: 0s - loss: 0.2070 - accuracy: 0.9406\n",
      "453/469 [===========================>..] - ETA: 0s - loss: 0.2057 - accuracy: 0.9407\n",
      "466/469 [============================>.] - ETA: 0s - loss: 0.2051 - accuracy: 0.9407\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.2047 - accuracy: 0.9408 - val_loss: 0.1440 - val_accuracy: 0.9618\n",
      "\u001b[36m(train_mnist pid=2634070)\u001b[0m Epoch 7/12\n",
      " 14/469 [..............................] - ETA: 1s - loss: 0.1651 - accuracy: 0.9492\n",
      " 38/469 [=>............................] - ETA: 1s - loss: 0.1798 - accuracy: 0.9488\n",
      " 62/469 [==>...........................] - ETA: 1s - loss: 0.1896 - accuracy: 0.9462\n",
      " 74/469 [===>..........................] - ETA: 1s - loss: 0.1896 - accuracy: 0.9451\n",
      " 99/469 [=====>........................] - ETA: 1s - loss: 0.1968 - accuracy: 0.9430\n",
      "123/469 [======>.......................] - ETA: 1s - loss: 0.1991 - accuracy: 0.9421\n",
      "148/469 [========>.....................] - ETA: 1s - loss: 0.2028 - accuracy: 0.9417\n",
      "173/469 [==========>...................] - ETA: 1s - loss: 0.2120 - accuracy: 0.9398\n",
      "198/469 [===========>..................] - ETA: 1s - loss: 0.2149 - accuracy: 0.9395\n",
      "224/469 [=============>................] - ETA: 1s - loss: 0.2158 - accuracy: 0.9397\n",
      "262/469 [===============>..............] - ETA: 0s - loss: 0.2222 - accuracy: 0.9371\n",
      "286/469 [=================>............] - ETA: 0s - loss: 0.2210 - accuracy: 0.9370\n",
      "312/469 [==================>...........] - ETA: 0s - loss: 0.2216 - accuracy: 0.9372\n",
      "336/469 [====================>.........] - ETA: 0s - loss: 0.2247 - accuracy: 0.9363\n",
      "360/469 [======================>.......] - ETA: 0s - loss: 0.2262 - accuracy: 0.9354\n",
      "384/469 [=======================>......] - ETA: 0s - loss: 0.2244 - accuracy: 0.9358\n",
      "407/469 [=========================>....] - ETA: 0s - loss: 0.2218 - accuracy: 0.9363\n",
      "443/469 [===========================>..] - ETA: 0s - loss: 0.2232 - accuracy: 0.9363\n",
      "468/469 [============================>.] - ETA: 0s - loss: 0.2222 - accuracy: 0.9364\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.2220 - accuracy: 0.9364 - val_loss: 0.1644 - val_accuracy: 0.9545\n",
      "\u001b[36m(train_mnist pid=2634070)\u001b[0m Epoch 8/12\n",
      "  1/469 [..............................] - ETA: 2s - loss: 0.3507 - accuracy: 0.9219\n",
      " 27/469 [>.............................] - ETA: 1s - loss: 0.2191 - accuracy: 0.9326\n",
      " 52/469 [==>...........................] - ETA: 1s - loss: 0.2145 - accuracy: 0.9378\n",
      " 77/469 [===>..........................] - ETA: 1s - loss: 0.2112 - accuracy: 0.9380\n",
      "102/469 [=====>........................] - ETA: 1s - loss: 0.1969 - accuracy: 0.9417\n",
      "127/469 [=======>......................] - ETA: 1s - loss: 0.1926 - accuracy: 0.9430\n",
      "140/469 [=======>......................] - ETA: 1s - loss: 0.1902 - accuracy: 0.9435\n",
      "165/469 [=========>....................] - ETA: 1s - loss: 0.1993 - accuracy: 0.9415\n",
      "189/469 [===========>..................] - ETA: 1s - loss: 0.2029 - accuracy: 0.9399\n",
      "213/469 [============>.................] - ETA: 1s - loss: 0.2051 - accuracy: 0.9398\n",
      "237/469 [==============>...............] - ETA: 0s - loss: 0.2102 - accuracy: 0.9385\n",
      "262/469 [===============>..............] - ETA: 0s - loss: 0.2139 - accuracy: 0.9381\n",
      "286/469 [=================>............] - ETA: 0s - loss: 0.2171 - accuracy: 0.9375\n",
      "323/469 [===================>..........] - ETA: 0s - loss: 0.2144 - accuracy: 0.9379\n",
      "348/469 [=====================>........] - ETA: 0s - loss: 0.2168 - accuracy: 0.9377\n",
      "374/469 [======================>.......] - ETA: 0s - loss: 0.2156 - accuracy: 0.9376\n",
      "398/469 [========================>.....] - ETA: 0s - loss: 0.2151 - accuracy: 0.9379\n",
      "423/469 [==========================>...] - ETA: 0s - loss: 0.2135 - accuracy: 0.9384\n",
      "448/469 [===========================>..] - ETA: 0s - loss: 0.2144 - accuracy: 0.9385\n",
      "461/469 [============================>.] - ETA: 0s - loss: 0.2146 - accuracy: 0.9385\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.2151 - accuracy: 0.9384 - val_loss: 0.1708 - val_accuracy: 0.9599\n",
      "\u001b[36m(train_mnist pid=2634070)\u001b[0m Epoch 9/12\n",
      "  1/469 [..............................] - ETA: 1s - loss: 0.1990 - accuracy: 0.9375\n",
      " 28/469 [>.............................] - ETA: 1s - loss: 0.2107 - accuracy: 0.9436\n",
      " 51/469 [==>...........................] - ETA: 1s - loss: 0.2159 - accuracy: 0.9389\n",
      " 76/469 [===>..........................] - ETA: 1s - loss: 0.1946 - accuracy: 0.9441\n",
      "101/469 [=====>........................] - ETA: 1s - loss: 0.1920 - accuracy: 0.9462\n",
      "126/469 [=======>......................] - ETA: 1s - loss: 0.1923 - accuracy: 0.9466\n",
      "150/469 [========>.....................] - ETA: 1s - loss: 0.1942 - accuracy: 0.9456\n",
      "188/469 [===========>..................] - ETA: 1s - loss: 0.1976 - accuracy: 0.9443\n",
      "213/469 [============>.................] - ETA: 1s - loss: 0.2009 - accuracy: 0.9434\n",
      "238/469 [==============>...............] - ETA: 0s - loss: 0.2010 - accuracy: 0.9433\n",
      "263/469 [===============>..............] - ETA: 0s - loss: 0.1973 - accuracy: 0.9442\n",
      "287/469 [=================>............] - ETA: 0s - loss: 0.1985 - accuracy: 0.9441\n",
      "311/469 [==================>...........] - ETA: 0s - loss: 0.1986 - accuracy: 0.9444\n",
      "348/469 [=====================>........] - ETA: 0s - loss: 0.2004 - accuracy: 0.9437\n",
      "374/469 [======================>.......] - ETA: 0s - loss: 0.2039 - accuracy: 0.9425\n",
      "398/469 [========================>.....] - ETA: 0s - loss: 0.2074 - accuracy: 0.9417\n",
      "423/469 [==========================>...] - ETA: 0s - loss: 0.2099 - accuracy: 0.9410\n",
      "448/469 [===========================>..] - ETA: 0s - loss: 0.2095 - accuracy: 0.9411\n",
      "459/469 [============================>.] - ETA: 0s - loss: 0.2105 - accuracy: 0.9411\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.2110 - accuracy: 0.9408 - val_loss: 0.1962 - val_accuracy: 0.9545\n",
      "\u001b[36m(train_mnist pid=2634070)\u001b[0m Epoch 10/12\n",
      " 15/469 [..............................] - ETA: 1s - loss: 0.1965 - accuracy: 0.9448\n",
      " 42/469 [=>............................] - ETA: 1s - loss: 0.2175 - accuracy: 0.9448\n",
      " 54/469 [==>...........................] - ETA: 1s - loss: 0.2151 - accuracy: 0.9440\n",
      " 78/469 [===>..........................] - ETA: 1s - loss: 0.2212 - accuracy: 0.9410\n",
      "103/469 [=====>........................] - ETA: 1s - loss: 0.2109 - accuracy: 0.9416\n",
      "126/469 [=======>......................] - ETA: 1s - loss: 0.2210 - accuracy: 0.9406\n",
      "152/469 [========>.....................] - ETA: 1s - loss: 0.2149 - accuracy: 0.9419\n",
      "178/469 [==========>...................] - ETA: 1s - loss: 0.2172 - accuracy: 0.9410\n",
      "202/469 [===========>..................] - ETA: 1s - loss: 0.2110 - accuracy: 0.9428\n",
      "241/469 [==============>...............] - ETA: 0s - loss: 0.2074 - accuracy: 0.9431\n",
      "267/469 [================>.............] - ETA: 0s - loss: 0.2068 - accuracy: 0.9427\n",
      "291/469 [=================>............] - ETA: 0s - loss: 0.2023 - accuracy: 0.9435\n",
      "316/469 [===================>..........] - ETA: 0s - loss: 0.2031 - accuracy: 0.9432\n",
      "343/469 [====================>.........] - ETA: 0s - loss: 0.2028 - accuracy: 0.9435\n",
      "367/469 [======================>.......] - ETA: 0s - loss: 0.2020 - accuracy: 0.9433\n",
      "391/469 [========================>.....] - ETA: 0s - loss: 0.2028 - accuracy: 0.9431\n",
      "403/469 [========================>.....] - ETA: 0s - loss: 0.2032 - accuracy: 0.9430\n",
      "428/469 [==========================>...] - ETA: 0s - loss: 0.2038 - accuracy: 0.9430\n",
      "453/469 [===========================>..] - ETA: 0s - loss: 0.2043 - accuracy: 0.9428\n",
      "465/469 [============================>.] - ETA: 0s - loss: 0.2065 - accuracy: 0.9424\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.2063 - accuracy: 0.9423 - val_loss: 0.1851 - val_accuracy: 0.9585\n",
      "\u001b[36m(train_mnist pid=2634070)\u001b[0m Epoch 11/12\n",
      " 15/469 [..............................] - ETA: 1s - loss: 0.2035 - accuracy: 0.9417\n",
      " 41/469 [=>............................] - ETA: 1s - loss: 0.1960 - accuracy: 0.9478\n",
      " 66/469 [===>..........................] - ETA: 1s - loss: 0.2040 - accuracy: 0.9435\n",
      " 89/469 [====>.........................] - ETA: 1s - loss: 0.2086 - accuracy: 0.9432\n",
      "124/469 [======>.......................] - ETA: 1s - loss: 0.2023 - accuracy: 0.9452\n",
      "148/469 [========>.....................] - ETA: 1s - loss: 0.2034 - accuracy: 0.9444\n",
      "173/469 [==========>...................] - ETA: 1s - loss: 0.1996 - accuracy: 0.9444\n",
      "198/469 [===========>..................] - ETA: 1s - loss: 0.2011 - accuracy: 0.9433\n",
      "224/469 [=============>................] - ETA: 1s - loss: 0.2003 - accuracy: 0.9434\n",
      "250/469 [==============>...............] - ETA: 0s - loss: 0.2012 - accuracy: 0.9431\n",
      "262/469 [===============>..............] - ETA: 0s - loss: 0.1985 - accuracy: 0.9437\n",
      "289/469 [=================>............] - ETA: 0s - loss: 0.2017 - accuracy: 0.9433\n",
      "314/469 [===================>..........] - ETA: 0s - loss: 0.2068 - accuracy: 0.9425\n",
      "340/469 [====================>.........] - ETA: 0s - loss: 0.2100 - accuracy: 0.9418\n",
      "365/469 [======================>.......] - ETA: 0s - loss: 0.2123 - accuracy: 0.9412\n",
      "390/469 [=======================>......] - ETA: 0s - loss: 0.2143 - accuracy: 0.9410\n",
      "416/469 [=========================>....] - ETA: 0s - loss: 0.2131 - accuracy: 0.9410\n",
      "442/469 [===========================>..] - ETA: 0s - loss: 0.2148 - accuracy: 0.9406\n",
      "454/469 [============================>.] - ETA: 0s - loss: 0.2166 - accuracy: 0.9401\n",
      "467/469 [============================>.] - ETA: 0s - loss: 0.2175 - accuracy: 0.9398\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.2175 - accuracy: 0.9398 - val_loss: 0.1923 - val_accuracy: 0.9572\n",
      "\u001b[36m(train_mnist pid=2634070)\u001b[0m Epoch 12/12\n",
      " 14/469 [..............................] - ETA: 1s - loss: 0.2189 - accuracy: 0.9448\n",
      " 40/469 [=>............................] - ETA: 1s - loss: 0.1849 - accuracy: 0.9494\n",
      " 66/469 [===>..........................] - ETA: 1s - loss: 0.1924 - accuracy: 0.9464\n",
      " 78/469 [===>..........................] - ETA: 1s - loss: 0.1900 - accuracy: 0.9473\n",
      "102/469 [=====>........................] - ETA: 1s - loss: 0.1963 - accuracy: 0.9450\n",
      "128/469 [=======>......................] - ETA: 1s - loss: 0.1881 - accuracy: 0.9463\n",
      "152/469 [========>.....................] - ETA: 1s - loss: 0.1839 - accuracy: 0.9478\n",
      "178/469 [==========>...................] - ETA: 1s - loss: 0.1841 - accuracy: 0.9482\n",
      "204/469 [============>.................] - ETA: 1s - loss: 0.1851 - accuracy: 0.9482\n",
      "230/469 [=============>................] - ETA: 0s - loss: 0.1875 - accuracy: 0.9478\n",
      "266/469 [================>.............] - ETA: 0s - loss: 0.1884 - accuracy: 0.9475\n",
      "291/469 [=================>............] - ETA: 0s - loss: 0.1877 - accuracy: 0.9471\n",
      "316/469 [===================>..........] - ETA: 0s - loss: 0.1878 - accuracy: 0.9468\n",
      "342/469 [====================>.........] - ETA: 0s - loss: 0.1866 - accuracy: 0.9467\n",
      "368/469 [======================>.......] - ETA: 0s - loss: 0.1924 - accuracy: 0.9458\n",
      "394/469 [========================>.....] - ETA: 0s - loss: 0.1938 - accuracy: 0.9454\n",
      "419/469 [=========================>....] - ETA: 0s - loss: 0.1966 - accuracy: 0.9450\n",
      "431/469 [==========================>...] - ETA: 0s - loss: 0.1989 - accuracy: 0.9441\n",
      "455/469 [============================>.] - ETA: 0s - loss: 0.2000 - accuracy: 0.9441\n",
      "467/469 [============================>.] - ETA: 0s - loss: 0.2014 - accuracy: 0.9441\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.2016 - accuracy: 0.9442 - val_loss: 0.1910 - val_accuracy: 0.9589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=2636148)\u001b[0m 2023-12-05 09:48:36.351208: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=2636148)\u001b[0m 2023-12-05 09:48:36.390195: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=2636148)\u001b[0m 2023-12-05 09:48:36.390222: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=2636148)\u001b[0m 2023-12-05 09:48:36.391259: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=2636148)\u001b[0m 2023-12-05 09:48:36.397121: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=2636148)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=2636148)\u001b[0m 2023-12-05 09:48:37.099138: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=2636148)\u001b[0m 2023-12-05 09:48:38.405422: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_mnist pid=2636148)\u001b[0m Epoch 1/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_mnist pid=2636148)\u001b[0m 2023-12-05 09:48:40.088592: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=2636148)\u001b[0m 2023-12-05 09:48:41.057778: I external/local_xla/xla/service/service.cc:168] XLA service 0x14781830c0c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=2636148)\u001b[0m 2023-12-05 09:48:41.057822: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=2636148)\u001b[0m 2023-12-05 09:48:41.067655: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=2636148)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=2636148)\u001b[0m I0000 00:00:1701787721.181994 2636467 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1/469 [..............................] - ETA: 17:37 - loss: 2.3049 - accuracy: 0.1094\n",
      " 19/469 [>.............................] - ETA: 2s - loss: 9.0065 - accuracy: 0.5058  \n",
      " 39/469 [=>............................] - ETA: 2s - loss: 4.6923 - accuracy: 0.6705\n",
      " 58/469 [==>...........................] - ETA: 2s - loss: 3.2901 - accuracy: 0.7380\n",
      " 77/469 [===>..........................] - ETA: 2s - loss: 2.5732 - accuracy: 0.7751\n",
      " 97/469 [=====>........................] - ETA: 2s - loss: 2.1118 - accuracy: 0.8012\n",
      "106/469 [=====>........................] - ETA: 2s - loss: 1.9586 - accuracy: 0.8109\n",
      "126/469 [=======>......................] - ETA: 1s - loss: 1.6987 - accuracy: 0.8253\n",
      "146/469 [========>.....................] - ETA: 1s - loss: 1.5046 - accuracy: 0.8378\n",
      "166/469 [=========>....................] - ETA: 1s - loss: 1.3607 - accuracy: 0.8461\n",
      "186/469 [==========>...................] - ETA: 1s - loss: 1.2459 - accuracy: 0.8525\n",
      "206/469 [============>.................] - ETA: 1s - loss: 1.1508 - accuracy: 0.8593\n",
      "226/469 [=============>................] - ETA: 1s - loss: 1.0741 - accuracy: 0.8639\n",
      "245/469 [==============>...............] - ETA: 1s - loss: 1.0115 - accuracy: 0.8680\n",
      "255/469 [===============>..............] - ETA: 1s - loss: 0.9816 - accuracy: 0.8700\n",
      "274/469 [================>.............] - ETA: 1s - loss: 0.9319 - accuracy: 0.8736\n",
      "292/469 [=================>............] - ETA: 0s - loss: 0.8891 - accuracy: 0.8771\n",
      "312/469 [==================>...........] - ETA: 0s - loss: 0.8506 - accuracy: 0.8796\n",
      "332/469 [====================>.........] - ETA: 0s - loss: 0.8157 - accuracy: 0.8821\n",
      "351/469 [=====================>........] - ETA: 0s - loss: 0.7860 - accuracy: 0.8844\n",
      "370/469 [======================>.......] - ETA: 0s - loss: 0.7583 - accuracy: 0.8866\n",
      "379/469 [=======================>......] - ETA: 0s - loss: 0.7458 - accuracy: 0.8878\n",
      "398/469 [========================>.....] - ETA: 0s - loss: 0.7231 - accuracy: 0.8891\n",
      "417/469 [=========================>....] - ETA: 0s - loss: 0.6999 - accuracy: 0.8912\n",
      "435/469 [==========================>...] - ETA: 0s - loss: 0.6823 - accuracy: 0.8923\n",
      "454/469 [============================>.] - ETA: 0s - loss: 0.6648 - accuracy: 0.8937\n",
      "463/469 [============================>.] - ETA: 0s - loss: 0.6564 - accuracy: 0.8942\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.6522 - accuracy: 0.8944\n",
      "469/469 [==============================] - 5s 7ms/step - loss: 0.6522 - accuracy: 0.8944 - val_loss: 0.1741 - val_accuracy: 0.9460\n",
      "\u001b[36m(train_mnist pid=2636148)\u001b[0m Epoch 2/12\n",
      " 11/469 [..............................] - ETA: 2s - loss: 0.2129 - accuracy: 0.9354\n",
      " 30/469 [>.............................] - ETA: 2s - loss: 0.2311 - accuracy: 0.9328\n",
      " 50/469 [==>...........................] - ETA: 2s - loss: 0.2306 - accuracy: 0.9291\n",
      " 69/469 [===>..........................] - ETA: 2s - loss: 0.2218 - accuracy: 0.9310\n",
      " 88/469 [====>.........................] - ETA: 2s - loss: 0.2220 - accuracy: 0.9304\n",
      "108/469 [=====>........................] - ETA: 1s - loss: 0.2311 - accuracy: 0.9292\n",
      "118/469 [======>.......................] - ETA: 1s - loss: 0.2323 - accuracy: 0.9290\n",
      "138/469 [=======>......................] - ETA: 1s - loss: 0.2359 - accuracy: 0.9277\n",
      "158/469 [=========>....................] - ETA: 1s - loss: 0.2331 - accuracy: 0.9287\n",
      "178/469 [==========>...................] - ETA: 1s - loss: 0.2349 - accuracy: 0.9278\n",
      "198/469 [===========>..................] - ETA: 1s - loss: 0.2375 - accuracy: 0.9268\n",
      "218/469 [============>.................] - ETA: 1s - loss: 0.2354 - accuracy: 0.9273\n",
      "238/469 [==============>...............] - ETA: 1s - loss: 0.2339 - accuracy: 0.9284\n",
      "257/469 [===============>..............] - ETA: 1s - loss: 0.2308 - accuracy: 0.9293\n",
      "287/469 [=================>............] - ETA: 0s - loss: 0.2306 - accuracy: 0.9294\n",
      "305/469 [==================>...........] - ETA: 0s - loss: 0.2291 - accuracy: 0.9300\n",
      "325/469 [===================>..........] - ETA: 0s - loss: 0.2287 - accuracy: 0.9307\n",
      "345/469 [=====================>........] - ETA: 0s - loss: 0.2280 - accuracy: 0.9310\n",
      "364/469 [======================>.......] - ETA: 0s - loss: 0.2267 - accuracy: 0.9317\n",
      "384/469 [=======================>......] - ETA: 0s - loss: 0.2271 - accuracy: 0.9318\n",
      "403/469 [========================>.....] - ETA: 0s - loss: 0.2274 - accuracy: 0.9316\n",
      "423/469 [==========================>...] - ETA: 0s - loss: 0.2278 - accuracy: 0.9313\n",
      "452/469 [===========================>..] - ETA: 0s - loss: 0.2273 - accuracy: 0.9313\n",
      "462/469 [============================>.] - ETA: 0s - loss: 0.2297 - accuracy: 0.9311\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.2299 - accuracy: 0.9311 - val_loss: 0.1944 - val_accuracy: 0.9426\n",
      "\u001b[36m(train_mnist pid=2636148)\u001b[0m Epoch 3/12\n",
      "  1/469 [..............................] - ETA: 2s - loss: 0.0986 - accuracy: 0.9766\n",
      " 20/469 [>.............................] - ETA: 2s - loss: 0.2231 - accuracy: 0.9355\n",
      " 38/469 [=>............................] - ETA: 2s - loss: 0.2302 - accuracy: 0.9311\n",
      " 57/469 [==>...........................] - ETA: 2s - loss: 0.2280 - accuracy: 0.9319\n",
      " 76/469 [===>..........................] - ETA: 2s - loss: 0.2223 - accuracy: 0.9343\n",
      " 95/469 [=====>........................] - ETA: 2s - loss: 0.2249 - accuracy: 0.9341\n",
      "105/469 [=====>........................] - ETA: 2s - loss: 0.2218 - accuracy: 0.9347\n",
      "124/469 [======>.......................] - ETA: 1s - loss: 0.2176 - accuracy: 0.9354\n",
      "143/469 [========>.....................] - ETA: 1s - loss: 0.2184 - accuracy: 0.9355\n",
      "163/469 [=========>....................] - ETA: 1s - loss: 0.2168 - accuracy: 0.9360\n",
      "181/469 [==========>...................] - ETA: 1s - loss: 0.2175 - accuracy: 0.9360\n",
      "200/469 [===========>..................] - ETA: 1s - loss: 0.2194 - accuracy: 0.9352\n",
      "220/469 [=============>................] - ETA: 1s - loss: 0.2179 - accuracy: 0.9349\n",
      "240/469 [==============>...............] - ETA: 1s - loss: 0.2180 - accuracy: 0.9347\n",
      "259/469 [===============>..............] - ETA: 1s - loss: 0.2161 - accuracy: 0.9357\n",
      "278/469 [================>.............] - ETA: 1s - loss: 0.2159 - accuracy: 0.9358\n",
      "296/469 [=================>............] - ETA: 0s - loss: 0.2171 - accuracy: 0.9360\n",
      "306/469 [==================>...........] - ETA: 0s - loss: 0.2163 - accuracy: 0.9361\n",
      "325/469 [===================>..........] - ETA: 0s - loss: 0.2169 - accuracy: 0.9357\n",
      "344/469 [=====================>........] - ETA: 0s - loss: 0.2192 - accuracy: 0.9349\n",
      "364/469 [======================>.......] - ETA: 0s - loss: 0.2199 - accuracy: 0.9347\n",
      "383/469 [=======================>......] - ETA: 0s - loss: 0.2188 - accuracy: 0.9350\n",
      "401/469 [========================>.....] - ETA: 0s - loss: 0.2204 - accuracy: 0.9346\n",
      "420/469 [=========================>....] - ETA: 0s - loss: 0.2208 - accuracy: 0.9346\n",
      "440/469 [===========================>..] - ETA: 0s - loss: 0.2204 - accuracy: 0.9347\n",
      "450/469 [===========================>..] - ETA: 0s - loss: 0.2195 - accuracy: 0.9349\n",
      "460/469 [============================>.] - ETA: 0s - loss: 0.2198 - accuracy: 0.9347\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.2201 - accuracy: 0.9347 - val_loss: 0.2089 - val_accuracy: 0.9464\n",
      "\u001b[36m(train_mnist pid=2636148)\u001b[0m Epoch 4/12\n",
      " 11/469 [..............................] - ETA: 2s - loss: 0.2158 - accuracy: 0.9276\n",
      " 30/469 [>.............................] - ETA: 2s - loss: 0.2188 - accuracy: 0.9326\n",
      " 49/469 [==>...........................] - ETA: 2s - loss: 0.2183 - accuracy: 0.9327\n",
      " 59/469 [==>...........................] - ETA: 2s - loss: 0.2094 - accuracy: 0.9346\n",
      " 79/469 [====>.........................] - ETA: 2s - loss: 0.2153 - accuracy: 0.9346\n",
      " 98/469 [=====>........................] - ETA: 2s - loss: 0.2186 - accuracy: 0.9346\n",
      "117/469 [======>.......................] - ETA: 1s - loss: 0.2130 - accuracy: 0.9361\n",
      "136/469 [=======>......................] - ETA: 1s - loss: 0.2070 - accuracy: 0.9373\n",
      "156/469 [========>.....................] - ETA: 1s - loss: 0.2032 - accuracy: 0.9386\n",
      "175/469 [==========>...................] - ETA: 1s - loss: 0.1989 - accuracy: 0.9398\n",
      "194/469 [===========>..................] - ETA: 1s - loss: 0.2010 - accuracy: 0.9400\n",
      "213/469 [============>.................] - ETA: 1s - loss: 0.2013 - accuracy: 0.9397\n",
      "223/469 [=============>................] - ETA: 1s - loss: 0.2042 - accuracy: 0.9392\n",
      "243/469 [==============>...............] - ETA: 1s - loss: 0.2027 - accuracy: 0.9396\n",
      "263/469 [===============>..............] - ETA: 1s - loss: 0.2031 - accuracy: 0.9391\n",
      "282/469 [=================>............] - ETA: 1s - loss: 0.2021 - accuracy: 0.9392\n",
      "301/469 [==================>...........] - ETA: 0s - loss: 0.2044 - accuracy: 0.9390\n",
      "321/469 [===================>..........] - ETA: 0s - loss: 0.2026 - accuracy: 0.9394\n",
      "341/469 [====================>.........] - ETA: 0s - loss: 0.2007 - accuracy: 0.9399\n",
      "361/469 [======================>.......] - ETA: 0s - loss: 0.2002 - accuracy: 0.9404\n",
      "371/469 [======================>.......] - ETA: 0s - loss: 0.2016 - accuracy: 0.9402\n",
      "391/469 [========================>.....] - ETA: 0s - loss: 0.2027 - accuracy: 0.9403\n",
      "410/469 [=========================>....] - ETA: 0s - loss: 0.2040 - accuracy: 0.9400\n",
      "429/469 [==========================>...] - ETA: 0s - loss: 0.2044 - accuracy: 0.9396\n",
      "448/469 [===========================>..] - ETA: 0s - loss: 0.2057 - accuracy: 0.9394\n",
      "468/469 [============================>.] - ETA: 0s - loss: 0.2089 - accuracy: 0.9386\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.2091 - accuracy: 0.9385 - val_loss: 0.1999 - val_accuracy: 0.9444\n",
      "\u001b[36m(train_mnist pid=2636148)\u001b[0m Epoch 5/12\n",
      "  1/469 [..............................] - ETA: 2s - loss: 0.2107 - accuracy: 0.9531\n",
      " 21/469 [>.............................] - ETA: 2s - loss: 0.2306 - accuracy: 0.9289\n",
      " 41/469 [=>............................] - ETA: 2s - loss: 0.2254 - accuracy: 0.9341\n",
      " 51/469 [==>...........................] - ETA: 2s - loss: 0.2188 - accuracy: 0.9363\n",
      " 71/469 [===>..........................] - ETA: 2s - loss: 0.2134 - accuracy: 0.9373\n",
      " 91/469 [====>.........................] - ETA: 2s - loss: 0.2076 - accuracy: 0.9397\n",
      "110/469 [======>.......................] - ETA: 1s - loss: 0.2102 - accuracy: 0.9391\n",
      "128/469 [=======>......................] - ETA: 1s - loss: 0.2113 - accuracy: 0.9389\n",
      "148/469 [========>.....................] - ETA: 1s - loss: 0.2160 - accuracy: 0.9378\n",
      "167/469 [=========>....................] - ETA: 1s - loss: 0.2199 - accuracy: 0.9368\n",
      "186/469 [==========>...................] - ETA: 1s - loss: 0.2140 - accuracy: 0.9383\n",
      "206/469 [============>.................] - ETA: 1s - loss: 0.2167 - accuracy: 0.9380\n",
      "226/469 [=============>................] - ETA: 1s - loss: 0.2217 - accuracy: 0.9363\n",
      "236/469 [==============>...............] - ETA: 1s - loss: 0.2214 - accuracy: 0.9364\n",
      "255/469 [===============>..............] - ETA: 1s - loss: 0.2229 - accuracy: 0.9364\n",
      "275/469 [================>.............] - ETA: 1s - loss: 0.2224 - accuracy: 0.9366\n",
      "295/469 [=================>............] - ETA: 0s - loss: 0.2223 - accuracy: 0.9362\n",
      "315/469 [===================>..........] - ETA: 0s - loss: 0.2210 - accuracy: 0.9364\n",
      "335/469 [====================>.........] - ETA: 0s - loss: 0.2212 - accuracy: 0.9361\n",
      "354/469 [=====================>........] - ETA: 0s - loss: 0.2187 - accuracy: 0.9367\n",
      "374/469 [======================>.......] - ETA: 0s - loss: 0.2170 - accuracy: 0.9372\n",
      "384/469 [=======================>......] - ETA: 0s - loss: 0.2158 - accuracy: 0.9376\n",
      "403/469 [========================>.....] - ETA: 0s - loss: 0.2155 - accuracy: 0.9378\n",
      "422/469 [=========================>....] - ETA: 0s - loss: 0.2154 - accuracy: 0.9379\n",
      "442/469 [===========================>..] - ETA: 0s - loss: 0.2154 - accuracy: 0.9382\n",
      "462/469 [============================>.] - ETA: 0s - loss: 0.2145 - accuracy: 0.9385\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.2144 - accuracy: 0.9385 - val_loss: 0.1841 - val_accuracy: 0.9541\n",
      "\u001b[36m(train_mnist pid=2636148)\u001b[0m Epoch 6/12\n",
      " 11/469 [..............................] - ETA: 2s - loss: 0.1880 - accuracy: 0.9453\n",
      " 30/469 [>.............................] - ETA: 2s - loss: 0.1866 - accuracy: 0.9445\n",
      " 50/469 [==>...........................] - ETA: 2s - loss: 0.1863 - accuracy: 0.9434\n",
      " 59/469 [==>...........................] - ETA: 2s - loss: 0.1803 - accuracy: 0.9447\n",
      " 78/469 [===>..........................] - ETA: 2s - loss: 0.1845 - accuracy: 0.9444\n",
      " 97/469 [=====>........................] - ETA: 2s - loss: 0.1915 - accuracy: 0.9426\n",
      "116/469 [======>.......................] - ETA: 1s - loss: 0.1928 - accuracy: 0.9421\n",
      "136/469 [=======>......................] - ETA: 1s - loss: 0.1957 - accuracy: 0.9422\n",
      "154/469 [========>.....................] - ETA: 1s - loss: 0.2018 - accuracy: 0.9405\n",
      "174/469 [==========>...................] - ETA: 1s - loss: 0.2070 - accuracy: 0.9397\n",
      "194/469 [===========>..................] - ETA: 1s - loss: 0.2072 - accuracy: 0.9401\n",
      "203/469 [===========>..................] - ETA: 1s - loss: 0.2077 - accuracy: 0.9402\n",
      "223/469 [=============>................] - ETA: 1s - loss: 0.2078 - accuracy: 0.9401\n",
      "243/469 [==============>...............] - ETA: 1s - loss: 0.2069 - accuracy: 0.9407\n",
      "262/469 [===============>..............] - ETA: 1s - loss: 0.2056 - accuracy: 0.9411\n",
      "281/469 [================>.............] - ETA: 1s - loss: 0.2042 - accuracy: 0.9411\n",
      "301/469 [==================>...........] - ETA: 0s - loss: 0.2024 - accuracy: 0.9414\n",
      "320/469 [===================>..........] - ETA: 0s - loss: 0.2006 - accuracy: 0.9419\n",
      "348/469 [=====================>........] - ETA: 0s - loss: 0.2053 - accuracy: 0.9408\n",
      "367/469 [======================>.......] - ETA: 0s - loss: 0.2086 - accuracy: 0.9402\n",
      "386/469 [=======================>......] - ETA: 0s - loss: 0.2084 - accuracy: 0.9405\n",
      "405/469 [========================>.....] - ETA: 0s - loss: 0.2083 - accuracy: 0.9404\n",
      "425/469 [==========================>...] - ETA: 0s - loss: 0.2113 - accuracy: 0.9399\n",
      "444/469 [===========================>..] - ETA: 0s - loss: 0.2119 - accuracy: 0.9396\n",
      "462/469 [============================>.] - ETA: 0s - loss: 0.2123 - accuracy: 0.9395\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.2117 - accuracy: 0.9398 - val_loss: 0.1886 - val_accuracy: 0.9525\n",
      "\u001b[36m(train_mnist pid=2636148)\u001b[0m Epoch 7/12\n",
      " 11/469 [..............................] - ETA: 2s - loss: 0.1743 - accuracy: 0.9474\n",
      " 31/469 [>.............................] - ETA: 2s - loss: 0.1889 - accuracy: 0.9443\n",
      " 51/469 [==>...........................] - ETA: 2s - loss: 0.1776 - accuracy: 0.9470\n",
      " 70/469 [===>..........................] - ETA: 2s - loss: 0.1789 - accuracy: 0.9463\n",
      " 80/469 [====>.........................] - ETA: 2s - loss: 0.1736 - accuracy: 0.9481\n",
      " 99/469 [=====>........................] - ETA: 1s - loss: 0.1771 - accuracy: 0.9471\n",
      "118/469 [======>.......................] - ETA: 1s - loss: 0.1801 - accuracy: 0.9459\n",
      "136/469 [=======>......................] - ETA: 1s - loss: 0.1818 - accuracy: 0.9455\n",
      "156/469 [========>.....................] - ETA: 1s - loss: 0.1807 - accuracy: 0.9457\n",
      "176/469 [==========>...................] - ETA: 1s - loss: 0.1810 - accuracy: 0.9458\n",
      "196/469 [===========>..................] - ETA: 1s - loss: 0.1857 - accuracy: 0.9446\n",
      "225/469 [=============>................] - ETA: 1s - loss: 0.1875 - accuracy: 0.9442\n",
      "245/469 [==============>...............] - ETA: 1s - loss: 0.1866 - accuracy: 0.9447\n",
      "264/469 [===============>..............] - ETA: 1s - loss: 0.1889 - accuracy: 0.9440\n",
      "282/469 [=================>............] - ETA: 1s - loss: 0.1885 - accuracy: 0.9445\n",
      "300/469 [==================>...........] - ETA: 0s - loss: 0.1913 - accuracy: 0.9440\n",
      "320/469 [===================>..........] - ETA: 0s - loss: 0.1937 - accuracy: 0.9436\n",
      "340/469 [====================>.........] - ETA: 0s - loss: 0.1940 - accuracy: 0.9436\n",
      "370/469 [======================>.......] - ETA: 0s - loss: 0.1975 - accuracy: 0.9430\n",
      "390/469 [=======================>......] - ETA: 0s - loss: 0.1996 - accuracy: 0.9424\n",
      "408/469 [=========================>....] - ETA: 0s - loss: 0.2015 - accuracy: 0.9420\n",
      "427/469 [==========================>...] - ETA: 0s - loss: 0.2020 - accuracy: 0.9418\n",
      "446/469 [===========================>..] - ETA: 0s - loss: 0.2055 - accuracy: 0.9411\n",
      "466/469 [============================>.] - ETA: 0s - loss: 0.2083 - accuracy: 0.9405\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.2090 - accuracy: 0.9405 - val_loss: 0.2843 - val_accuracy: 0.9176\n",
      "\u001b[36m(train_mnist pid=2636148)\u001b[0m Epoch 8/12\n",
      "  1/469 [..............................] - ETA: 2s - loss: 0.2666 - accuracy: 0.9141\n",
      " 21/469 [>.............................] - ETA: 2s - loss: 0.2326 - accuracy: 0.9342\n",
      " 41/469 [=>............................] - ETA: 2s - loss: 0.2160 - accuracy: 0.9386\n",
      " 51/469 [==>...........................] - ETA: 2s - loss: 0.2107 - accuracy: 0.9418\n",
      " 71/469 [===>..........................] - ETA: 2s - loss: 0.2179 - accuracy: 0.9417\n",
      " 89/469 [====>.........................] - ETA: 2s - loss: 0.2075 - accuracy: 0.9433\n",
      "108/469 [=====>........................] - ETA: 1s - loss: 0.2015 - accuracy: 0.9450\n",
      "127/469 [=======>......................] - ETA: 1s - loss: 0.1965 - accuracy: 0.9456\n",
      "146/469 [========>.....................] - ETA: 1s - loss: 0.1967 - accuracy: 0.9449\n",
      "166/469 [=========>....................] - ETA: 1s - loss: 0.2031 - accuracy: 0.9442\n",
      "186/469 [==========>...................] - ETA: 1s - loss: 0.2042 - accuracy: 0.9437\n",
      "206/469 [============>.................] - ETA: 1s - loss: 0.2037 - accuracy: 0.9430\n",
      "215/469 [============>.................] - ETA: 1s - loss: 0.2093 - accuracy: 0.9421\n",
      "235/469 [==============>...............] - ETA: 1s - loss: 0.2367 - accuracy: 0.9381\n",
      "255/469 [===============>..............] - ETA: 1s - loss: 0.2461 - accuracy: 0.9350\n",
      "273/469 [================>.............] - ETA: 1s - loss: 0.2510 - accuracy: 0.9339\n",
      "293/469 [=================>............] - ETA: 0s - loss: 0.2519 - accuracy: 0.9330\n",
      "313/469 [===================>..........] - ETA: 0s - loss: 0.2539 - accuracy: 0.9322\n",
      "333/469 [====================>.........] - ETA: 0s - loss: 0.2548 - accuracy: 0.9314\n",
      "342/469 [====================>.........] - ETA: 0s - loss: 0.2534 - accuracy: 0.9317\n",
      "362/469 [======================>.......] - ETA: 0s - loss: 0.2515 - accuracy: 0.9318\n",
      "382/469 [=======================>......] - ETA: 0s - loss: 0.2516 - accuracy: 0.9318\n",
      "402/469 [========================>.....] - ETA: 0s - loss: 0.2518 - accuracy: 0.9314\n",
      "422/469 [=========================>....] - ETA: 0s - loss: 0.2517 - accuracy: 0.9316\n",
      "442/469 [===========================>..] - ETA: 0s - loss: 0.2505 - accuracy: 0.9316\n",
      "462/469 [============================>.] - ETA: 0s - loss: 0.2498 - accuracy: 0.9318\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.2497 - accuracy: 0.9318 - val_loss: 0.2538 - val_accuracy: 0.9469\n",
      "\u001b[36m(train_mnist pid=2636148)\u001b[0m Epoch 9/12\n",
      " 20/469 [>.............................] - ETA: 2s - loss: 0.2355 - accuracy: 0.9383\n",
      " 40/469 [=>............................] - ETA: 2s - loss: 0.2385 - accuracy: 0.9375\n",
      " 59/469 [==>...........................] - ETA: 2s - loss: 0.2239 - accuracy: 0.9408\n",
      " 79/469 [====>.........................] - ETA: 2s - loss: 0.2179 - accuracy: 0.9413\n",
      " 98/469 [=====>........................] - ETA: 1s - loss: 0.2105 - accuracy: 0.9428\n",
      "118/469 [======>.......................] - ETA: 1s - loss: 0.2190 - accuracy: 0.9407\n",
      "136/469 [=======>......................] - ETA: 1s - loss: 0.2182 - accuracy: 0.9405\n",
      "146/469 [========>.....................] - ETA: 1s - loss: 0.2169 - accuracy: 0.9406\n",
      "165/469 [=========>....................] - ETA: 1s - loss: 0.2162 - accuracy: 0.9407\n",
      "185/469 [==========>...................] - ETA: 1s - loss: 0.2252 - accuracy: 0.9395\n",
      "204/469 [============>.................] - ETA: 1s - loss: 0.2335 - accuracy: 0.9378\n",
      "224/469 [=============>................] - ETA: 1s - loss: 0.2348 - accuracy: 0.9385\n",
      "244/469 [==============>...............] - ETA: 1s - loss: 0.2344 - accuracy: 0.9383\n",
      "264/469 [===============>..............] - ETA: 1s - loss: 0.2327 - accuracy: 0.9386\n",
      "281/469 [================>.............] - ETA: 1s - loss: 0.2331 - accuracy: 0.9384\n",
      "291/469 [=================>............] - ETA: 0s - loss: 0.2332 - accuracy: 0.9385\n",
      "311/469 [==================>...........] - ETA: 0s - loss: 0.2362 - accuracy: 0.9380\n",
      "331/469 [====================>.........] - ETA: 0s - loss: 0.2378 - accuracy: 0.9372\n",
      "351/469 [=====================>........] - ETA: 0s - loss: 0.2403 - accuracy: 0.9370\n",
      "371/469 [======================>.......] - ETA: 0s - loss: 0.2419 - accuracy: 0.9360\n",
      "390/469 [=======================>......] - ETA: 0s - loss: 0.2407 - accuracy: 0.9360\n",
      "409/469 [=========================>....] - ETA: 0s - loss: 0.2396 - accuracy: 0.9358\n",
      "429/469 [==========================>...] - ETA: 0s - loss: 0.2400 - accuracy: 0.9358\n",
      "449/469 [===========================>..] - ETA: 0s - loss: 0.2392 - accuracy: 0.9362\n",
      "468/469 [============================>.] - ETA: 0s - loss: 0.2381 - accuracy: 0.9364\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.2380 - accuracy: 0.9364 - val_loss: 0.1700 - val_accuracy: 0.9554\n",
      "\u001b[36m(train_mnist pid=2636148)\u001b[0m Epoch 10/12\n",
      "  1/469 [..............................] - ETA: 2s - loss: 0.1939 - accuracy: 0.9531\n",
      " 20/469 [>.............................] - ETA: 2s - loss: 0.1844 - accuracy: 0.9516\n",
      " 40/469 [=>............................] - ETA: 2s - loss: 0.1977 - accuracy: 0.9480\n",
      " 59/469 [==>...........................] - ETA: 2s - loss: 0.2256 - accuracy: 0.9425\n",
      " 69/469 [===>..........................] - ETA: 2s - loss: 0.2241 - accuracy: 0.9418\n",
      " 89/469 [====>.........................] - ETA: 2s - loss: 0.2207 - accuracy: 0.9424\n",
      "109/469 [=====>........................] - ETA: 1s - loss: 0.2203 - accuracy: 0.9424\n",
      "129/469 [=======>......................] - ETA: 1s - loss: 0.2172 - accuracy: 0.9427\n",
      "149/469 [========>.....................] - ETA: 1s - loss: 0.2182 - accuracy: 0.9424\n",
      "168/469 [=========>....................] - ETA: 1s - loss: 0.2119 - accuracy: 0.9435\n",
      "186/469 [==========>...................] - ETA: 1s - loss: 0.2108 - accuracy: 0.9442\n",
      "196/469 [===========>..................] - ETA: 1s - loss: 0.2099 - accuracy: 0.9442\n",
      "214/469 [============>.................] - ETA: 1s - loss: 0.2104 - accuracy: 0.9443\n",
      "232/469 [=============>................] - ETA: 1s - loss: 0.2090 - accuracy: 0.9445\n",
      "252/469 [===============>..............] - ETA: 1s - loss: 0.2077 - accuracy: 0.9447\n",
      "272/469 [================>.............] - ETA: 1s - loss: 0.2060 - accuracy: 0.9450\n",
      "292/469 [=================>............] - ETA: 0s - loss: 0.2070 - accuracy: 0.9449\n",
      "312/469 [==================>...........] - ETA: 0s - loss: 0.2070 - accuracy: 0.9447\n",
      "322/469 [===================>..........] - ETA: 0s - loss: 0.2082 - accuracy: 0.9443\n",
      "342/469 [====================>.........] - ETA: 0s - loss: 0.2097 - accuracy: 0.9439\n",
      "362/469 [======================>.......] - ETA: 0s - loss: 0.2099 - accuracy: 0.9436\n",
      "380/469 [=======================>......] - ETA: 0s - loss: 0.2146 - accuracy: 0.9426\n",
      "400/469 [========================>.....] - ETA: 0s - loss: 0.2197 - accuracy: 0.9418\n",
      "419/469 [=========================>....] - ETA: 0s - loss: 0.2199 - accuracy: 0.9417\n",
      "439/469 [===========================>..] - ETA: 0s - loss: 0.2226 - accuracy: 0.9414\n",
      "467/469 [============================>.] - ETA: 0s - loss: 0.2262 - accuracy: 0.9406\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.2262 - accuracy: 0.9407 - val_loss: 0.2553 - val_accuracy: 0.9463\n",
      "\u001b[36m(train_mnist pid=2636148)\u001b[0m Epoch 11/12\n",
      "  1/469 [..............................] - ETA: 2s - loss: 0.1025 - accuracy: 0.9453\n",
      " 19/469 [>.............................] - ETA: 2s - loss: 0.2924 - accuracy: 0.9194\n",
      " 38/469 [=>............................] - ETA: 2s - loss: 0.2558 - accuracy: 0.9289\n",
      " 58/469 [==>...........................] - ETA: 2s - loss: 0.2659 - accuracy: 0.9301\n",
      " 78/469 [===>..........................] - ETA: 2s - loss: 0.2477 - accuracy: 0.9340\n",
      " 98/469 [=====>........................] - ETA: 1s - loss: 0.2455 - accuracy: 0.9346\n",
      "118/469 [======>.......................] - ETA: 1s - loss: 0.2394 - accuracy: 0.9350\n",
      "128/469 [=======>......................] - ETA: 1s - loss: 0.2368 - accuracy: 0.9357\n",
      "148/469 [========>.....................] - ETA: 1s - loss: 0.2401 - accuracy: 0.9363\n",
      "167/469 [=========>....................] - ETA: 1s - loss: 0.2403 - accuracy: 0.9367\n",
      "187/469 [==========>...................] - ETA: 1s - loss: 0.2389 - accuracy: 0.9368\n",
      "207/469 [============>.................] - ETA: 1s - loss: 0.2356 - accuracy: 0.9367\n",
      "227/469 [=============>................] - ETA: 1s - loss: 0.2342 - accuracy: 0.9372\n",
      "247/469 [==============>...............] - ETA: 1s - loss: 0.2314 - accuracy: 0.9378\n",
      "267/469 [================>.............] - ETA: 1s - loss: 0.2284 - accuracy: 0.9383\n",
      "286/469 [=================>............] - ETA: 0s - loss: 0.2309 - accuracy: 0.9379\n",
      "296/469 [=================>............] - ETA: 0s - loss: 0.2301 - accuracy: 0.9383\n",
      "315/469 [===================>..........] - ETA: 0s - loss: 0.2299 - accuracy: 0.9387\n",
      "335/469 [====================>.........] - ETA: 0s - loss: 0.2291 - accuracy: 0.9389\n",
      "354/469 [=====================>........] - ETA: 0s - loss: 0.2262 - accuracy: 0.9395\n",
      "374/469 [======================>.......] - ETA: 0s - loss: 0.2252 - accuracy: 0.9396\n",
      "392/469 [========================>.....] - ETA: 0s - loss: 0.2253 - accuracy: 0.9399\n",
      "412/469 [=========================>....] - ETA: 0s - loss: 0.2261 - accuracy: 0.9397\n",
      "421/469 [=========================>....] - ETA: 0s - loss: 0.2256 - accuracy: 0.9396\n",
      "440/469 [===========================>..] - ETA: 0s - loss: 0.2250 - accuracy: 0.9395\n",
      "460/469 [============================>.] - ETA: 0s - loss: 0.2242 - accuracy: 0.9396\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.2243 - accuracy: 0.9394 - val_loss: 0.1782 - val_accuracy: 0.9542\n",
      "\u001b[36m(train_mnist pid=2636148)\u001b[0m Epoch 12/12\n",
      " 10/469 [..............................] - ETA: 2s - loss: 0.1696 - accuracy: 0.9453\n",
      " 30/469 [>.............................] - ETA: 2s - loss: 0.1811 - accuracy: 0.9464\n",
      " 50/469 [==>...........................] - ETA: 2s - loss: 0.1874 - accuracy: 0.9466\n",
      " 69/469 [===>..........................] - ETA: 2s - loss: 0.1934 - accuracy: 0.9449\n",
      " 89/469 [====>.........................] - ETA: 2s - loss: 0.1995 - accuracy: 0.9430\n",
      "109/469 [=====>........................] - ETA: 1s - loss: 0.2114 - accuracy: 0.9416\n",
      "119/469 [======>.......................] - ETA: 1s - loss: 0.2108 - accuracy: 0.9415\n",
      "139/469 [=======>......................] - ETA: 1s - loss: 0.2094 - accuracy: 0.9422\n",
      "159/469 [=========>....................] - ETA: 1s - loss: 0.2081 - accuracy: 0.9429\n",
      "179/469 [==========>...................] - ETA: 1s - loss: 0.2113 - accuracy: 0.9420\n",
      "198/469 [===========>..................] - ETA: 1s - loss: 0.2148 - accuracy: 0.9412\n",
      "216/469 [============>.................] - ETA: 1s - loss: 0.2161 - accuracy: 0.9409\n",
      "236/469 [==============>...............] - ETA: 1s - loss: 0.2205 - accuracy: 0.9404\n",
      "246/469 [==============>...............] - ETA: 1s - loss: 0.2213 - accuracy: 0.9401\n",
      "266/469 [================>.............] - ETA: 1s - loss: 0.2219 - accuracy: 0.9397\n",
      "285/469 [=================>............] - ETA: 0s - loss: 0.2225 - accuracy: 0.9398\n",
      "304/469 [==================>...........] - ETA: 0s - loss: 0.2211 - accuracy: 0.9399\n",
      "324/469 [===================>..........] - ETA: 0s - loss: 0.2175 - accuracy: 0.9408\n",
      "344/469 [=====================>........] - ETA: 0s - loss: 0.2172 - accuracy: 0.9410\n",
      "364/469 [======================>.......] - ETA: 0s - loss: 0.2158 - accuracy: 0.9416\n",
      "383/469 [=======================>......] - ETA: 0s - loss: 0.2178 - accuracy: 0.9412\n",
      "403/469 [========================>.....] - ETA: 0s - loss: 0.2234 - accuracy: 0.9402\n",
      "413/469 [=========================>....] - ETA: 0s - loss: 0.2234 - accuracy: 0.9403\n",
      "433/469 [==========================>...] - ETA: 0s - loss: 0.2235 - accuracy: 0.9405\n",
      "453/469 [===========================>..] - ETA: 0s - loss: 0.2230 - accuracy: 0.9408\n",
      "463/469 [============================>.] - ETA: 0s - loss: 0.2228 - accuracy: 0.9408\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.2220 - accuracy: 0.9409 - val_loss: 0.2289 - val_accuracy: 0.9516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=2638393)\u001b[0m 2023-12-05 09:49:17.433545: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=2638393)\u001b[0m 2023-12-05 09:49:17.473508: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=2638393)\u001b[0m 2023-12-05 09:49:17.473533: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=2638393)\u001b[0m 2023-12-05 09:49:17.474581: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=2638393)\u001b[0m 2023-12-05 09:49:17.480562: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=2638393)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=2638393)\u001b[0m 2023-12-05 09:49:18.187193: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=2638393)\u001b[0m 2023-12-05 09:49:19.523873: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_mnist pid=2638393)\u001b[0m Epoch 1/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_mnist pid=2638393)\u001b[0m 2023-12-05 09:49:21.264479: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=2638393)\u001b[0m 2023-12-05 09:49:22.258548: I external/local_xla/xla/service/service.cc:168] XLA service 0x152f05bfddc0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=2638393)\u001b[0m 2023-12-05 09:49:22.258591: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=2638393)\u001b[0m 2023-12-05 09:49:22.269470: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=2638393)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=2638393)\u001b[0m I0000 00:00:1701787762.391399 2638606 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 12/469 [..............................] - ETA: 2s - loss: 3.0743 - accuracy: 0.2220   \n",
      " 36/469 [=>............................] - ETA: 1s - loss: 1.8649 - accuracy: 0.4631\n",
      " 49/469 [==>...........................] - ETA: 1s - loss: 1.5739 - accuracy: 0.5351\n",
      " 73/469 [===>..........................] - ETA: 1s - loss: 1.2793 - accuracy: 0.6153\n",
      " 97/469 [=====>........................] - ETA: 1s - loss: 1.1088 - accuracy: 0.6637\n",
      "121/469 [======>.......................] - ETA: 1s - loss: 0.9909 - accuracy: 0.6980\n",
      "147/469 [========>.....................] - ETA: 1s - loss: 0.8999 - accuracy: 0.7248\n",
      "160/469 [=========>....................] - ETA: 1s - loss: 0.8668 - accuracy: 0.7351\n",
      "186/469 [==========>...................] - ETA: 1s - loss: 0.8096 - accuracy: 0.7523\n",
      "213/469 [============>.................] - ETA: 1s - loss: 0.7635 - accuracy: 0.7663\n",
      "239/469 [==============>...............] - ETA: 0s - loss: 0.7275 - accuracy: 0.7768\n",
      "264/469 [===============>..............] - ETA: 0s - loss: 0.6984 - accuracy: 0.7852\n",
      "290/469 [=================>............] - ETA: 0s - loss: 0.6726 - accuracy: 0.7928\n",
      "316/469 [===================>..........] - ETA: 0s - loss: 0.6500 - accuracy: 0.7999\n",
      "342/469 [====================>.........] - ETA: 0s - loss: 0.6307 - accuracy: 0.8062\n",
      "378/469 [=======================>......] - ETA: 0s - loss: 0.6108 - accuracy: 0.8128\n",
      "403/469 [========================>.....] - ETA: 0s - loss: 0.5968 - accuracy: 0.8168\n",
      "429/469 [==========================>...] - ETA: 0s - loss: 0.5850 - accuracy: 0.8203\n",
      "454/469 [============================>.] - ETA: 0s - loss: 0.5748 - accuracy: 0.8232\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.5696 - accuracy: 0.8252\n",
      "469/469 [==============================] - 5s 5ms/step - loss: 0.5696 - accuracy: 0.8252 - val_loss: 0.1530 - val_accuracy: 0.9539\n",
      "\u001b[36m(train_mnist pid=2638393)\u001b[0m Epoch 2/12\n",
      "  1/469 [..............................] - ETA: 2s - loss: 0.2431 - accuracy: 0.9297\n",
      " 28/469 [>.............................] - ETA: 1s - loss: 0.3722 - accuracy: 0.8823\n",
      " 53/469 [==>...........................] - ETA: 1s - loss: 0.3785 - accuracy: 0.8818\n",
      " 78/469 [===>..........................] - ETA: 1s - loss: 0.3808 - accuracy: 0.8815\n",
      "105/469 [=====>........................] - ETA: 1s - loss: 0.3789 - accuracy: 0.8836\n",
      "131/469 [=======>......................] - ETA: 1s - loss: 0.3777 - accuracy: 0.8837\n",
      "156/469 [========>.....................] - ETA: 1s - loss: 0.3776 - accuracy: 0.8830\n",
      "169/469 [=========>....................] - ETA: 1s - loss: 0.3749 - accuracy: 0.8833\n",
      "194/469 [===========>..................] - ETA: 1s - loss: 0.3714 - accuracy: 0.8848\n",
      "218/469 [============>.................] - ETA: 1s - loss: 0.3731 - accuracy: 0.8846\n",
      "243/469 [==============>...............] - ETA: 0s - loss: 0.3707 - accuracy: 0.8855\n",
      "268/469 [================>.............] - ETA: 0s - loss: 0.3682 - accuracy: 0.8863\n",
      "293/469 [=================>............] - ETA: 0s - loss: 0.3688 - accuracy: 0.8864\n",
      "306/469 [==================>...........] - ETA: 0s - loss: 0.3680 - accuracy: 0.8868\n",
      "330/469 [====================>.........] - ETA: 0s - loss: 0.3686 - accuracy: 0.8867\n",
      "358/469 [=====================>........] - ETA: 0s - loss: 0.3680 - accuracy: 0.8870\n",
      "383/469 [=======================>......] - ETA: 0s - loss: 0.3693 - accuracy: 0.8866\n",
      "409/469 [=========================>....] - ETA: 0s - loss: 0.3685 - accuracy: 0.8869\n",
      "433/469 [==========================>...] - ETA: 0s - loss: 0.3690 - accuracy: 0.8870\n",
      "458/469 [============================>.] - ETA: 0s - loss: 0.3664 - accuracy: 0.8877\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.3662 - accuracy: 0.8878 - val_loss: 0.1481 - val_accuracy: 0.9560\n",
      "\u001b[36m(train_mnist pid=2638393)\u001b[0m Epoch 3/12\n",
      "  1/469 [..............................] - ETA: 1s - loss: 0.5029 - accuracy: 0.8906\n",
      " 14/469 [..............................] - ETA: 1s - loss: 0.3335 - accuracy: 0.9023\n",
      " 38/469 [=>............................] - ETA: 1s - loss: 0.3331 - accuracy: 0.8988\n",
      " 62/469 [==>...........................] - ETA: 1s - loss: 0.3400 - accuracy: 0.8950\n",
      " 87/469 [====>.........................] - ETA: 1s - loss: 0.3458 - accuracy: 0.8935\n",
      "111/469 [======>.......................] - ETA: 1s - loss: 0.3402 - accuracy: 0.8937\n",
      "135/469 [=======>......................] - ETA: 1s - loss: 0.3378 - accuracy: 0.8946\n",
      "148/469 [========>.....................] - ETA: 1s - loss: 0.3361 - accuracy: 0.8953\n",
      "173/469 [==========>...................] - ETA: 1s - loss: 0.3331 - accuracy: 0.8960\n",
      "198/469 [===========>..................] - ETA: 1s - loss: 0.3376 - accuracy: 0.8951\n",
      "224/469 [=============>................] - ETA: 1s - loss: 0.3386 - accuracy: 0.8954\n",
      "249/469 [==============>...............] - ETA: 0s - loss: 0.3411 - accuracy: 0.8949\n",
      "274/469 [================>.............] - ETA: 0s - loss: 0.3374 - accuracy: 0.8956\n",
      "286/469 [=================>............] - ETA: 0s - loss: 0.3389 - accuracy: 0.8947\n",
      "311/469 [==================>...........] - ETA: 0s - loss: 0.3386 - accuracy: 0.8952\n",
      "338/469 [====================>.........] - ETA: 0s - loss: 0.3389 - accuracy: 0.8956\n",
      "364/469 [======================>.......] - ETA: 0s - loss: 0.3387 - accuracy: 0.8960\n",
      "390/469 [=======================>......] - ETA: 0s - loss: 0.3368 - accuracy: 0.8966\n",
      "414/469 [=========================>....] - ETA: 0s - loss: 0.3358 - accuracy: 0.8967\n",
      "441/469 [===========================>..] - ETA: 0s - loss: 0.3361 - accuracy: 0.8964\n",
      "454/469 [============================>.] - ETA: 0s - loss: 0.3355 - accuracy: 0.8966\n",
      "467/469 [============================>.] - ETA: 0s - loss: 0.3352 - accuracy: 0.8966\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.3353 - accuracy: 0.8966 - val_loss: 0.1320 - val_accuracy: 0.9617\n",
      "\u001b[36m(train_mnist pid=2638393)\u001b[0m Epoch 4/12\n",
      " 14/469 [..............................] - ETA: 1s - loss: 0.3196 - accuracy: 0.9068\n",
      " 38/469 [=>............................] - ETA: 1s - loss: 0.3099 - accuracy: 0.9021\n",
      " 50/469 [==>...........................] - ETA: 1s - loss: 0.3068 - accuracy: 0.9048\n",
      " 75/469 [===>..........................] - ETA: 1s - loss: 0.3063 - accuracy: 0.9058\n",
      "101/469 [=====>........................] - ETA: 1s - loss: 0.3033 - accuracy: 0.9073\n",
      "125/469 [======>.......................] - ETA: 1s - loss: 0.3134 - accuracy: 0.9036\n",
      "152/469 [========>.....................] - ETA: 1s - loss: 0.3174 - accuracy: 0.9027\n",
      "178/469 [==========>...................] - ETA: 1s - loss: 0.3256 - accuracy: 0.9010\n",
      "216/469 [============>.................] - ETA: 1s - loss: 0.3342 - accuracy: 0.8981\n",
      "242/469 [==============>...............] - ETA: 0s - loss: 0.3316 - accuracy: 0.8986\n",
      "267/469 [================>.............] - ETA: 0s - loss: 0.3325 - accuracy: 0.8990\n",
      "293/469 [=================>............] - ETA: 0s - loss: 0.3343 - accuracy: 0.8987\n",
      "319/469 [===================>..........] - ETA: 0s - loss: 0.3323 - accuracy: 0.8995\n",
      "344/469 [=====================>........] - ETA: 0s - loss: 0.3332 - accuracy: 0.8997\n",
      "369/469 [======================>.......] - ETA: 0s - loss: 0.3315 - accuracy: 0.8998\n",
      "381/469 [=======================>......] - ETA: 0s - loss: 0.3311 - accuracy: 0.8998\n",
      "407/469 [=========================>....] - ETA: 0s - loss: 0.3313 - accuracy: 0.8997\n",
      "434/469 [==========================>...] - ETA: 0s - loss: 0.3304 - accuracy: 0.8999\n",
      "458/469 [============================>.] - ETA: 0s - loss: 0.3284 - accuracy: 0.9000\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.3280 - accuracy: 0.9002 - val_loss: 0.1288 - val_accuracy: 0.9624\n",
      "\u001b[36m(train_mnist pid=2638393)\u001b[0m Epoch 5/12\n",
      " 15/469 [..............................] - ETA: 1s - loss: 0.3216 - accuracy: 0.8969\n",
      " 41/469 [=>............................] - ETA: 1s - loss: 0.3101 - accuracy: 0.9015\n",
      " 54/469 [==>...........................] - ETA: 1s - loss: 0.3088 - accuracy: 0.9012\n",
      " 80/469 [====>.........................] - ETA: 1s - loss: 0.3052 - accuracy: 0.9021\n",
      "104/469 [=====>........................] - ETA: 1s - loss: 0.3053 - accuracy: 0.9036\n",
      "129/469 [=======>......................] - ETA: 1s - loss: 0.3098 - accuracy: 0.9020\n",
      "153/469 [========>.....................] - ETA: 1s - loss: 0.3117 - accuracy: 0.9032\n",
      "178/469 [==========>...................] - ETA: 1s - loss: 0.3171 - accuracy: 0.9023\n",
      "214/469 [============>.................] - ETA: 1s - loss: 0.3162 - accuracy: 0.9032\n",
      "241/469 [==============>...............] - ETA: 0s - loss: 0.3159 - accuracy: 0.9034\n",
      "265/469 [===============>..............] - ETA: 0s - loss: 0.3157 - accuracy: 0.9029\n",
      "290/469 [=================>............] - ETA: 0s - loss: 0.3165 - accuracy: 0.9031\n",
      "316/469 [===================>..........] - ETA: 0s - loss: 0.3164 - accuracy: 0.9027\n",
      "342/469 [====================>.........] - ETA: 0s - loss: 0.3174 - accuracy: 0.9029\n",
      "379/469 [=======================>......] - ETA: 0s - loss: 0.3168 - accuracy: 0.9032\n",
      "405/469 [========================>.....] - ETA: 0s - loss: 0.3169 - accuracy: 0.9030\n",
      "432/469 [==========================>...] - ETA: 0s - loss: 0.3200 - accuracy: 0.9021\n",
      "458/469 [============================>.] - ETA: 0s - loss: 0.3220 - accuracy: 0.9015\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.3212 - accuracy: 0.9017 - val_loss: 0.1386 - val_accuracy: 0.9618\n",
      "\u001b[36m(train_mnist pid=2638393)\u001b[0m Epoch 6/12\n",
      "  1/469 [..............................] - ETA: 2s - loss: 0.1981 - accuracy: 0.9219\n",
      " 27/469 [>.............................] - ETA: 1s - loss: 0.3072 - accuracy: 0.9100\n",
      " 53/469 [==>...........................] - ETA: 1s - loss: 0.3219 - accuracy: 0.9012\n",
      " 79/469 [====>.........................] - ETA: 1s - loss: 0.3275 - accuracy: 0.8989\n",
      "104/469 [=====>........................] - ETA: 1s - loss: 0.3188 - accuracy: 0.9019\n",
      "116/469 [======>.......................] - ETA: 1s - loss: 0.3205 - accuracy: 0.9013\n",
      "142/469 [========>.....................] - ETA: 1s - loss: 0.3181 - accuracy: 0.9022\n",
      "166/469 [=========>....................] - ETA: 1s - loss: 0.3136 - accuracy: 0.9023\n",
      "190/469 [===========>..................] - ETA: 1s - loss: 0.3151 - accuracy: 0.9021\n",
      "217/469 [============>.................] - ETA: 1s - loss: 0.3187 - accuracy: 0.9019\n",
      "241/469 [==============>...............] - ETA: 0s - loss: 0.3176 - accuracy: 0.9024\n",
      "252/469 [===============>..............] - ETA: 0s - loss: 0.3175 - accuracy: 0.9025\n",
      "278/469 [================>.............] - ETA: 0s - loss: 0.3160 - accuracy: 0.9031\n",
      "303/469 [==================>...........] - ETA: 0s - loss: 0.3152 - accuracy: 0.9036\n",
      "329/469 [====================>.........] - ETA: 0s - loss: 0.3143 - accuracy: 0.9039\n",
      "355/469 [=====================>........] - ETA: 0s - loss: 0.3127 - accuracy: 0.9040\n",
      "380/469 [=======================>......] - ETA: 0s - loss: 0.3124 - accuracy: 0.9040\n",
      "405/469 [========================>.....] - ETA: 0s - loss: 0.3105 - accuracy: 0.9047\n",
      "431/469 [==========================>...] - ETA: 0s - loss: 0.3091 - accuracy: 0.9051\n",
      "444/469 [===========================>..] - ETA: 0s - loss: 0.3094 - accuracy: 0.9052\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.3087 - accuracy: 0.9056\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.3087 - accuracy: 0.9056 - val_loss: 0.1421 - val_accuracy: 0.9598\n",
      "\u001b[36m(train_mnist pid=2638393)\u001b[0m Epoch 7/12\n",
      " 14/469 [..............................] - ETA: 1s - loss: 0.3056 - accuracy: 0.8951\n",
      " 37/469 [=>............................] - ETA: 1s - loss: 0.3026 - accuracy: 0.9060\n",
      " 61/469 [==>...........................] - ETA: 1s - loss: 0.2955 - accuracy: 0.9089\n",
      " 86/469 [====>.........................] - ETA: 1s - loss: 0.2965 - accuracy: 0.9087\n",
      "112/469 [======>.......................] - ETA: 1s - loss: 0.3022 - accuracy: 0.9080\n",
      "136/469 [=======>......................] - ETA: 1s - loss: 0.2997 - accuracy: 0.9081\n",
      "149/469 [========>.....................] - ETA: 1s - loss: 0.3012 - accuracy: 0.9081\n",
      "175/469 [==========>...................] - ETA: 1s - loss: 0.3010 - accuracy: 0.9079\n",
      "200/469 [===========>..................] - ETA: 1s - loss: 0.3007 - accuracy: 0.9077\n",
      "227/469 [=============>................] - ETA: 0s - loss: 0.3016 - accuracy: 0.9075\n",
      "253/469 [===============>..............] - ETA: 0s - loss: 0.3029 - accuracy: 0.9071\n",
      "278/469 [================>.............] - ETA: 0s - loss: 0.3018 - accuracy: 0.9076\n",
      "303/469 [==================>...........] - ETA: 0s - loss: 0.3018 - accuracy: 0.9072\n",
      "315/469 [===================>..........] - ETA: 0s - loss: 0.3030 - accuracy: 0.9069\n",
      "341/469 [====================>.........] - ETA: 0s - loss: 0.3027 - accuracy: 0.9073\n",
      "367/469 [======================>.......] - ETA: 0s - loss: 0.3019 - accuracy: 0.9074\n",
      "393/469 [========================>.....] - ETA: 0s - loss: 0.3000 - accuracy: 0.9081\n",
      "419/469 [=========================>....] - ETA: 0s - loss: 0.2985 - accuracy: 0.9084\n",
      "445/469 [===========================>..] - ETA: 0s - loss: 0.2975 - accuracy: 0.9087\n",
      "459/469 [============================>.] - ETA: 0s - loss: 0.2991 - accuracy: 0.9084\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.2985 - accuracy: 0.9083 - val_loss: 0.1267 - val_accuracy: 0.9633\n",
      "\u001b[36m(train_mnist pid=2638393)\u001b[0m Epoch 8/12\n",
      "  1/469 [..............................] - ETA: 2s - loss: 0.2444 - accuracy: 0.9141\n",
      " 28/469 [>.............................] - ETA: 1s - loss: 0.2676 - accuracy: 0.9129\n",
      " 54/469 [==>...........................] - ETA: 1s - loss: 0.2681 - accuracy: 0.9168\n",
      " 80/469 [====>.........................] - ETA: 1s - loss: 0.2723 - accuracy: 0.9141\n",
      "105/469 [=====>........................] - ETA: 1s - loss: 0.2757 - accuracy: 0.9147\n",
      "130/469 [=======>......................] - ETA: 1s - loss: 0.2811 - accuracy: 0.9152\n",
      "142/469 [========>.....................] - ETA: 1s - loss: 0.2829 - accuracy: 0.9151\n",
      "168/469 [=========>....................] - ETA: 1s - loss: 0.2822 - accuracy: 0.9147\n",
      "195/469 [===========>..................] - ETA: 1s - loss: 0.2865 - accuracy: 0.9148\n",
      "220/469 [=============>................] - ETA: 1s - loss: 0.2905 - accuracy: 0.9131\n",
      "245/469 [==============>...............] - ETA: 0s - loss: 0.2982 - accuracy: 0.9103\n",
      "271/469 [================>.............] - ETA: 0s - loss: 0.3044 - accuracy: 0.9086\n",
      "296/469 [=================>............] - ETA: 0s - loss: 0.3078 - accuracy: 0.9075\n",
      "322/469 [===================>..........] - ETA: 0s - loss: 0.3069 - accuracy: 0.9076\n",
      "335/469 [====================>.........] - ETA: 0s - loss: 0.3068 - accuracy: 0.9078\n",
      "357/469 [=====================>........] - ETA: 0s - loss: 0.3064 - accuracy: 0.9080\n",
      "382/469 [=======================>......] - ETA: 0s - loss: 0.3063 - accuracy: 0.9081\n",
      "408/469 [=========================>....] - ETA: 0s - loss: 0.3047 - accuracy: 0.9083\n",
      "435/469 [==========================>...] - ETA: 0s - loss: 0.3048 - accuracy: 0.9081\n",
      "460/469 [============================>.] - ETA: 0s - loss: 0.3039 - accuracy: 0.9082\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.3038 - accuracy: 0.9083 - val_loss: 0.1341 - val_accuracy: 0.9628\n",
      "\u001b[36m(train_mnist pid=2638393)\u001b[0m Epoch 9/12\n",
      "  1/469 [..............................] - ETA: 1s - loss: 0.3492 - accuracy: 0.8672\n",
      " 26/469 [>.............................] - ETA: 1s - loss: 0.2980 - accuracy: 0.9047\n",
      " 52/469 [==>...........................] - ETA: 1s - loss: 0.2843 - accuracy: 0.9064\n",
      " 65/469 [===>..........................] - ETA: 1s - loss: 0.2891 - accuracy: 0.9073\n",
      " 90/469 [====>.........................] - ETA: 1s - loss: 0.2919 - accuracy: 0.9086\n",
      "115/469 [======>.......................] - ETA: 1s - loss: 0.2917 - accuracy: 0.9092\n",
      "140/469 [=======>......................] - ETA: 1s - loss: 0.2913 - accuracy: 0.9099\n",
      "164/469 [=========>....................] - ETA: 1s - loss: 0.2899 - accuracy: 0.9108\n",
      "190/469 [===========>..................] - ETA: 1s - loss: 0.2851 - accuracy: 0.9120\n",
      "215/469 [============>.................] - ETA: 1s - loss: 0.2901 - accuracy: 0.9110\n",
      "228/469 [=============>................] - ETA: 0s - loss: 0.2932 - accuracy: 0.9104\n",
      "252/469 [===============>..............] - ETA: 0s - loss: 0.2932 - accuracy: 0.9099\n",
      "276/469 [================>.............] - ETA: 0s - loss: 0.2967 - accuracy: 0.9089\n",
      "300/469 [==================>...........] - ETA: 0s - loss: 0.2986 - accuracy: 0.9082\n",
      "325/469 [===================>..........] - ETA: 0s - loss: 0.2985 - accuracy: 0.9087\n",
      "351/469 [=====================>........] - ETA: 0s - loss: 0.3000 - accuracy: 0.9084\n",
      "376/469 [=======================>......] - ETA: 0s - loss: 0.2997 - accuracy: 0.9087\n",
      "388/469 [=======================>......] - ETA: 0s - loss: 0.2995 - accuracy: 0.9089\n",
      "413/469 [=========================>....] - ETA: 0s - loss: 0.2976 - accuracy: 0.9093\n",
      "439/469 [===========================>..] - ETA: 0s - loss: 0.2998 - accuracy: 0.9088\n",
      "464/469 [============================>.] - ETA: 0s - loss: 0.3008 - accuracy: 0.9087\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.3008 - accuracy: 0.9086 - val_loss: 0.1372 - val_accuracy: 0.9621\n",
      "\u001b[36m(train_mnist pid=2638393)\u001b[0m Epoch 10/12\n",
      "  1/469 [..............................] - ETA: 1s - loss: 0.2010 - accuracy: 0.9375\n",
      " 14/469 [..............................] - ETA: 1s - loss: 0.2797 - accuracy: 0.9208\n",
      " 40/469 [=>............................] - ETA: 1s - loss: 0.2867 - accuracy: 0.9172\n",
      " 65/469 [===>..........................] - ETA: 1s - loss: 0.2745 - accuracy: 0.9165\n",
      " 90/469 [====>.........................] - ETA: 1s - loss: 0.2807 - accuracy: 0.9162\n",
      "114/469 [======>.......................] - ETA: 1s - loss: 0.2771 - accuracy: 0.9171\n",
      "140/469 [=======>......................] - ETA: 1s - loss: 0.2828 - accuracy: 0.9152\n",
      "166/469 [=========>....................] - ETA: 1s - loss: 0.2849 - accuracy: 0.9135\n",
      "178/469 [==========>...................] - ETA: 1s - loss: 0.2847 - accuracy: 0.9132\n",
      "204/469 [============>.................] - ETA: 1s - loss: 0.2874 - accuracy: 0.9128\n",
      "230/469 [=============>................] - ETA: 0s - loss: 0.2886 - accuracy: 0.9122\n",
      "255/469 [===============>..............] - ETA: 0s - loss: 0.2906 - accuracy: 0.9119\n",
      "280/469 [================>.............] - ETA: 0s - loss: 0.2865 - accuracy: 0.9130\n",
      "305/469 [==================>...........] - ETA: 0s - loss: 0.2875 - accuracy: 0.9127\n",
      "317/469 [===================>..........] - ETA: 0s - loss: 0.2892 - accuracy: 0.9122\n",
      "343/469 [====================>.........] - ETA: 0s - loss: 0.2889 - accuracy: 0.9121\n",
      "369/469 [======================>.......] - ETA: 0s - loss: 0.2898 - accuracy: 0.9121\n",
      "395/469 [========================>.....] - ETA: 0s - loss: 0.2933 - accuracy: 0.9116\n",
      "419/469 [=========================>....] - ETA: 0s - loss: 0.2941 - accuracy: 0.9113\n",
      "443/469 [===========================>..] - ETA: 0s - loss: 0.2955 - accuracy: 0.9113\n",
      "467/469 [============================>.] - ETA: 0s - loss: 0.2957 - accuracy: 0.9110\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.2957 - accuracy: 0.9110 - val_loss: 0.1268 - val_accuracy: 0.9647\n",
      "\u001b[36m(train_mnist pid=2638393)\u001b[0m Epoch 11/12\n",
      " 16/469 [>.............................] - ETA: 1s - loss: 0.2734 - accuracy: 0.9238\n",
      " 43/469 [=>............................] - ETA: 1s - loss: 0.2750 - accuracy: 0.9211\n",
      " 68/469 [===>..........................] - ETA: 1s - loss: 0.2751 - accuracy: 0.9177\n",
      " 80/469 [====>.........................] - ETA: 1s - loss: 0.2685 - accuracy: 0.9190\n",
      "106/469 [=====>........................] - ETA: 1s - loss: 0.2652 - accuracy: 0.9186\n",
      "132/469 [=======>......................] - ETA: 1s - loss: 0.2661 - accuracy: 0.9173\n",
      "158/469 [=========>....................] - ETA: 1s - loss: 0.2665 - accuracy: 0.9172\n",
      "184/469 [==========>...................] - ETA: 1s - loss: 0.2738 - accuracy: 0.9158\n",
      "209/469 [============>.................] - ETA: 1s - loss: 0.2774 - accuracy: 0.9142\n",
      "222/469 [=============>................] - ETA: 0s - loss: 0.2798 - accuracy: 0.9136\n",
      "248/469 [==============>...............] - ETA: 0s - loss: 0.2806 - accuracy: 0.9132\n",
      "273/469 [================>.............] - ETA: 0s - loss: 0.2836 - accuracy: 0.9130\n",
      "298/469 [==================>...........] - ETA: 0s - loss: 0.2859 - accuracy: 0.9125\n",
      "324/469 [===================>..........] - ETA: 0s - loss: 0.2846 - accuracy: 0.9129\n",
      "350/469 [=====================>........] - ETA: 0s - loss: 0.2860 - accuracy: 0.9128\n",
      "375/469 [======================>.......] - ETA: 0s - loss: 0.2882 - accuracy: 0.9117\n",
      "402/469 [========================>.....] - ETA: 0s - loss: 0.2902 - accuracy: 0.9111\n",
      "415/469 [=========================>....] - ETA: 0s - loss: 0.2894 - accuracy: 0.9110\n",
      "441/469 [===========================>..] - ETA: 0s - loss: 0.2892 - accuracy: 0.9112\n",
      "467/469 [============================>.] - ETA: 0s - loss: 0.2882 - accuracy: 0.9114\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.2881 - accuracy: 0.9113 - val_loss: 0.1578 - val_accuracy: 0.9604\n",
      "\u001b[36m(train_mnist pid=2638393)\u001b[0m Epoch 12/12\n",
      "  1/469 [..............................] - ETA: 1s - loss: 0.2257 - accuracy: 0.9141\n",
      " 26/469 [>.............................] - ETA: 1s - loss: 0.2750 - accuracy: 0.9111\n",
      " 67/469 [===>..........................] - ETA: 1s - loss: 0.2791 - accuracy: 0.9115\n",
      " 93/469 [====>.........................] - ETA: 1s - loss: 0.2785 - accuracy: 0.9131\n",
      "117/469 [======>.......................] - ETA: 1s - loss: 0.2800 - accuracy: 0.9136\n",
      "142/469 [========>.....................] - ETA: 1s - loss: 0.2808 - accuracy: 0.9142\n",
      "168/469 [=========>....................] - ETA: 1s - loss: 0.2868 - accuracy: 0.9116\n",
      "193/469 [===========>..................] - ETA: 1s - loss: 0.2884 - accuracy: 0.9116\n",
      "219/469 [=============>................] - ETA: 1s - loss: 0.2889 - accuracy: 0.9121\n",
      "231/469 [=============>................] - ETA: 0s - loss: 0.2871 - accuracy: 0.9123\n",
      "257/469 [===============>..............] - ETA: 0s - loss: 0.2883 - accuracy: 0.9125\n",
      "281/469 [================>.............] - ETA: 0s - loss: 0.2879 - accuracy: 0.9127\n",
      "307/469 [==================>...........] - ETA: 0s - loss: 0.2888 - accuracy: 0.9127\n",
      "332/469 [====================>.........] - ETA: 0s - loss: 0.2875 - accuracy: 0.9131\n",
      "358/469 [=====================>........] - ETA: 0s - loss: 0.2874 - accuracy: 0.9131\n",
      "371/469 [======================>.......] - ETA: 0s - loss: 0.2857 - accuracy: 0.9136\n",
      "397/469 [========================>.....] - ETA: 0s - loss: 0.2829 - accuracy: 0.9142\n",
      "422/469 [=========================>....] - ETA: 0s - loss: 0.2830 - accuracy: 0.9142\n",
      "448/469 [===========================>..] - ETA: 0s - loss: 0.2823 - accuracy: 0.9143\n",
      "461/469 [============================>.] - ETA: 0s - loss: 0.2826 - accuracy: 0.9141\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.2831 - accuracy: 0.9140 - val_loss: 0.1237 - val_accuracy: 0.9649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=2641581)\u001b[0m 2023-12-05 09:49:51.420723: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=2641581)\u001b[0m 2023-12-05 09:49:51.459581: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=2641581)\u001b[0m 2023-12-05 09:49:51.459609: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=2641581)\u001b[0m 2023-12-05 09:49:51.460627: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=2641581)\u001b[0m 2023-12-05 09:49:51.466508: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=2641581)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=2641581)\u001b[0m 2023-12-05 09:49:52.171665: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=2641581)\u001b[0m 2023-12-05 09:49:53.489515: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_mnist pid=2641581)\u001b[0m Epoch 1/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_mnist pid=2641581)\u001b[0m 2023-12-05 09:49:55.205359: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=2641581)\u001b[0m 2023-12-05 09:49:56.172718: I external/local_xla/xla/service/service.cc:168] XLA service 0x145915ce0780 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=2641581)\u001b[0m 2023-12-05 09:49:56.172760: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=2641581)\u001b[0m 2023-12-05 09:49:56.179660: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=2641581)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=2641581)\u001b[0m I0000 00:00:1701787796.293462 2641734 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 11/938 [..............................] - ETA: 4s - loss: 68.8632 - accuracy: 0.1094  \n",
      " 35/938 [>.............................] - ETA: 4s - loss: 23.2338 - accuracy: 0.1112\n",
      " 59/938 [>.............................] - ETA: 4s - loss: 14.7219 - accuracy: 0.1110\n",
      " 83/938 [=>............................] - ETA: 3s - loss: 11.1315 - accuracy: 0.1101\n",
      "107/938 [==>...........................] - ETA: 3s - loss: 9.1512 - accuracy: 0.1097 \n",
      "130/938 [===>..........................] - ETA: 3s - loss: 7.9430 - accuracy: 0.1053\n",
      "154/938 [===>..........................] - ETA: 3s - loss: 7.0644 - accuracy: 0.1063\n",
      "165/938 [====>.........................] - ETA: 3s - loss: 6.7478 - accuracy: 0.1065\n",
      "189/938 [=====>........................] - ETA: 3s - loss: 6.1840 - accuracy: 0.1064\n",
      "213/938 [=====>........................] - ETA: 3s - loss: 5.7473 - accuracy: 0.1055\n",
      "238/938 [======>.......................] - ETA: 3s - loss: 5.3855 - accuracy: 0.1078\n",
      "263/938 [=======>......................] - ETA: 2s - loss: 5.0930 - accuracy: 0.1074\n",
      "286/938 [========>.....................] - ETA: 2s - loss: 4.8698 - accuracy: 0.1063\n",
      "311/938 [========>.....................] - ETA: 2s - loss: 4.6638 - accuracy: 0.1067\n",
      "335/938 [=========>....................] - ETA: 2s - loss: 4.4952 - accuracy: 0.1063\n",
      "347/938 [==========>...................] - ETA: 2s - loss: 4.4195 - accuracy: 0.1062\n",
      "370/938 [==========>...................] - ETA: 2s - loss: 4.2879 - accuracy: 0.1071\n",
      "394/938 [===========>..................] - ETA: 2s - loss: 4.1678 - accuracy: 0.1066\n",
      "420/938 [============>.................] - ETA: 2s - loss: 4.0524 - accuracy: 0.1066\n",
      "443/938 [=============>................] - ETA: 2s - loss: 3.9619 - accuracy: 0.1069\n",
      "468/938 [=============>................] - ETA: 2s - loss: 3.8738 - accuracy: 0.1068\n",
      "506/938 [===============>..............] - ETA: 1s - loss: 3.7566 - accuracy: 0.1058\n",
      "531/938 [===============>..............] - ETA: 1s - loss: 3.6884 - accuracy: 0.1055\n",
      "557/938 [================>.............] - ETA: 1s - loss: 3.6240 - accuracy: 0.1049\n",
      "582/938 [=================>............] - ETA: 1s - loss: 3.5676 - accuracy: 0.1047\n",
      "606/938 [==================>...........] - ETA: 1s - loss: 3.5176 - accuracy: 0.1052\n",
      "629/938 [===================>..........] - ETA: 1s - loss: 3.4737 - accuracy: 0.1049\n",
      "653/938 [===================>..........] - ETA: 1s - loss: 3.4309 - accuracy: 0.1047\n",
      "665/938 [====================>.........] - ETA: 1s - loss: 3.4108 - accuracy: 0.1043\n",
      "689/938 [=====================>........] - ETA: 1s - loss: 3.3725 - accuracy: 0.1044\n",
      "714/938 [=====================>........] - ETA: 0s - loss: 3.3351 - accuracy: 0.1045\n",
      "737/938 [======================>.......] - ETA: 0s - loss: 3.3031 - accuracy: 0.1047\n",
      "760/938 [=======================>......] - ETA: 0s - loss: 3.2731 - accuracy: 0.1046\n",
      "786/938 [========================>.....] - ETA: 0s - loss: 3.2412 - accuracy: 0.1044\n",
      "823/938 [=========================>....] - ETA: 0s - loss: 3.1991 - accuracy: 0.1050\n",
      "846/938 [==========================>...] - ETA: 0s - loss: 3.1750 - accuracy: 0.1046\n",
      "870/938 [==========================>...] - ETA: 0s - loss: 3.1510 - accuracy: 0.1044\n",
      "894/938 [===========================>..] - ETA: 0s - loss: 3.1284 - accuracy: 0.1042\n",
      "919/938 [============================>.] - ETA: 0s - loss: 3.1061 - accuracy: 0.1040\n",
      "930/938 [============================>.] - ETA: 0s - loss: 3.0967 - accuracy: 0.1041\n",
      "938/938 [==============================] - ETA: 0s - loss: 3.0904 - accuracy: 0.1041\n",
      "938/938 [==============================] - 7s 5ms/step - loss: 3.0904 - accuracy: 0.1041 - val_loss: 2.3054 - val_accuracy: 0.1135\n",
      "\u001b[36m(train_mnist pid=2641581)\u001b[0m Epoch 2/12\n",
      " 13/938 [..............................] - ETA: 4s - loss: 2.3094 - accuracy: 0.0962\n",
      " 38/938 [>.............................] - ETA: 3s - loss: 2.3044 - accuracy: 0.1073\n",
      " 61/938 [>.............................] - ETA: 3s - loss: 2.3054 - accuracy: 0.1073\n",
      " 86/938 [=>............................] - ETA: 3s - loss: 2.3054 - accuracy: 0.1085\n",
      " 99/938 [==>...........................] - ETA: 3s - loss: 2.3049 - accuracy: 0.1089\n",
      "123/938 [==>...........................] - ETA: 3s - loss: 2.3057 - accuracy: 0.1079\n",
      "147/938 [===>..........................] - ETA: 3s - loss: 2.3063 - accuracy: 0.1068\n",
      "170/938 [====>.........................] - ETA: 3s - loss: 2.3062 - accuracy: 0.1076\n",
      "194/938 [=====>........................] - ETA: 3s - loss: 2.3066 - accuracy: 0.1062\n",
      "217/938 [=====>........................] - ETA: 3s - loss: 2.3068 - accuracy: 0.1049\n",
      "240/938 [======>.......................] - ETA: 3s - loss: 2.3069 - accuracy: 0.1045\n",
      "263/938 [=======>......................] - ETA: 2s - loss: 2.3068 - accuracy: 0.1049\n",
      "275/938 [=======>......................] - ETA: 2s - loss: 2.3072 - accuracy: 0.1049\n",
      "300/938 [========>.....................] - ETA: 2s - loss: 2.3072 - accuracy: 0.1052\n",
      "323/938 [=========>....................] - ETA: 2s - loss: 2.3077 - accuracy: 0.1040\n",
      "345/938 [==========>...................] - ETA: 2s - loss: 2.3077 - accuracy: 0.1041\n",
      "367/938 [==========>...................] - ETA: 2s - loss: 2.3075 - accuracy: 0.1044\n",
      "390/938 [===========>..................] - ETA: 2s - loss: 2.3077 - accuracy: 0.1045\n",
      "425/938 [============>.................] - ETA: 2s - loss: 2.3078 - accuracy: 0.1041\n",
      "450/938 [=============>................] - ETA: 2s - loss: 2.3078 - accuracy: 0.1039\n",
      "475/938 [==============>...............] - ETA: 2s - loss: 2.3080 - accuracy: 0.1031\n",
      "499/938 [==============>...............] - ETA: 1s - loss: 2.3080 - accuracy: 0.1031\n",
      "523/938 [===============>..............] - ETA: 1s - loss: 2.3079 - accuracy: 0.1030\n",
      "547/938 [================>.............] - ETA: 1s - loss: 2.3080 - accuracy: 0.1029\n",
      "558/938 [================>.............] - ETA: 1s - loss: 2.3081 - accuracy: 0.1025\n",
      "583/938 [=================>............] - ETA: 1s - loss: 2.3082 - accuracy: 0.1027\n",
      "606/938 [==================>...........] - ETA: 1s - loss: 2.3082 - accuracy: 0.1030\n",
      "628/938 [===================>..........] - ETA: 1s - loss: 2.3081 - accuracy: 0.1032\n",
      "652/938 [===================>..........] - ETA: 1s - loss: 2.3080 - accuracy: 0.1029\n",
      "675/938 [====================>.........] - ETA: 1s - loss: 2.3081 - accuracy: 0.1028\n",
      "687/938 [====================>.........] - ETA: 1s - loss: 2.3082 - accuracy: 0.1027\n",
      "710/938 [=====================>........] - ETA: 1s - loss: 2.3083 - accuracy: 0.1028\n",
      "733/938 [======================>.......] - ETA: 0s - loss: 2.3084 - accuracy: 0.1024\n",
      "756/938 [=======================>......] - ETA: 0s - loss: 2.3085 - accuracy: 0.1027\n",
      "781/938 [=======================>......] - ETA: 0s - loss: 2.3084 - accuracy: 0.1029\n",
      "807/938 [========================>.....] - ETA: 0s - loss: 2.3082 - accuracy: 0.1035\n",
      "832/938 [=========================>....] - ETA: 0s - loss: 2.3082 - accuracy: 0.1040\n",
      "856/938 [==========================>...] - ETA: 0s - loss: 2.3082 - accuracy: 0.1039\n",
      "891/938 [===========================>..] - ETA: 0s - loss: 2.3082 - accuracy: 0.1037\n",
      "914/938 [============================>.] - ETA: 0s - loss: 2.3081 - accuracy: 0.1040\n",
      "938/938 [==============================] - ETA: 0s - loss: 2.3082 - accuracy: 0.1042\n",
      "938/938 [==============================] - 4s 5ms/step - loss: 2.3082 - accuracy: 0.1042 - val_loss: 2.3058 - val_accuracy: 0.1009\n",
      "\u001b[36m(train_mnist pid=2641581)\u001b[0m Epoch 3/12\n",
      "  1/938 [..............................] - ETA: 4s - loss: 2.3090 - accuracy: 0.0469\n",
      " 25/938 [..............................] - ETA: 3s - loss: 2.3045 - accuracy: 0.1081\n",
      " 49/938 [>.............................] - ETA: 3s - loss: 2.3054 - accuracy: 0.1110\n",
      " 73/938 [=>............................] - ETA: 3s - loss: 2.3069 - accuracy: 0.1045\n",
      " 97/938 [==>...........................] - ETA: 3s - loss: 2.3083 - accuracy: 0.1049\n",
      "122/938 [==>...........................] - ETA: 3s - loss: 2.3085 - accuracy: 0.1040\n",
      "133/938 [===>..........................] - ETA: 3s - loss: 2.3084 - accuracy: 0.1040\n",
      "156/938 [===>..........................] - ETA: 3s - loss: 2.3087 - accuracy: 0.1029\n",
      "180/938 [====>.........................] - ETA: 3s - loss: 2.3085 - accuracy: 0.1026\n",
      "203/938 [=====>........................] - ETA: 3s - loss: 2.3079 - accuracy: 0.1023\n",
      "227/938 [======>.......................] - ETA: 3s - loss: 2.3075 - accuracy: 0.1019\n",
      "251/938 [=======>......................] - ETA: 2s - loss: 2.3077 - accuracy: 0.1025\n",
      "275/938 [=======>......................] - ETA: 2s - loss: 2.3079 - accuracy: 0.1023\n",
      "286/938 [========>.....................] - ETA: 2s - loss: 2.3078 - accuracy: 0.1030\n",
      "309/938 [========>.....................] - ETA: 2s - loss: 2.3078 - accuracy: 0.1030\n",
      "332/938 [=========>....................] - ETA: 2s - loss: 2.3077 - accuracy: 0.1028\n",
      "354/938 [==========>...................] - ETA: 2s - loss: 2.3076 - accuracy: 0.1035\n",
      "378/938 [===========>..................] - ETA: 2s - loss: 2.3076 - accuracy: 0.1033\n",
      "402/938 [===========>..................] - ETA: 2s - loss: 2.3077 - accuracy: 0.1030\n",
      "426/938 [============>.................] - ETA: 2s - loss: 2.3076 - accuracy: 0.1031\n",
      "449/938 [=============>................] - ETA: 2s - loss: 2.3077 - accuracy: 0.1033\n",
      "473/938 [==============>...............] - ETA: 2s - loss: 2.3080 - accuracy: 0.1031\n",
      "485/938 [==============>...............] - ETA: 2s - loss: 2.3081 - accuracy: 0.1029\n",
      "510/938 [===============>..............] - ETA: 1s - loss: 2.3082 - accuracy: 0.1027\n",
      "533/938 [================>.............] - ETA: 1s - loss: 2.3081 - accuracy: 0.1031\n",
      "555/938 [================>.............] - ETA: 1s - loss: 2.3082 - accuracy: 0.1032\n",
      "580/938 [=================>............] - ETA: 1s - loss: 2.3080 - accuracy: 0.1036\n",
      "604/938 [==================>...........] - ETA: 1s - loss: 2.3081 - accuracy: 0.1031\n",
      "629/938 [===================>..........] - ETA: 1s - loss: 2.3080 - accuracy: 0.1034\n",
      "655/938 [===================>..........] - ETA: 1s - loss: 2.3078 - accuracy: 0.1034\n",
      "667/938 [====================>.........] - ETA: 1s - loss: 2.3078 - accuracy: 0.1035\n",
      "690/938 [=====================>........] - ETA: 1s - loss: 2.3079 - accuracy: 0.1037\n",
      "713/938 [=====================>........] - ETA: 0s - loss: 2.3078 - accuracy: 0.1039\n",
      "737/938 [======================>.......] - ETA: 0s - loss: 2.3077 - accuracy: 0.1038\n",
      "760/938 [=======================>......] - ETA: 0s - loss: 2.3077 - accuracy: 0.1040\n",
      "782/938 [========================>.....] - ETA: 0s - loss: 2.3075 - accuracy: 0.1044\n",
      "806/938 [========================>.....] - ETA: 0s - loss: 2.3076 - accuracy: 0.1044\n",
      "818/938 [=========================>....] - ETA: 0s - loss: 2.3076 - accuracy: 0.1044\n",
      "841/938 [=========================>....] - ETA: 0s - loss: 2.3075 - accuracy: 0.1048\n",
      "865/938 [==========================>...] - ETA: 0s - loss: 2.3075 - accuracy: 0.1046\n",
      "889/938 [===========================>..] - ETA: 0s - loss: 2.3075 - accuracy: 0.1049\n",
      "911/938 [============================>.] - ETA: 0s - loss: 2.3076 - accuracy: 0.1050\n",
      "934/938 [============================>.] - ETA: 0s - loss: 2.3076 - accuracy: 0.1052\n",
      "938/938 [==============================] - 4s 5ms/step - loss: 2.3076 - accuracy: 0.1051 - val_loss: 2.3091 - val_accuracy: 0.1028\n",
      "\u001b[36m(train_mnist pid=2641581)\u001b[0m Epoch 4/12\n",
      "  1/938 [..............................] - ETA: 4s - loss: 2.2964 - accuracy: 0.1406\n",
      " 24/938 [..............................] - ETA: 4s - loss: 2.3068 - accuracy: 0.1113\n",
      " 48/938 [>.............................] - ETA: 3s - loss: 2.3079 - accuracy: 0.1090\n",
      " 73/938 [=>............................] - ETA: 3s - loss: 2.3073 - accuracy: 0.1081\n",
      " 96/938 [==>...........................] - ETA: 3s - loss: 2.3068 - accuracy: 0.1089\n",
      "108/938 [==>...........................] - ETA: 3s - loss: 2.3065 - accuracy: 0.1091\n",
      "133/938 [===>..........................] - ETA: 3s - loss: 2.3072 - accuracy: 0.1055\n",
      "157/938 [====>.........................] - ETA: 3s - loss: 2.3088 - accuracy: 0.1047\n",
      "181/938 [====>.........................] - ETA: 3s - loss: 2.3095 - accuracy: 0.1043\n",
      "204/938 [=====>........................] - ETA: 3s - loss: 2.3091 - accuracy: 0.1032\n",
      "226/938 [======>.......................] - ETA: 3s - loss: 2.3086 - accuracy: 0.1023\n",
      "237/938 [======>.......................] - ETA: 3s - loss: 2.3089 - accuracy: 0.1024\n",
      "259/938 [=======>......................] - ETA: 2s - loss: 2.3085 - accuracy: 0.1033\n",
      "284/938 [========>.....................] - ETA: 2s - loss: 2.3088 - accuracy: 0.1034\n",
      "308/938 [========>.....................] - ETA: 2s - loss: 2.3084 - accuracy: 0.1048\n",
      "331/938 [=========>....................] - ETA: 2s - loss: 2.3087 - accuracy: 0.1048\n",
      "355/938 [==========>...................] - ETA: 2s - loss: 2.3088 - accuracy: 0.1044\n",
      "379/938 [===========>..................] - ETA: 2s - loss: 2.3084 - accuracy: 0.1052\n",
      "402/938 [===========>..................] - ETA: 2s - loss: 2.3086 - accuracy: 0.1048\n",
      "413/938 [============>.................] - ETA: 2s - loss: 2.3087 - accuracy: 0.1045\n",
      "435/938 [============>.................] - ETA: 2s - loss: 2.3086 - accuracy: 0.1047\n",
      "459/938 [=============>................] - ETA: 2s - loss: 2.3083 - accuracy: 0.1051\n",
      "482/938 [==============>...............] - ETA: 2s - loss: 2.3082 - accuracy: 0.1052\n",
      "505/938 [===============>..............] - ETA: 1s - loss: 2.3085 - accuracy: 0.1045\n",
      "529/938 [===============>..............] - ETA: 1s - loss: 2.3086 - accuracy: 0.1046\n",
      "553/938 [================>.............] - ETA: 1s - loss: 2.3087 - accuracy: 0.1044\n",
      "575/938 [=================>............] - ETA: 1s - loss: 2.3087 - accuracy: 0.1044\n",
      "598/938 [==================>...........] - ETA: 1s - loss: 2.3087 - accuracy: 0.1042\n",
      "609/938 [==================>...........] - ETA: 1s - loss: 2.3086 - accuracy: 0.1042\n",
      "633/938 [===================>..........] - ETA: 1s - loss: 2.3086 - accuracy: 0.1040\n",
      "659/938 [====================>.........] - ETA: 1s - loss: 2.3087 - accuracy: 0.1038\n",
      "682/938 [====================>.........] - ETA: 1s - loss: 2.3089 - accuracy: 0.1040\n",
      "706/938 [=====================>........] - ETA: 1s - loss: 2.3089 - accuracy: 0.1038\n",
      "729/938 [======================>.......] - ETA: 0s - loss: 2.3088 - accuracy: 0.1039\n",
      "753/938 [=======================>......] - ETA: 0s - loss: 2.3086 - accuracy: 0.1039\n",
      "777/938 [=======================>......] - ETA: 0s - loss: 2.3085 - accuracy: 0.1044\n",
      "789/938 [========================>.....] - ETA: 0s - loss: 2.3085 - accuracy: 0.1043\n",
      "813/938 [=========================>....] - ETA: 0s - loss: 2.3086 - accuracy: 0.1040\n",
      "836/938 [=========================>....] - ETA: 0s - loss: 2.3087 - accuracy: 0.1037\n",
      "860/938 [==========================>...] - ETA: 0s - loss: 2.3087 - accuracy: 0.1035\n",
      "885/938 [===========================>..] - ETA: 0s - loss: 2.3090 - accuracy: 0.1032\n",
      "910/938 [============================>.] - ETA: 0s - loss: 2.3090 - accuracy: 0.1036\n",
      "935/938 [============================>.] - ETA: 0s - loss: 2.3089 - accuracy: 0.1039\n",
      "938/938 [==============================] - 4s 5ms/step - loss: 2.3089 - accuracy: 0.1040 - val_loss: 2.3066 - val_accuracy: 0.1028\n",
      "\u001b[36m(train_mnist pid=2641581)\u001b[0m Epoch 5/12\n",
      "  1/938 [..............................] - ETA: 4s - loss: 2.3121 - accuracy: 0.0938\n",
      " 25/938 [..............................] - ETA: 3s - loss: 2.2998 - accuracy: 0.1244\n",
      " 47/938 [>.............................] - ETA: 4s - loss: 2.3030 - accuracy: 0.1210\n",
      " 69/938 [=>............................] - ETA: 3s - loss: 2.3045 - accuracy: 0.1196\n",
      " 92/938 [=>............................] - ETA: 3s - loss: 2.3057 - accuracy: 0.1153\n",
      "104/938 [==>...........................] - ETA: 3s - loss: 2.3058 - accuracy: 0.1139\n",
      "126/938 [===>..........................] - ETA: 3s - loss: 2.3062 - accuracy: 0.1128\n",
      "150/938 [===>..........................] - ETA: 3s - loss: 2.3054 - accuracy: 0.1158\n",
      "173/938 [====>.........................] - ETA: 3s - loss: 2.3061 - accuracy: 0.1137\n",
      "196/938 [=====>........................] - ETA: 3s - loss: 2.3062 - accuracy: 0.1119\n",
      "218/938 [=====>........................] - ETA: 3s - loss: 2.3069 - accuracy: 0.1094\n",
      "240/938 [======>.......................] - ETA: 3s - loss: 2.3067 - accuracy: 0.1098\n",
      "265/938 [=======>......................] - ETA: 3s - loss: 2.3066 - accuracy: 0.1093\n",
      "276/938 [=======>......................] - ETA: 3s - loss: 2.3066 - accuracy: 0.1090\n",
      "300/938 [========>.....................] - ETA: 2s - loss: 2.3066 - accuracy: 0.1085\n",
      "322/938 [=========>....................] - ETA: 2s - loss: 2.3067 - accuracy: 0.1088\n",
      "346/938 [==========>...................] - ETA: 2s - loss: 2.3068 - accuracy: 0.1088\n",
      "369/938 [==========>...................] - ETA: 2s - loss: 2.3065 - accuracy: 0.1089\n",
      "393/938 [===========>..................] - ETA: 2s - loss: 2.3070 - accuracy: 0.1080\n",
      "417/938 [============>.................] - ETA: 2s - loss: 2.3072 - accuracy: 0.1078\n",
      "443/938 [=============>................] - ETA: 2s - loss: 2.3072 - accuracy: 0.1075\n",
      "478/938 [==============>...............] - ETA: 2s - loss: 2.3070 - accuracy: 0.1069\n",
      "502/938 [===============>..............] - ETA: 1s - loss: 2.3069 - accuracy: 0.1072\n",
      "525/938 [===============>..............] - ETA: 1s - loss: 2.3067 - accuracy: 0.1073\n",
      "548/938 [================>.............] - ETA: 1s - loss: 2.3069 - accuracy: 0.1072\n",
      "573/938 [=================>............] - ETA: 1s - loss: 2.3071 - accuracy: 0.1076\n",
      "598/938 [==================>...........] - ETA: 1s - loss: 2.3072 - accuracy: 0.1071\n",
      "622/938 [==================>...........] - ETA: 1s - loss: 2.3073 - accuracy: 0.1069\n",
      "644/938 [===================>..........] - ETA: 1s - loss: 2.3073 - accuracy: 0.1074\n",
      "678/938 [====================>.........] - ETA: 1s - loss: 2.3075 - accuracy: 0.1073\n",
      "702/938 [=====================>........] - ETA: 1s - loss: 2.3075 - accuracy: 0.1070\n",
      "726/938 [======================>.......] - ETA: 0s - loss: 2.3077 - accuracy: 0.1072\n",
      "750/938 [======================>.......] - ETA: 0s - loss: 2.3077 - accuracy: 0.1072\n",
      "775/938 [=======================>......] - ETA: 0s - loss: 2.3077 - accuracy: 0.1070\n",
      "798/938 [========================>.....] - ETA: 0s - loss: 2.3077 - accuracy: 0.1070\n",
      "822/938 [=========================>....] - ETA: 0s - loss: 2.3079 - accuracy: 0.1067\n",
      "845/938 [==========================>...] - ETA: 0s - loss: 2.3078 - accuracy: 0.1067\n",
      "881/938 [===========================>..] - ETA: 0s - loss: 2.3078 - accuracy: 0.1064\n",
      "904/938 [===========================>..] - ETA: 0s - loss: 2.3078 - accuracy: 0.1067\n",
      "928/938 [============================>.] - ETA: 0s - loss: 2.3079 - accuracy: 0.1068\n",
      "938/938 [==============================] - ETA: 0s - loss: 2.3078 - accuracy: 0.1067\n",
      "938/938 [==============================] - 5s 5ms/step - loss: 2.3078 - accuracy: 0.1067 - val_loss: 2.3116 - val_accuracy: 0.1135\n",
      "\u001b[36m(train_mnist pid=2641581)\u001b[0m Epoch 6/12\n",
      " 12/938 [..............................] - ETA: 4s - loss: 2.3169 - accuracy: 0.1211\n",
      " 34/938 [>.............................] - ETA: 4s - loss: 2.3108 - accuracy: 0.1153\n",
      " 58/938 [>.............................] - ETA: 4s - loss: 2.3095 - accuracy: 0.1102\n",
      " 84/938 [=>............................] - ETA: 3s - loss: 2.3104 - accuracy: 0.1075\n",
      "109/938 [==>...........................] - ETA: 3s - loss: 2.3100 - accuracy: 0.1056\n",
      "132/938 [===>..........................] - ETA: 3s - loss: 2.3091 - accuracy: 0.1050\n",
      "154/938 [===>..........................] - ETA: 3s - loss: 2.3091 - accuracy: 0.1060\n",
      "165/938 [====>.........................] - ETA: 3s - loss: 2.3088 - accuracy: 0.1064\n",
      "188/938 [=====>........................] - ETA: 3s - loss: 2.3087 - accuracy: 0.1057\n",
      "211/938 [=====>........................] - ETA: 3s - loss: 2.3089 - accuracy: 0.1050\n",
      "235/938 [======>.......................] - ETA: 3s - loss: 2.3084 - accuracy: 0.1051\n",
      "257/938 [=======>......................] - ETA: 3s - loss: 2.3086 - accuracy: 0.1062\n",
      "281/938 [=======>......................] - ETA: 2s - loss: 2.3087 - accuracy: 0.1064\n",
      "315/938 [=========>....................] - ETA: 2s - loss: 2.3084 - accuracy: 0.1063\n",
      "337/938 [=========>....................] - ETA: 2s - loss: 2.3083 - accuracy: 0.1072\n",
      "360/938 [==========>...................] - ETA: 2s - loss: 2.3083 - accuracy: 0.1066\n",
      "383/938 [===========>..................] - ETA: 2s - loss: 2.3085 - accuracy: 0.1059\n",
      "405/938 [===========>..................] - ETA: 2s - loss: 2.3086 - accuracy: 0.1052\n",
      "428/938 [============>.................] - ETA: 2s - loss: 2.3088 - accuracy: 0.1053\n",
      "462/938 [=============>................] - ETA: 2s - loss: 2.3088 - accuracy: 0.1045\n",
      "485/938 [==============>...............] - ETA: 2s - loss: 2.3086 - accuracy: 0.1049\n",
      "511/938 [===============>..............] - ETA: 1s - loss: 2.3086 - accuracy: 0.1048\n",
      "535/938 [================>.............] - ETA: 1s - loss: 2.3085 - accuracy: 0.1049\n",
      "558/938 [================>.............] - ETA: 1s - loss: 2.3085 - accuracy: 0.1049\n",
      "581/938 [=================>............] - ETA: 1s - loss: 2.3086 - accuracy: 0.1047\n",
      "607/938 [==================>...........] - ETA: 1s - loss: 2.3085 - accuracy: 0.1045\n",
      "630/938 [===================>..........] - ETA: 1s - loss: 2.3086 - accuracy: 0.1043\n",
      "654/938 [===================>..........] - ETA: 1s - loss: 2.3088 - accuracy: 0.1039\n",
      "677/938 [====================>.........] - ETA: 1s - loss: 2.3086 - accuracy: 0.1041\n",
      "700/938 [=====================>........] - ETA: 1s - loss: 2.3086 - accuracy: 0.1041\n",
      "724/938 [======================>.......] - ETA: 0s - loss: 2.3085 - accuracy: 0.1046\n",
      "735/938 [======================>.......] - ETA: 0s - loss: 2.3086 - accuracy: 0.1045\n",
      "758/938 [=======================>......] - ETA: 0s - loss: 2.3086 - accuracy: 0.1045\n",
      "782/938 [========================>.....] - ETA: 0s - loss: 2.3085 - accuracy: 0.1046\n",
      "808/938 [========================>.....] - ETA: 0s - loss: 2.3084 - accuracy: 0.1048\n",
      "831/938 [=========================>....] - ETA: 0s - loss: 2.3083 - accuracy: 0.1050\n",
      "854/938 [==========================>...] - ETA: 0s - loss: 2.3083 - accuracy: 0.1049\n",
      "865/938 [==========================>...] - ETA: 0s - loss: 2.3083 - accuracy: 0.1049\n",
      "891/938 [===========================>..] - ETA: 0s - loss: 2.3082 - accuracy: 0.1052\n",
      "914/938 [============================>.] - ETA: 0s - loss: 2.3083 - accuracy: 0.1048\n",
      "937/938 [============================>.] - ETA: 0s - loss: 2.3083 - accuracy: 0.1048\n",
      "938/938 [==============================] - 5s 5ms/step - loss: 2.3084 - accuracy: 0.1048 - val_loss: 2.3069 - val_accuracy: 0.0982\n",
      "\u001b[36m(train_mnist pid=2641581)\u001b[0m Epoch 7/12\n",
      "  1/938 [..............................] - ETA: 4s - loss: 2.3017 - accuracy: 0.1562\n",
      " 23/938 [..............................] - ETA: 4s - loss: 2.3071 - accuracy: 0.1114\n",
      " 48/938 [>.............................] - ETA: 3s - loss: 2.3056 - accuracy: 0.1113\n",
      " 72/938 [=>............................] - ETA: 3s - loss: 2.3066 - accuracy: 0.1102\n",
      " 96/938 [==>...........................] - ETA: 3s - loss: 2.3075 - accuracy: 0.1082\n",
      "120/938 [==>...........................] - ETA: 3s - loss: 2.3079 - accuracy: 0.1072\n",
      "143/938 [===>..........................] - ETA: 3s - loss: 2.3076 - accuracy: 0.1066\n",
      "179/938 [====>.........................] - ETA: 3s - loss: 2.3082 - accuracy: 0.1070\n",
      "202/938 [=====>........................] - ETA: 3s - loss: 2.3077 - accuracy: 0.1094\n",
      "226/938 [======>.......................] - ETA: 3s - loss: 2.3070 - accuracy: 0.1101\n",
      "249/938 [======>.......................] - ETA: 3s - loss: 2.3071 - accuracy: 0.1094\n",
      "271/938 [=======>......................] - ETA: 2s - loss: 2.3071 - accuracy: 0.1083\n",
      "295/938 [========>.....................] - ETA: 2s - loss: 2.3070 - accuracy: 0.1093\n",
      "318/938 [=========>....................] - ETA: 2s - loss: 2.3070 - accuracy: 0.1102\n",
      "329/938 [=========>....................] - ETA: 2s - loss: 2.3070 - accuracy: 0.1100\n",
      "351/938 [==========>...................] - ETA: 2s - loss: 2.3072 - accuracy: 0.1093\n",
      "377/938 [===========>..................] - ETA: 2s - loss: 2.3073 - accuracy: 0.1097\n",
      "401/938 [===========>..................] - ETA: 2s - loss: 2.3075 - accuracy: 0.1087\n",
      "426/938 [============>.................] - ETA: 2s - loss: 2.3077 - accuracy: 0.1080\n",
      "450/938 [=============>................] - ETA: 2s - loss: 2.3079 - accuracy: 0.1076\n",
      "473/938 [==============>...............] - ETA: 2s - loss: 2.3079 - accuracy: 0.1073\n",
      "484/938 [==============>...............] - ETA: 2s - loss: 2.3080 - accuracy: 0.1069\n",
      "507/938 [===============>..............] - ETA: 1s - loss: 2.3081 - accuracy: 0.1065\n",
      "531/938 [===============>..............] - ETA: 1s - loss: 2.3083 - accuracy: 0.1060\n",
      "555/938 [================>.............] - ETA: 1s - loss: 2.3083 - accuracy: 0.1058\n",
      "577/938 [=================>............] - ETA: 1s - loss: 2.3083 - accuracy: 0.1055\n",
      "599/938 [==================>...........] - ETA: 1s - loss: 2.3082 - accuracy: 0.1061\n",
      "621/938 [==================>...........] - ETA: 1s - loss: 2.3083 - accuracy: 0.1056\n",
      "644/938 [===================>..........] - ETA: 1s - loss: 2.3083 - accuracy: 0.1058\n",
      "656/938 [===================>..........] - ETA: 1s - loss: 2.3084 - accuracy: 0.1059\n",
      "680/938 [====================>.........] - ETA: 1s - loss: 2.3085 - accuracy: 0.1059\n",
      "705/938 [=====================>........] - ETA: 1s - loss: 2.3084 - accuracy: 0.1059\n",
      "729/938 [======================>.......] - ETA: 0s - loss: 2.3084 - accuracy: 0.1057\n",
      "752/938 [=======================>......] - ETA: 0s - loss: 2.3084 - accuracy: 0.1058\n",
      "776/938 [=======================>......] - ETA: 0s - loss: 2.3083 - accuracy: 0.1059\n",
      "800/938 [========================>.....] - ETA: 0s - loss: 2.3082 - accuracy: 0.1057\n",
      "812/938 [========================>.....] - ETA: 0s - loss: 2.3082 - accuracy: 0.1060\n",
      "836/938 [=========================>....] - ETA: 0s - loss: 2.3083 - accuracy: 0.1056\n",
      "860/938 [==========================>...] - ETA: 0s - loss: 2.3082 - accuracy: 0.1057\n",
      "885/938 [===========================>..] - ETA: 0s - loss: 2.3083 - accuracy: 0.1055\n",
      "909/938 [============================>.] - ETA: 0s - loss: 2.3084 - accuracy: 0.1053\n",
      "934/938 [============================>.] - ETA: 0s - loss: 2.3084 - accuracy: 0.1051\n",
      "938/938 [==============================] - 4s 5ms/step - loss: 2.3084 - accuracy: 0.1051 - val_loss: 2.3031 - val_accuracy: 0.1135\n",
      "\u001b[36m(train_mnist pid=2641581)\u001b[0m Epoch 8/12\n",
      "  1/938 [..............................] - ETA: 4s - loss: 2.3161 - accuracy: 0.0938\n",
      " 23/938 [..............................] - ETA: 4s - loss: 2.3032 - accuracy: 0.1223\n",
      " 45/938 [>.............................] - ETA: 4s - loss: 2.3068 - accuracy: 0.1139\n",
      " 80/938 [=>............................] - ETA: 3s - loss: 2.3080 - accuracy: 0.1100\n",
      "104/938 [==>...........................] - ETA: 3s - loss: 2.3077 - accuracy: 0.1109\n",
      "128/938 [===>..........................] - ETA: 3s - loss: 2.3076 - accuracy: 0.1089\n",
      "152/938 [===>..........................] - ETA: 3s - loss: 2.3071 - accuracy: 0.1076\n",
      "175/938 [====>.........................] - ETA: 3s - loss: 2.3078 - accuracy: 0.1068\n",
      "199/938 [=====>........................] - ETA: 3s - loss: 2.3081 - accuracy: 0.1069\n",
      "211/938 [=====>........................] - ETA: 3s - loss: 2.3081 - accuracy: 0.1074\n",
      "235/938 [======>.......................] - ETA: 3s - loss: 2.3081 - accuracy: 0.1061\n",
      "260/938 [=======>......................] - ETA: 2s - loss: 2.3076 - accuracy: 0.1053\n",
      "284/938 [========>.....................] - ETA: 2s - loss: 2.3073 - accuracy: 0.1052\n",
      "308/938 [========>.....................] - ETA: 2s - loss: 2.3068 - accuracy: 0.1068\n",
      "332/938 [=========>....................] - ETA: 2s - loss: 2.3071 - accuracy: 0.1064\n",
      "369/938 [==========>...................] - ETA: 2s - loss: 2.3071 - accuracy: 0.1056\n",
      "394/938 [===========>..................] - ETA: 2s - loss: 2.3070 - accuracy: 0.1058\n",
      "416/938 [============>.................] - ETA: 2s - loss: 2.3071 - accuracy: 0.1061\n",
      "439/938 [=============>................] - ETA: 2s - loss: 2.3073 - accuracy: 0.1060\n",
      "463/938 [=============>................] - ETA: 2s - loss: 2.3070 - accuracy: 0.1058\n",
      "486/938 [==============>...............] - ETA: 1s - loss: 2.3072 - accuracy: 0.1058\n",
      "510/938 [===============>..............] - ETA: 1s - loss: 2.3072 - accuracy: 0.1058\n",
      "545/938 [================>.............] - ETA: 1s - loss: 2.3073 - accuracy: 0.1052\n",
      "567/938 [=================>............] - ETA: 1s - loss: 2.3074 - accuracy: 0.1054\n",
      "590/938 [=================>............] - ETA: 1s - loss: 2.3074 - accuracy: 0.1052\n",
      "614/938 [==================>...........] - ETA: 1s - loss: 2.3077 - accuracy: 0.1048\n",
      "638/938 [===================>..........] - ETA: 1s - loss: 2.3078 - accuracy: 0.1052\n",
      "661/938 [====================>.........] - ETA: 1s - loss: 2.3078 - accuracy: 0.1048\n",
      "673/938 [====================>.........] - ETA: 1s - loss: 2.3079 - accuracy: 0.1048\n",
      "695/938 [=====================>........] - ETA: 1s - loss: 2.3079 - accuracy: 0.1045\n",
      "720/938 [======================>.......] - ETA: 0s - loss: 2.3080 - accuracy: 0.1046\n",
      "743/938 [======================>.......] - ETA: 0s - loss: 2.3081 - accuracy: 0.1046\n",
      "766/938 [=======================>......] - ETA: 0s - loss: 2.3079 - accuracy: 0.1050\n",
      "790/938 [========================>.....] - ETA: 0s - loss: 2.3081 - accuracy: 0.1047\n",
      "812/938 [========================>.....] - ETA: 0s - loss: 2.3080 - accuracy: 0.1051\n",
      "824/938 [=========================>....] - ETA: 0s - loss: 2.3081 - accuracy: 0.1052\n",
      "848/938 [==========================>...] - ETA: 0s - loss: 2.3081 - accuracy: 0.1050\n",
      "872/938 [==========================>...] - ETA: 0s - loss: 2.3081 - accuracy: 0.1050\n",
      "896/938 [===========================>..] - ETA: 0s - loss: 2.3081 - accuracy: 0.1046\n",
      "918/938 [============================>.] - ETA: 0s - loss: 2.3082 - accuracy: 0.1043\n",
      "929/938 [============================>.] - ETA: 0s - loss: 2.3082 - accuracy: 0.1042\n",
      "938/938 [==============================] - 4s 5ms/step - loss: 2.3083 - accuracy: 0.1041 - val_loss: 2.3076 - val_accuracy: 0.1135\n",
      "\u001b[36m(train_mnist pid=2641581)\u001b[0m Epoch 9/12\n",
      "  1/938 [..............................] - ETA: 4s - loss: 2.2935 - accuracy: 0.1875\n",
      " 25/938 [..............................] - ETA: 3s - loss: 2.3085 - accuracy: 0.1063\n",
      " 50/938 [>.............................] - ETA: 3s - loss: 2.3075 - accuracy: 0.1122\n",
      " 73/938 [=>............................] - ETA: 3s - loss: 2.3079 - accuracy: 0.1117\n",
      " 85/938 [=>............................] - ETA: 3s - loss: 2.3089 - accuracy: 0.1094\n",
      "110/938 [==>...........................] - ETA: 3s - loss: 2.3084 - accuracy: 0.1094\n",
      "132/938 [===>..........................] - ETA: 3s - loss: 2.3078 - accuracy: 0.1098\n",
      "156/938 [===>..........................] - ETA: 3s - loss: 2.3073 - accuracy: 0.1088\n",
      "179/938 [====>.........................] - ETA: 3s - loss: 2.3080 - accuracy: 0.1072\n",
      "204/938 [=====>........................] - ETA: 3s - loss: 2.3084 - accuracy: 0.1068\n",
      "227/938 [======>.......................] - ETA: 3s - loss: 2.3089 - accuracy: 0.1069\n",
      "249/938 [======>.......................] - ETA: 3s - loss: 2.3090 - accuracy: 0.1064\n",
      "285/938 [========>.....................] - ETA: 2s - loss: 2.3089 - accuracy: 0.1069\n",
      "309/938 [========>.....................] - ETA: 2s - loss: 2.3086 - accuracy: 0.1066\n",
      "334/938 [=========>....................] - ETA: 2s - loss: 2.3091 - accuracy: 0.1064\n",
      "357/938 [==========>...................] - ETA: 2s - loss: 2.3089 - accuracy: 0.1064\n",
      "381/938 [===========>..................] - ETA: 2s - loss: 2.3090 - accuracy: 0.1070\n",
      "404/938 [===========>..................] - ETA: 2s - loss: 2.3088 - accuracy: 0.1071\n",
      "426/938 [============>.................] - ETA: 2s - loss: 2.3089 - accuracy: 0.1060\n",
      "461/938 [=============>................] - ETA: 2s - loss: 2.3089 - accuracy: 0.1059\n",
      "486/938 [==============>...............] - ETA: 2s - loss: 2.3087 - accuracy: 0.1061\n",
      "509/938 [===============>..............] - ETA: 1s - loss: 2.3088 - accuracy: 0.1056\n",
      "533/938 [================>.............] - ETA: 1s - loss: 2.3087 - accuracy: 0.1055\n",
      "557/938 [================>.............] - ETA: 1s - loss: 2.3089 - accuracy: 0.1056\n",
      "581/938 [=================>............] - ETA: 1s - loss: 2.3089 - accuracy: 0.1056\n",
      "604/938 [==================>...........] - ETA: 1s - loss: 2.3088 - accuracy: 0.1057\n",
      "616/938 [==================>...........] - ETA: 1s - loss: 2.3088 - accuracy: 0.1052\n",
      "641/938 [===================>..........] - ETA: 1s - loss: 2.3087 - accuracy: 0.1046\n",
      "667/938 [====================>.........] - ETA: 1s - loss: 2.3086 - accuracy: 0.1046\n",
      "692/938 [=====================>........] - ETA: 1s - loss: 2.3085 - accuracy: 0.1050\n",
      "716/938 [=====================>........] - ETA: 0s - loss: 2.3083 - accuracy: 0.1060\n",
      "739/938 [======================>.......] - ETA: 0s - loss: 2.3085 - accuracy: 0.1059\n",
      "762/938 [=======================>......] - ETA: 0s - loss: 2.3085 - accuracy: 0.1056\n",
      "785/938 [========================>.....] - ETA: 0s - loss: 2.3086 - accuracy: 0.1055\n",
      "797/938 [========================>.....] - ETA: 0s - loss: 2.3086 - accuracy: 0.1052\n",
      "820/938 [=========================>....] - ETA: 0s - loss: 2.3086 - accuracy: 0.1050\n",
      "843/938 [=========================>....] - ETA: 0s - loss: 2.3085 - accuracy: 0.1047\n",
      "869/938 [==========================>...] - ETA: 0s - loss: 2.3089 - accuracy: 0.1044\n",
      "891/938 [===========================>..] - ETA: 0s - loss: 2.3088 - accuracy: 0.1046\n",
      "915/938 [============================>.] - ETA: 0s - loss: 2.3089 - accuracy: 0.1046\n",
      "927/938 [============================>.] - ETA: 0s - loss: 2.3089 - accuracy: 0.1047\n",
      "938/938 [==============================] - 4s 5ms/step - loss: 2.3089 - accuracy: 0.1049 - val_loss: 2.3081 - val_accuracy: 0.1135\n",
      "\u001b[36m(train_mnist pid=2641581)\u001b[0m Epoch 10/12\n",
      "  1/938 [..............................] - ETA: 4s - loss: 2.3182 - accuracy: 0.0938\n",
      " 25/938 [..............................] - ETA: 4s - loss: 2.3114 - accuracy: 0.1025\n",
      " 48/938 [>.............................] - ETA: 3s - loss: 2.3100 - accuracy: 0.1009\n",
      " 59/938 [>.............................] - ETA: 3s - loss: 2.3088 - accuracy: 0.1001\n",
      " 84/938 [=>............................] - ETA: 3s - loss: 2.3082 - accuracy: 0.1004\n",
      "108/938 [==>...........................] - ETA: 3s - loss: 2.3094 - accuracy: 0.1026\n",
      "132/938 [===>..........................] - ETA: 3s - loss: 2.3094 - accuracy: 0.1017\n",
      "155/938 [===>..........................] - ETA: 3s - loss: 2.3094 - accuracy: 0.1029\n",
      "180/938 [====>.........................] - ETA: 3s - loss: 2.3093 - accuracy: 0.1021\n",
      "203/938 [=====>........................] - ETA: 3s - loss: 2.3093 - accuracy: 0.1011\n",
      "215/938 [=====>........................] - ETA: 3s - loss: 2.3092 - accuracy: 0.1007\n",
      "238/938 [======>.......................] - ETA: 3s - loss: 2.3085 - accuracy: 0.1012\n",
      "262/938 [=======>......................] - ETA: 2s - loss: 2.3086 - accuracy: 0.1013\n",
      "285/938 [========>.....................] - ETA: 2s - loss: 2.3086 - accuracy: 0.1014\n",
      "308/938 [========>.....................] - ETA: 2s - loss: 2.3087 - accuracy: 0.1012\n",
      "331/938 [=========>....................] - ETA: 2s - loss: 2.3089 - accuracy: 0.1022\n",
      "356/938 [==========>...................] - ETA: 2s - loss: 2.3090 - accuracy: 0.1016\n",
      "367/938 [==========>...................] - ETA: 2s - loss: 2.3088 - accuracy: 0.1017\n",
      "392/938 [===========>..................] - ETA: 2s - loss: 2.3089 - accuracy: 0.1022\n",
      "416/938 [============>.................] - ETA: 2s - loss: 2.3089 - accuracy: 0.1028\n",
      "440/938 [=============>................] - ETA: 2s - loss: 2.3089 - accuracy: 0.1022\n",
      "464/938 [=============>................] - ETA: 2s - loss: 2.3093 - accuracy: 0.1021\n",
      "489/938 [==============>...............] - ETA: 1s - loss: 2.3090 - accuracy: 0.1027\n",
      "514/938 [===============>..............] - ETA: 1s - loss: 2.3091 - accuracy: 0.1027\n",
      "537/938 [================>.............] - ETA: 1s - loss: 2.3090 - accuracy: 0.1029\n",
      "573/938 [=================>............] - ETA: 1s - loss: 2.3089 - accuracy: 0.1027\n",
      "596/938 [==================>...........] - ETA: 1s - loss: 2.3089 - accuracy: 0.1026\n",
      "621/938 [==================>...........] - ETA: 1s - loss: 2.3089 - accuracy: 0.1021\n",
      "644/938 [===================>..........] - ETA: 1s - loss: 2.3090 - accuracy: 0.1025\n",
      "668/938 [====================>.........] - ETA: 1s - loss: 2.3089 - accuracy: 0.1028\n",
      "692/938 [=====================>........] - ETA: 1s - loss: 2.3091 - accuracy: 0.1025\n",
      "703/938 [=====================>........] - ETA: 1s - loss: 2.3091 - accuracy: 0.1023\n",
      "726/938 [======================>.......] - ETA: 0s - loss: 2.3093 - accuracy: 0.1018\n",
      "748/938 [======================>.......] - ETA: 0s - loss: 2.3093 - accuracy: 0.1019\n",
      "771/938 [=======================>......] - ETA: 0s - loss: 2.3092 - accuracy: 0.1020\n",
      "795/938 [========================>.....] - ETA: 0s - loss: 2.3092 - accuracy: 0.1021\n",
      "819/938 [=========================>....] - ETA: 0s - loss: 2.3091 - accuracy: 0.1022\n",
      "842/938 [=========================>....] - ETA: 0s - loss: 2.3093 - accuracy: 0.1022\n",
      "854/938 [==========================>...] - ETA: 0s - loss: 2.3093 - accuracy: 0.1023\n",
      "880/938 [===========================>..] - ETA: 0s - loss: 2.3093 - accuracy: 0.1020\n",
      "904/938 [===========================>..] - ETA: 0s - loss: 2.3091 - accuracy: 0.1020\n",
      "927/938 [============================>.] - ETA: 0s - loss: 2.3092 - accuracy: 0.1019\n",
      "938/938 [==============================] - 4s 5ms/step - loss: 2.3091 - accuracy: 0.1020 - val_loss: 2.3024 - val_accuracy: 0.1135\n",
      "\u001b[36m(train_mnist pid=2641581)\u001b[0m Epoch 11/12\n",
      " 12/938 [..............................] - ETA: 4s - loss: 2.3043 - accuracy: 0.1159\n",
      " 37/938 [>.............................] - ETA: 3s - loss: 2.3079 - accuracy: 0.1022\n",
      " 74/938 [=>............................] - ETA: 3s - loss: 2.3082 - accuracy: 0.1014\n",
      " 97/938 [==>...........................] - ETA: 3s - loss: 2.3084 - accuracy: 0.1055\n",
      "120/938 [==>...........................] - ETA: 3s - loss: 2.3077 - accuracy: 0.1046\n",
      "144/938 [===>..........................] - ETA: 3s - loss: 2.3084 - accuracy: 0.1029\n",
      "168/938 [====>.........................] - ETA: 3s - loss: 2.3078 - accuracy: 0.1049\n",
      "191/938 [=====>........................] - ETA: 3s - loss: 2.3076 - accuracy: 0.1067\n",
      "215/938 [=====>........................] - ETA: 3s - loss: 2.3079 - accuracy: 0.1059\n",
      "238/938 [======>.......................] - ETA: 3s - loss: 2.3078 - accuracy: 0.1050\n",
      "273/938 [=======>......................] - ETA: 2s - loss: 2.3079 - accuracy: 0.1056\n",
      "296/938 [========>.....................] - ETA: 2s - loss: 2.3079 - accuracy: 0.1053\n",
      "319/938 [=========>....................] - ETA: 2s - loss: 2.3077 - accuracy: 0.1064\n",
      "345/938 [==========>...................] - ETA: 2s - loss: 2.3079 - accuracy: 0.1063\n",
      "371/938 [==========>...................] - ETA: 2s - loss: 2.3086 - accuracy: 0.1054\n",
      "394/938 [===========>..................] - ETA: 2s - loss: 2.3085 - accuracy: 0.1054\n",
      "417/938 [============>.................] - ETA: 2s - loss: 2.3085 - accuracy: 0.1055\n",
      "429/938 [============>.................] - ETA: 2s - loss: 2.3085 - accuracy: 0.1054\n",
      "454/938 [=============>................] - ETA: 2s - loss: 2.3088 - accuracy: 0.1048\n",
      "478/938 [==============>...............] - ETA: 2s - loss: 2.3085 - accuracy: 0.1051\n",
      "502/938 [===============>..............] - ETA: 1s - loss: 2.3087 - accuracy: 0.1051\n",
      "527/938 [===============>..............] - ETA: 1s - loss: 2.3085 - accuracy: 0.1048\n",
      "553/938 [================>.............] - ETA: 1s - loss: 2.3086 - accuracy: 0.1044\n",
      "577/938 [=================>............] - ETA: 1s - loss: 2.3089 - accuracy: 0.1046\n",
      "602/938 [==================>...........] - ETA: 1s - loss: 2.3087 - accuracy: 0.1039\n",
      "626/938 [===================>..........] - ETA: 1s - loss: 2.3084 - accuracy: 0.1043\n",
      "637/938 [===================>..........] - ETA: 1s - loss: 2.3085 - accuracy: 0.1043\n",
      "661/938 [====================>.........] - ETA: 1s - loss: 2.3085 - accuracy: 0.1042\n",
      "683/938 [====================>.........] - ETA: 1s - loss: 2.3085 - accuracy: 0.1044\n",
      "707/938 [=====================>........] - ETA: 1s - loss: 2.3086 - accuracy: 0.1039\n",
      "733/938 [======================>.......] - ETA: 0s - loss: 2.3086 - accuracy: 0.1042\n",
      "756/938 [=======================>......] - ETA: 0s - loss: 2.3086 - accuracy: 0.1044\n",
      "779/938 [=======================>......] - ETA: 0s - loss: 2.3086 - accuracy: 0.1051\n",
      "801/938 [========================>.....] - ETA: 0s - loss: 2.3086 - accuracy: 0.1049\n",
      "812/938 [========================>.....] - ETA: 0s - loss: 2.3087 - accuracy: 0.1046\n",
      "835/938 [=========================>....] - ETA: 0s - loss: 2.3087 - accuracy: 0.1046\n",
      "859/938 [==========================>...] - ETA: 0s - loss: 2.3088 - accuracy: 0.1042\n",
      "881/938 [===========================>..] - ETA: 0s - loss: 2.3088 - accuracy: 0.1044\n",
      "904/938 [===========================>..] - ETA: 0s - loss: 2.3087 - accuracy: 0.1044\n",
      "927/938 [============================>.] - ETA: 0s - loss: 2.3087 - accuracy: 0.1046\n",
      "938/938 [==============================] - ETA: 0s - loss: 2.3089 - accuracy: 0.1042\n",
      "938/938 [==============================] - 4s 5ms/step - loss: 2.3089 - accuracy: 0.1042 - val_loss: 2.3065 - val_accuracy: 0.1032\n",
      "\u001b[36m(train_mnist pid=2641581)\u001b[0m Epoch 12/12\n",
      " 13/938 [..............................] - ETA: 4s - loss: 2.3132 - accuracy: 0.0950\n",
      " 25/938 [..............................] - ETA: 3s - loss: 2.3141 - accuracy: 0.0931\n",
      " 49/938 [>.............................] - ETA: 3s - loss: 2.3112 - accuracy: 0.1059\n",
      " 71/938 [=>............................] - ETA: 3s - loss: 2.3126 - accuracy: 0.1056\n",
      " 95/938 [==>...........................] - ETA: 3s - loss: 2.3114 - accuracy: 0.1072\n",
      "117/938 [==>...........................] - ETA: 3s - loss: 2.3107 - accuracy: 0.1066\n",
      "140/938 [===>..........................] - ETA: 3s - loss: 2.3102 - accuracy: 0.1065\n",
      "165/938 [====>.........................] - ETA: 3s - loss: 2.3101 - accuracy: 0.1072\n",
      "177/938 [====>.........................] - ETA: 3s - loss: 2.3095 - accuracy: 0.1084\n",
      "201/938 [=====>........................] - ETA: 3s - loss: 2.3100 - accuracy: 0.1073\n",
      "225/938 [======>.......................] - ETA: 3s - loss: 2.3099 - accuracy: 0.1072\n",
      "247/938 [======>.......................] - ETA: 3s - loss: 2.3101 - accuracy: 0.1077\n",
      "271/938 [=======>......................] - ETA: 2s - loss: 2.3096 - accuracy: 0.1082\n",
      "295/938 [========>.....................] - ETA: 2s - loss: 2.3099 - accuracy: 0.1064\n",
      "320/938 [=========>....................] - ETA: 2s - loss: 2.3097 - accuracy: 0.1069\n",
      "331/938 [=========>....................] - ETA: 2s - loss: 2.3095 - accuracy: 0.1074\n",
      "355/938 [==========>...................] - ETA: 2s - loss: 2.3094 - accuracy: 0.1079\n",
      "379/938 [===========>..................] - ETA: 2s - loss: 2.3093 - accuracy: 0.1078\n",
      "403/938 [===========>..................] - ETA: 2s - loss: 2.3091 - accuracy: 0.1076\n",
      "426/938 [============>.................] - ETA: 2s - loss: 2.3092 - accuracy: 0.1072\n",
      "450/938 [=============>................] - ETA: 2s - loss: 2.3093 - accuracy: 0.1068\n",
      "474/938 [==============>...............] - ETA: 2s - loss: 2.3092 - accuracy: 0.1065\n",
      "486/938 [==============>...............] - ETA: 1s - loss: 2.3091 - accuracy: 0.1070\n",
      "510/938 [===============>..............] - ETA: 1s - loss: 2.3092 - accuracy: 0.1064\n",
      "535/938 [================>.............] - ETA: 1s - loss: 2.3092 - accuracy: 0.1065\n",
      "559/938 [================>.............] - ETA: 1s - loss: 2.3093 - accuracy: 0.1061\n",
      "584/938 [=================>............] - ETA: 1s - loss: 2.3093 - accuracy: 0.1067\n",
      "607/938 [==================>...........] - ETA: 1s - loss: 2.3092 - accuracy: 0.1073\n",
      "631/938 [===================>..........] - ETA: 1s - loss: 2.3094 - accuracy: 0.1067\n",
      "654/938 [===================>..........] - ETA: 1s - loss: 2.3092 - accuracy: 0.1072\n",
      "666/938 [====================>.........] - ETA: 1s - loss: 2.3092 - accuracy: 0.1072\n",
      "690/938 [=====================>........] - ETA: 1s - loss: 2.3093 - accuracy: 0.1067\n",
      "713/938 [=====================>........] - ETA: 0s - loss: 2.3095 - accuracy: 0.1062\n",
      "737/938 [======================>.......] - ETA: 0s - loss: 2.3095 - accuracy: 0.1059\n",
      "761/938 [=======================>......] - ETA: 0s - loss: 2.3094 - accuracy: 0.1058\n",
      "786/938 [========================>.....] - ETA: 0s - loss: 2.3093 - accuracy: 0.1062\n",
      "809/938 [========================>.....] - ETA: 0s - loss: 2.3093 - accuracy: 0.1060\n",
      "820/938 [=========================>....] - ETA: 0s - loss: 2.3093 - accuracy: 0.1062\n",
      "843/938 [=========================>....] - ETA: 0s - loss: 2.3091 - accuracy: 0.1061\n",
      "869/938 [==========================>...] - ETA: 0s - loss: 2.3091 - accuracy: 0.1058\n",
      "892/938 [===========================>..] - ETA: 0s - loss: 2.3091 - accuracy: 0.1055\n",
      "914/938 [============================>.] - ETA: 0s - loss: 2.3091 - accuracy: 0.1054\n",
      "938/938 [==============================] - ETA: 0s - loss: 2.3092 - accuracy: 0.1052\n",
      "938/938 [==============================] - 4s 5ms/step - loss: 2.3092 - accuracy: 0.1052 - val_loss: 2.3065 - val_accuracy: 0.1032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=2645324)\u001b[0m 2023-12-05 09:50:53.456023: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=2645324)\u001b[0m 2023-12-05 09:50:53.456054: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=2645324)\u001b[0m 2023-12-05 09:50:53.457112: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=2645324)\u001b[0m 2023-12-05 09:50:53.462973: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=2645324)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=2645324)\u001b[0m 2023-12-05 09:50:53.415726: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=2645324)\u001b[0m 2023-12-05 09:50:54.171755: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=2645324)\u001b[0m 2023-12-05 09:50:55.483593: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_mnist pid=2645324)\u001b[0m Epoch 1/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_mnist pid=2645324)\u001b[0m 2023-12-05 09:50:57.172051: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=2645324)\u001b[0m 2023-12-05 09:50:58.147996: I external/local_xla/xla/service/service.cc:168] XLA service 0x1499f830bc80 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=2645324)\u001b[0m 2023-12-05 09:50:58.148045: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=2645324)\u001b[0m 2023-12-05 09:50:58.157088: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=2645324)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=2645324)\u001b[0m I0000 00:00:1701787858.281410 2645459 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1/469 [..............................] - ETA: 17:50 - loss: 2.2962 - accuracy: 0.1406\n",
      " 24/469 [>.............................] - ETA: 1s - loss: 4.3634 - accuracy: 0.1175 \n",
      " 49/469 [==>...........................] - ETA: 1s - loss: 3.3118 - accuracy: 0.1134\n",
      " 75/469 [===>..........................] - ETA: 1s - loss: 2.9613 - accuracy: 0.1124\n",
      " 88/469 [====>.........................] - ETA: 1s - loss: 2.8648 - accuracy: 0.1101\n",
      "114/469 [======>.......................] - ETA: 1s - loss: 2.7367 - accuracy: 0.1109\n",
      "140/469 [=======>......................] - ETA: 1s - loss: 2.6561 - accuracy: 0.1096\n",
      "165/469 [=========>....................] - ETA: 1s - loss: 2.6030 - accuracy: 0.1082\n",
      "190/469 [===========>..................] - ETA: 1s - loss: 2.5633 - accuracy: 0.1093\n",
      "214/469 [============>.................] - ETA: 1s - loss: 2.5343 - accuracy: 0.1098\n",
      "240/469 [==============>...............] - ETA: 0s - loss: 2.5095 - accuracy: 0.1097\n",
      "277/469 [================>.............] - ETA: 0s - loss: 2.4822 - accuracy: 0.1097\n",
      "302/469 [==================>...........] - ETA: 0s - loss: 2.4672 - accuracy: 0.1098\n",
      "328/469 [===================>..........] - ETA: 0s - loss: 2.4543 - accuracy: 0.1091\n",
      "353/469 [=====================>........] - ETA: 0s - loss: 2.4436 - accuracy: 0.1098\n",
      "380/469 [=======================>......] - ETA: 0s - loss: 2.4338 - accuracy: 0.1095\n",
      "404/469 [========================>.....] - ETA: 0s - loss: 2.4261 - accuracy: 0.1094\n",
      "417/469 [=========================>....] - ETA: 0s - loss: 2.4223 - accuracy: 0.1091\n",
      "442/469 [===========================>..] - ETA: 0s - loss: 2.4155 - accuracy: 0.1090\n",
      "467/469 [============================>.] - ETA: 0s - loss: 2.4095 - accuracy: 0.1087\n",
      "469/469 [==============================] - ETA: 0s - loss: 2.4091 - accuracy: 0.1085\n",
      "469/469 [==============================] - 5s 5ms/step - loss: 2.4091 - accuracy: 0.1085 - val_loss: 2.3056 - val_accuracy: 0.1028\n",
      "\u001b[36m(train_mnist pid=2645324)\u001b[0m Epoch 2/12\n",
      " 15/469 [..............................] - ETA: 1s - loss: 2.3090 - accuracy: 0.1036\n",
      " 42/469 [=>............................] - ETA: 1s - loss: 2.3056 - accuracy: 0.1031\n",
      " 68/469 [===>..........................] - ETA: 1s - loss: 2.3051 - accuracy: 0.1043\n",
      " 94/469 [=====>........................] - ETA: 1s - loss: 2.3036 - accuracy: 0.1098\n",
      "119/469 [======>.......................] - ETA: 1s - loss: 2.3033 - accuracy: 0.1113\n",
      "145/469 [========>.....................] - ETA: 1s - loss: 2.3036 - accuracy: 0.1102\n",
      "183/469 [==========>...................] - ETA: 1s - loss: 2.3035 - accuracy: 0.1078\n",
      "209/469 [============>.................] - ETA: 1s - loss: 2.3033 - accuracy: 0.1088\n",
      "236/469 [==============>...............] - ETA: 0s - loss: 2.3036 - accuracy: 0.1086\n",
      "262/469 [===============>..............] - ETA: 0s - loss: 2.3035 - accuracy: 0.1084\n",
      "288/469 [=================>............] - ETA: 0s - loss: 2.3036 - accuracy: 0.1097\n",
      "313/469 [===================>..........] - ETA: 0s - loss: 2.3036 - accuracy: 0.1095\n",
      "339/469 [====================>.........] - ETA: 0s - loss: 2.3038 - accuracy: 0.1089\n",
      "363/469 [======================>.......] - ETA: 0s - loss: 2.3039 - accuracy: 0.1086\n",
      "377/469 [=======================>......] - ETA: 0s - loss: 2.3040 - accuracy: 0.1080\n",
      "402/469 [========================>.....] - ETA: 0s - loss: 2.3041 - accuracy: 0.1076\n",
      "426/469 [==========================>...] - ETA: 0s - loss: 2.3040 - accuracy: 0.1083\n",
      "451/469 [===========================>..] - ETA: 0s - loss: 2.3041 - accuracy: 0.1073\n",
      "463/469 [============================>.] - ETA: 0s - loss: 2.3041 - accuracy: 0.1072\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 2.3041 - accuracy: 0.1071 - val_loss: 2.3045 - val_accuracy: 0.0980\n",
      "\u001b[36m(train_mnist pid=2645324)\u001b[0m Epoch 3/12\n",
      " 14/469 [..............................] - ETA: 1s - loss: 2.3068 - accuracy: 0.0887\n",
      " 38/469 [=>............................] - ETA: 1s - loss: 2.3024 - accuracy: 0.1053\n",
      " 50/469 [==>...........................] - ETA: 1s - loss: 2.3030 - accuracy: 0.1083\n",
      " 74/469 [===>..........................] - ETA: 1s - loss: 2.3036 - accuracy: 0.1096\n",
      " 98/469 [=====>........................] - ETA: 1s - loss: 2.3040 - accuracy: 0.1079\n",
      "123/469 [======>.......................] - ETA: 1s - loss: 2.3042 - accuracy: 0.1084\n",
      "147/469 [========>.....................] - ETA: 1s - loss: 2.3041 - accuracy: 0.1082\n",
      "172/469 [==========>...................] - ETA: 1s - loss: 2.3041 - accuracy: 0.1097\n",
      "199/469 [===========>..................] - ETA: 1s - loss: 2.3042 - accuracy: 0.1100\n",
      "212/469 [============>.................] - ETA: 1s - loss: 2.3044 - accuracy: 0.1099\n",
      "237/469 [==============>...............] - ETA: 0s - loss: 2.3042 - accuracy: 0.1102\n",
      "262/469 [===============>..............] - ETA: 0s - loss: 2.3043 - accuracy: 0.1099\n",
      "286/469 [=================>............] - ETA: 0s - loss: 2.3041 - accuracy: 0.1097\n",
      "310/469 [==================>...........] - ETA: 0s - loss: 2.3041 - accuracy: 0.1093\n",
      "335/469 [====================>.........] - ETA: 0s - loss: 2.3041 - accuracy: 0.1094\n",
      "374/469 [======================>.......] - ETA: 0s - loss: 2.3040 - accuracy: 0.1096\n",
      "399/469 [========================>.....] - ETA: 0s - loss: 2.3040 - accuracy: 0.1092\n",
      "424/469 [==========================>...] - ETA: 0s - loss: 2.3040 - accuracy: 0.1089\n",
      "448/469 [===========================>..] - ETA: 0s - loss: 2.3039 - accuracy: 0.1086\n",
      "460/469 [============================>.] - ETA: 0s - loss: 2.3039 - accuracy: 0.1084\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 2.3041 - accuracy: 0.1085 - val_loss: 2.3059 - val_accuracy: 0.0982\n",
      "\u001b[36m(train_mnist pid=2645324)\u001b[0m Epoch 4/12\n",
      " 14/469 [..............................] - ETA: 1s - loss: 2.3049 - accuracy: 0.1077\n",
      " 40/469 [=>............................] - ETA: 1s - loss: 2.3047 - accuracy: 0.1027\n",
      " 66/469 [===>..........................] - ETA: 1s - loss: 2.3039 - accuracy: 0.1044\n",
      " 90/469 [====>.........................] - ETA: 1s - loss: 2.3037 - accuracy: 0.1076\n",
      "102/469 [=====>........................] - ETA: 1s - loss: 2.3038 - accuracy: 0.1061\n",
      "127/469 [=======>......................] - ETA: 1s - loss: 2.3036 - accuracy: 0.1075\n",
      "151/469 [========>.....................] - ETA: 1s - loss: 2.3038 - accuracy: 0.1064\n",
      "175/469 [==========>...................] - ETA: 1s - loss: 2.3038 - accuracy: 0.1068\n",
      "200/469 [===========>..................] - ETA: 1s - loss: 2.3037 - accuracy: 0.1076\n",
      "225/469 [=============>................] - ETA: 1s - loss: 2.3037 - accuracy: 0.1071\n",
      "250/469 [==============>...............] - ETA: 0s - loss: 2.3037 - accuracy: 0.1066\n",
      "286/469 [=================>............] - ETA: 0s - loss: 2.3038 - accuracy: 0.1068\n",
      "311/469 [==================>...........] - ETA: 0s - loss: 2.3037 - accuracy: 0.1078\n",
      "337/469 [====================>.........] - ETA: 0s - loss: 2.3039 - accuracy: 0.1071\n",
      "362/469 [======================>.......] - ETA: 0s - loss: 2.3039 - accuracy: 0.1070\n",
      "386/469 [=======================>......] - ETA: 0s - loss: 2.3038 - accuracy: 0.1072\n",
      "411/469 [=========================>....] - ETA: 0s - loss: 2.3038 - accuracy: 0.1072\n",
      "435/469 [==========================>...] - ETA: 0s - loss: 2.3037 - accuracy: 0.1077\n",
      "448/469 [===========================>..] - ETA: 0s - loss: 2.3038 - accuracy: 0.1074\n",
      "461/469 [============================>.] - ETA: 0s - loss: 2.3038 - accuracy: 0.1071\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 2.3038 - accuracy: 0.1070 - val_loss: 2.3046 - val_accuracy: 0.1135\n",
      "\u001b[36m(train_mnist pid=2645324)\u001b[0m Epoch 5/12\n",
      " 13/469 [..............................] - ETA: 1s - loss: 2.3042 - accuracy: 0.1136\n",
      " 37/469 [=>............................] - ETA: 1s - loss: 2.3039 - accuracy: 0.1064\n",
      " 49/469 [==>...........................] - ETA: 1s - loss: 2.3055 - accuracy: 0.1003\n",
      " 76/469 [===>..........................] - ETA: 1s - loss: 2.3048 - accuracy: 0.1041\n",
      "100/469 [=====>........................] - ETA: 1s - loss: 2.3047 - accuracy: 0.1050\n",
      "125/469 [======>.......................] - ETA: 1s - loss: 2.3046 - accuracy: 0.1052\n",
      "151/469 [========>.....................] - ETA: 1s - loss: 2.3044 - accuracy: 0.1052\n",
      "175/469 [==========>...................] - ETA: 1s - loss: 2.3047 - accuracy: 0.1040\n",
      "187/469 [==========>...................] - ETA: 1s - loss: 2.3045 - accuracy: 0.1048\n",
      "214/469 [============>.................] - ETA: 1s - loss: 2.3045 - accuracy: 0.1047\n",
      "238/469 [==============>...............] - ETA: 0s - loss: 2.3045 - accuracy: 0.1041\n",
      "263/469 [===============>..............] - ETA: 0s - loss: 2.3042 - accuracy: 0.1060\n",
      "289/469 [=================>............] - ETA: 0s - loss: 2.3043 - accuracy: 0.1065\n",
      "314/469 [===================>..........] - ETA: 0s - loss: 2.3043 - accuracy: 0.1062\n",
      "326/469 [===================>..........] - ETA: 0s - loss: 2.3042 - accuracy: 0.1067\n",
      "350/469 [=====================>........] - ETA: 0s - loss: 2.3044 - accuracy: 0.1059\n",
      "376/469 [=======================>......] - ETA: 0s - loss: 2.3044 - accuracy: 0.1058\n",
      "401/469 [========================>.....] - ETA: 0s - loss: 2.3043 - accuracy: 0.1059\n",
      "426/469 [==========================>...] - ETA: 0s - loss: 2.3043 - accuracy: 0.1068\n",
      "450/469 [===========================>..] - ETA: 0s - loss: 2.3043 - accuracy: 0.1066\n",
      "462/469 [============================>.] - ETA: 0s - loss: 2.3043 - accuracy: 0.1066\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 2.3043 - accuracy: 0.1068 - val_loss: 2.3027 - val_accuracy: 0.1135\n",
      "\u001b[36m(train_mnist pid=2645324)\u001b[0m Epoch 6/12\n",
      "  1/469 [..............................] - ETA: 1s - loss: 2.2871 - accuracy: 0.1484\n",
      " 26/469 [>.............................] - ETA: 1s - loss: 2.3025 - accuracy: 0.1169\n",
      " 50/469 [==>...........................] - ETA: 1s - loss: 2.3018 - accuracy: 0.1128\n",
      " 74/469 [===>..........................] - ETA: 1s - loss: 2.3031 - accuracy: 0.1085\n",
      " 98/469 [=====>........................] - ETA: 1s - loss: 2.3031 - accuracy: 0.1069\n",
      "135/469 [=======>......................] - ETA: 1s - loss: 2.3031 - accuracy: 0.1090\n",
      "160/469 [=========>....................] - ETA: 1s - loss: 2.3034 - accuracy: 0.1080\n",
      "185/469 [==========>...................] - ETA: 1s - loss: 2.3037 - accuracy: 0.1063\n",
      "211/469 [============>.................] - ETA: 1s - loss: 2.3034 - accuracy: 0.1079\n",
      "235/469 [==============>...............] - ETA: 0s - loss: 2.3033 - accuracy: 0.1086\n",
      "261/469 [===============>..............] - ETA: 0s - loss: 2.3034 - accuracy: 0.1078\n",
      "299/469 [==================>...........] - ETA: 0s - loss: 2.3036 - accuracy: 0.1074\n",
      "324/469 [===================>..........] - ETA: 0s - loss: 2.3038 - accuracy: 0.1071\n",
      "349/469 [=====================>........] - ETA: 0s - loss: 2.3039 - accuracy: 0.1072\n",
      "374/469 [======================>.......] - ETA: 0s - loss: 2.3040 - accuracy: 0.1066\n",
      "400/469 [========================>.....] - ETA: 0s - loss: 2.3041 - accuracy: 0.1064\n",
      "425/469 [==========================>...] - ETA: 0s - loss: 2.3040 - accuracy: 0.1070\n",
      "449/469 [===========================>..] - ETA: 0s - loss: 2.3040 - accuracy: 0.1069\n",
      "461/469 [============================>.] - ETA: 0s - loss: 2.3041 - accuracy: 0.1066\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 2.3041 - accuracy: 0.1064 - val_loss: 2.3040 - val_accuracy: 0.1028\n",
      "\u001b[36m(train_mnist pid=2645324)\u001b[0m Epoch 7/12\n",
      "  1/469 [..............................] - ETA: 2s - loss: 2.2983 - accuracy: 0.1016\n",
      " 27/469 [>.............................] - ETA: 1s - loss: 2.3020 - accuracy: 0.1131\n",
      " 51/469 [==>...........................] - ETA: 1s - loss: 2.3031 - accuracy: 0.1097\n",
      " 75/469 [===>..........................] - ETA: 1s - loss: 2.3035 - accuracy: 0.1071\n",
      "101/469 [=====>........................] - ETA: 1s - loss: 2.3038 - accuracy: 0.1054\n",
      "126/469 [=======>......................] - ETA: 1s - loss: 2.3037 - accuracy: 0.1046\n",
      "152/469 [========>.....................] - ETA: 1s - loss: 2.3043 - accuracy: 0.1038\n",
      "164/469 [=========>....................] - ETA: 1s - loss: 2.3043 - accuracy: 0.1031\n",
      "190/469 [===========>..................] - ETA: 1s - loss: 2.3045 - accuracy: 0.1009\n",
      "214/469 [============>.................] - ETA: 1s - loss: 2.3045 - accuracy: 0.1016\n",
      "238/469 [==============>...............] - ETA: 0s - loss: 2.3045 - accuracy: 0.1010\n",
      "263/469 [===============>..............] - ETA: 0s - loss: 2.3043 - accuracy: 0.1024\n",
      "289/469 [=================>............] - ETA: 0s - loss: 2.3042 - accuracy: 0.1031\n",
      "302/469 [==================>...........] - ETA: 0s - loss: 2.3041 - accuracy: 0.1037\n",
      "328/469 [===================>..........] - ETA: 0s - loss: 2.3041 - accuracy: 0.1037\n",
      "353/469 [=====================>........] - ETA: 0s - loss: 2.3042 - accuracy: 0.1034\n",
      "380/469 [=======================>......] - ETA: 0s - loss: 2.3042 - accuracy: 0.1038\n",
      "405/469 [========================>.....] - ETA: 0s - loss: 2.3041 - accuracy: 0.1039\n",
      "431/469 [==========================>...] - ETA: 0s - loss: 2.3042 - accuracy: 0.1034\n",
      "444/469 [===========================>..] - ETA: 0s - loss: 2.3042 - accuracy: 0.1031\n",
      "469/469 [==============================] - ETA: 0s - loss: 2.3042 - accuracy: 0.1039\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 2.3042 - accuracy: 0.1039 - val_loss: 2.3025 - val_accuracy: 0.1135\n",
      "\u001b[36m(train_mnist pid=2645324)\u001b[0m Epoch 8/12\n",
      "  1/469 [..............................] - ETA: 2s - loss: 2.2994 - accuracy: 0.1328\n",
      " 39/469 [=>............................] - ETA: 1s - loss: 2.3055 - accuracy: 0.1046\n",
      " 64/469 [===>..........................] - ETA: 1s - loss: 2.3047 - accuracy: 0.1100\n",
      " 90/469 [====>.........................] - ETA: 1s - loss: 2.3039 - accuracy: 0.1114\n",
      "116/469 [======>.......................] - ETA: 1s - loss: 2.3041 - accuracy: 0.1114\n",
      "142/469 [========>.....................] - ETA: 1s - loss: 2.3037 - accuracy: 0.1110\n",
      "166/469 [=========>....................] - ETA: 1s - loss: 2.3033 - accuracy: 0.1110\n",
      "190/469 [===========>..................] - ETA: 1s - loss: 2.3037 - accuracy: 0.1107\n",
      "202/469 [===========>..................] - ETA: 1s - loss: 2.3037 - accuracy: 0.1115\n",
      "229/469 [=============>................] - ETA: 0s - loss: 2.3037 - accuracy: 0.1117\n",
      "254/469 [===============>..............] - ETA: 0s - loss: 2.3039 - accuracy: 0.1103\n",
      "279/469 [================>.............] - ETA: 0s - loss: 2.3039 - accuracy: 0.1105\n",
      "303/469 [==================>...........] - ETA: 0s - loss: 2.3041 - accuracy: 0.1108\n",
      "329/469 [====================>.........] - ETA: 0s - loss: 2.3040 - accuracy: 0.1108\n",
      "353/469 [=====================>........] - ETA: 0s - loss: 2.3040 - accuracy: 0.1107\n",
      "366/469 [======================>.......] - ETA: 0s - loss: 2.3040 - accuracy: 0.1104\n",
      "391/469 [========================>.....] - ETA: 0s - loss: 2.3041 - accuracy: 0.1099\n",
      "416/469 [=========================>....] - ETA: 0s - loss: 2.3042 - accuracy: 0.1096\n",
      "442/469 [===========================>..] - ETA: 0s - loss: 2.3044 - accuracy: 0.1091\n",
      "467/469 [============================>.] - ETA: 0s - loss: 2.3044 - accuracy: 0.1087\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 2.3044 - accuracy: 0.1087 - val_loss: 2.3067 - val_accuracy: 0.1135\n",
      "\u001b[36m(train_mnist pid=2645324)\u001b[0m Epoch 9/12\n",
      " 14/469 [..............................] - ETA: 1s - loss: 2.3069 - accuracy: 0.0943\n",
      " 39/469 [=>............................] - ETA: 1s - loss: 2.3045 - accuracy: 0.1088\n",
      " 64/469 [===>..........................] - ETA: 1s - loss: 2.3044 - accuracy: 0.1049\n",
      " 90/469 [====>.........................] - ETA: 1s - loss: 2.3052 - accuracy: 0.1033\n",
      "117/469 [======>.......................] - ETA: 1s - loss: 2.3046 - accuracy: 0.1042\n",
      "143/469 [========>.....................] - ETA: 1s - loss: 2.3047 - accuracy: 0.1045\n",
      "168/469 [=========>....................] - ETA: 1s - loss: 2.3045 - accuracy: 0.1042\n",
      "181/469 [==========>...................] - ETA: 1s - loss: 2.3042 - accuracy: 0.1053\n",
      "206/469 [============>.................] - ETA: 1s - loss: 2.3039 - accuracy: 0.1060\n",
      "230/469 [=============>................] - ETA: 0s - loss: 2.3037 - accuracy: 0.1071\n",
      "254/469 [===============>..............] - ETA: 0s - loss: 2.3036 - accuracy: 0.1066\n",
      "280/469 [================>.............] - ETA: 0s - loss: 2.3038 - accuracy: 0.1061\n",
      "304/469 [==================>...........] - ETA: 0s - loss: 2.3039 - accuracy: 0.1061\n",
      "329/469 [====================>.........] - ETA: 0s - loss: 2.3038 - accuracy: 0.1063\n",
      "366/469 [======================>.......] - ETA: 0s - loss: 2.3037 - accuracy: 0.1066\n",
      "391/469 [========================>.....] - ETA: 0s - loss: 2.3040 - accuracy: 0.1057\n",
      "415/469 [=========================>....] - ETA: 0s - loss: 2.3040 - accuracy: 0.1055\n",
      "441/469 [===========================>..] - ETA: 0s - loss: 2.3040 - accuracy: 0.1055\n",
      "466/469 [============================>.] - ETA: 0s - loss: 2.3041 - accuracy: 0.1060\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 2.3041 - accuracy: 0.1062 - val_loss: 2.3024 - val_accuracy: 0.1135\n",
      "\u001b[36m(train_mnist pid=2645324)\u001b[0m Epoch 10/12\n",
      " 15/469 [..............................] - ETA: 1s - loss: 2.3034 - accuracy: 0.1161\n",
      " 40/469 [=>............................] - ETA: 1s - loss: 2.3040 - accuracy: 0.1102\n",
      " 64/469 [===>..........................] - ETA: 1s - loss: 2.3038 - accuracy: 0.1071\n",
      " 89/469 [====>.........................] - ETA: 1s - loss: 2.3043 - accuracy: 0.1067\n",
      "115/469 [======>.......................] - ETA: 1s - loss: 2.3041 - accuracy: 0.1066\n",
      "140/469 [=======>......................] - ETA: 1s - loss: 2.3041 - accuracy: 0.1057\n",
      "177/469 [==========>...................] - ETA: 1s - loss: 2.3041 - accuracy: 0.1040\n",
      "202/469 [===========>..................] - ETA: 1s - loss: 2.3039 - accuracy: 0.1045\n",
      "228/469 [=============>................] - ETA: 0s - loss: 2.3037 - accuracy: 0.1051\n",
      "254/469 [===============>..............] - ETA: 0s - loss: 2.3036 - accuracy: 0.1049\n",
      "278/469 [================>.............] - ETA: 0s - loss: 2.3037 - accuracy: 0.1050\n",
      "304/469 [==================>...........] - ETA: 0s - loss: 2.3038 - accuracy: 0.1059\n",
      "329/469 [====================>.........] - ETA: 0s - loss: 2.3039 - accuracy: 0.1067\n",
      "341/469 [====================>.........] - ETA: 0s - loss: 2.3039 - accuracy: 0.1067\n",
      "365/469 [======================>.......] - ETA: 0s - loss: 2.3039 - accuracy: 0.1077\n",
      "390/469 [=======================>......] - ETA: 0s - loss: 2.3039 - accuracy: 0.1074\n",
      "415/469 [=========================>....] - ETA: 0s - loss: 2.3041 - accuracy: 0.1073\n",
      "439/469 [===========================>..] - ETA: 0s - loss: 2.3041 - accuracy: 0.1072\n",
      "464/469 [============================>.] - ETA: 0s - loss: 2.3041 - accuracy: 0.1069\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 2.3042 - accuracy: 0.1066 - val_loss: 2.3034 - val_accuracy: 0.1135\n",
      "\u001b[36m(train_mnist pid=2645324)\u001b[0m Epoch 11/12\n",
      " 13/469 [..............................] - ETA: 1s - loss: 2.3050 - accuracy: 0.1100\n",
      " 38/469 [=>............................] - ETA: 1s - loss: 2.3053 - accuracy: 0.1046\n",
      " 62/469 [==>...........................] - ETA: 1s - loss: 2.3049 - accuracy: 0.1008\n",
      " 88/469 [====>.........................] - ETA: 1s - loss: 2.3046 - accuracy: 0.1023\n",
      "114/469 [======>.......................] - ETA: 1s - loss: 2.3045 - accuracy: 0.1031\n",
      "127/469 [=======>......................] - ETA: 1s - loss: 2.3042 - accuracy: 0.1039\n",
      "153/469 [========>.....................] - ETA: 1s - loss: 2.3047 - accuracy: 0.1009\n",
      "177/469 [==========>...................] - ETA: 1s - loss: 2.3048 - accuracy: 0.1012\n",
      "204/469 [============>.................] - ETA: 1s - loss: 2.3049 - accuracy: 0.1011\n",
      "229/469 [=============>................] - ETA: 0s - loss: 2.3051 - accuracy: 0.1000\n",
      "255/469 [===============>..............] - ETA: 0s - loss: 2.3049 - accuracy: 0.1017\n",
      "281/469 [================>.............] - ETA: 0s - loss: 2.3048 - accuracy: 0.1020\n",
      "305/469 [==================>...........] - ETA: 0s - loss: 2.3048 - accuracy: 0.1025\n",
      "317/469 [===================>..........] - ETA: 0s - loss: 2.3047 - accuracy: 0.1030\n",
      "341/469 [====================>.........] - ETA: 0s - loss: 2.3048 - accuracy: 0.1034\n",
      "366/469 [======================>.......] - ETA: 0s - loss: 2.3046 - accuracy: 0.1044\n",
      "391/469 [========================>.....] - ETA: 0s - loss: 2.3046 - accuracy: 0.1049\n",
      "417/469 [=========================>....] - ETA: 0s - loss: 2.3045 - accuracy: 0.1063\n",
      "442/469 [===========================>..] - ETA: 0s - loss: 2.3044 - accuracy: 0.1063\n",
      "466/469 [============================>.] - ETA: 0s - loss: 2.3044 - accuracy: 0.1060\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 2.3044 - accuracy: 0.1058 - val_loss: 2.3032 - val_accuracy: 0.0974\n",
      "\u001b[36m(train_mnist pid=2645324)\u001b[0m Epoch 12/12\n",
      " 13/469 [..............................] - ETA: 1s - loss: 2.3025 - accuracy: 0.1208\n",
      " 37/469 [=>............................] - ETA: 1s - loss: 2.3029 - accuracy: 0.1149\n",
      " 61/469 [==>...........................] - ETA: 1s - loss: 2.3030 - accuracy: 0.1110\n",
      " 86/469 [====>.........................] - ETA: 1s - loss: 2.3037 - accuracy: 0.1096\n",
      " 98/469 [=====>........................] - ETA: 1s - loss: 2.3046 - accuracy: 0.1075\n",
      "124/469 [======>.......................] - ETA: 1s - loss: 2.3050 - accuracy: 0.1095\n",
      "149/469 [========>.....................] - ETA: 1s - loss: 2.3043 - accuracy: 0.1106\n",
      "174/469 [==========>...................] - ETA: 1s - loss: 2.3041 - accuracy: 0.1100\n",
      "200/469 [===========>..................] - ETA: 1s - loss: 2.3041 - accuracy: 0.1093\n",
      "223/469 [=============>................] - ETA: 1s - loss: 2.3040 - accuracy: 0.1097\n",
      "248/469 [==============>...............] - ETA: 0s - loss: 2.3037 - accuracy: 0.1098\n",
      "260/469 [===============>..............] - ETA: 0s - loss: 2.3038 - accuracy: 0.1098\n",
      "286/469 [=================>............] - ETA: 0s - loss: 2.3039 - accuracy: 0.1089\n",
      "310/469 [==================>...........] - ETA: 0s - loss: 2.3037 - accuracy: 0.1093\n",
      "334/469 [====================>.........] - ETA: 0s - loss: 2.3038 - accuracy: 0.1094\n",
      "358/469 [=====================>........] - ETA: 0s - loss: 2.3038 - accuracy: 0.1092\n",
      "382/469 [=======================>......] - ETA: 0s - loss: 2.3039 - accuracy: 0.1084\n",
      "395/469 [========================>.....] - ETA: 0s - loss: 2.3040 - accuracy: 0.1086\n",
      "420/469 [=========================>....] - ETA: 0s - loss: 2.3041 - accuracy: 0.1083\n",
      "444/469 [===========================>..] - ETA: 0s - loss: 2.3041 - accuracy: 0.1080\n",
      "468/469 [============================>.] - ETA: 0s - loss: 2.3040 - accuracy: 0.1081\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 2.3040 - accuracy: 0.1081 - val_loss: 2.3058 - val_accuracy: 0.1135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-05 09:51:25,501\tINFO tune.py:1047 -- Total run time: 425.57 seconds (425.53 seconds for the tuning loop).\n"
     ]
    }
   ],
   "source": [
    "bayes_search_space = {\n",
    "    \"conv_filters\": tune.uniform(64,256),\n",
    "    \"lr\": tune.loguniform(0.001, 0.1),\n",
    "    \"batch_size\": tune.uniform(0, 2),  # 0 for 64, 1 for 128, 2 for 256\n",
    "    \"dropout\": tune.uniform(0, 1)\n",
    "}\n",
    "\n",
    "# Initialize Bayesian optimization search algorithm\n",
    "bayesopt_search = BayesOptSearch()\n",
    "\n",
    "start_time = time()\n",
    "\n",
    "bayes_analysis = tune.run(\n",
    "    train_mnist_bayes,\n",
    "    name=\"exp_bayes\",\n",
    "    metric=\"mean_accuracy\",\n",
    "    mode=\"max\",\n",
    "    stop={\"mean_accuracy\": 0.99},\n",
    "    resources_per_trial={\"gpu\": 1},\n",
    "    config=search_space,\n",
    "    search_alg=bayesopt_search,\n",
    "    num_samples=10\n",
    ")\n",
    "\n",
    "end_time = time()\n",
    "bayes_time = end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial config: {'conv_filters': 164.75323487338966, 'lr': 0.029831684879606152, 'batch_size': 0.6084844859190754, 'dropout': 0.43194501864211576}\n",
      "Best trial final validation accuracy: 0.9726999998092651\n",
      "Time taken for Bayesian Search: 425.58768105506897 seconds\n"
     ]
    }
   ],
   "source": [
    "best_trial = bayes_analysis.get_best_trial(\"mean_accuracy\", \"max\", \"last\")\n",
    "best_config = best_trial.config\n",
    "\n",
    "print(\"Best trial config: {}\".format(best_config))\n",
    "print(\"Best trial final validation accuracy: {}\".format(\n",
    "    best_trial.last_result[\"mean_accuracy\"]))\n",
    "print(\"Time taken for Bayesian Search: {} seconds\".format(bayes_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperband "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperband_search_space = {\n",
    "    \"conv_filters\": tune.choice([64, 128, 256]),\n",
    "    \"lr\": tune.loguniform(0.001, 0.1),\n",
    "    \"batch_size\": tune.choice([64, 128, 256]),\n",
    "    \"dropout\": tune.uniform(0, 1)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-05 11:54:08,350\tINFO worker.py:1507 -- Calling ray.init() again after it has already been called.\n",
      "2023-12-05 11:54:08,354\tINFO tune.py:586 -- [output] This uses the legacy output and progress reporter, as Jupyter notebooks are not supported by the new engine, yet. For more information, please see https://github.com/ray-project/ray/issues/36949\n",
      "2023-12-05 11:54:08,367\tINFO tensorboardx.py:178 -- pip install \"ray[tune]\" to see TensorBoard files.\n",
      "2023-12-05 11:54:08,368\tWARNING callback.py:137 -- The TensorboardX logger cannot be instantiated because either TensorboardX or one of it's dependencies is not installed. Please make sure you have the latest version of TensorboardX installed: `pip install -U tensorboardx`\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2023-12-05 12:14:18</td></tr>\n",
       "<tr><td>Running for: </td><td>00:20:10.30        </td></tr>\n",
       "<tr><td>Memory:      </td><td>56.3/377.3 GiB     </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using HyperBand: num_stopped=2 total_brackets=3<br>Round #0:<br>  Bracket(Max Size (n)=5, Milestone (r)=81, completed=100.0%): {TERMINATED: 5} <br>  Bracket(Max Size (n)=3, Milestone (r)=81, completed=100.0%): {TERMINATED: 8} <br>  Bracket(Max Size (n)=5, Milestone (r)=27, completed=15.2%): {TERMINATED: 7} <br>Logical resource usage: 0/48 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name             </th><th>status    </th><th>loc                </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_filters</th><th style=\"text-align: right;\">   dropout</th><th style=\"text-align: right;\">        lr</th><th style=\"text-align: right;\">   acc</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_mnist_e8192_00000</td><td>TERMINATED</td><td>10.32.35.81:3103815</td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\">           128</td><td style=\"text-align: right;\">0.624152  </td><td style=\"text-align: right;\">0.00310254</td><td style=\"text-align: right;\">0.9865</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         49.5617</td></tr>\n",
       "<tr><td>train_mnist_e8192_00001</td><td>TERMINATED</td><td>10.32.35.81:3106917</td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\">           256</td><td style=\"text-align: right;\">0.31604   </td><td style=\"text-align: right;\">0.00198681</td><td style=\"text-align: right;\">0.9887</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         37.5665</td></tr>\n",
       "<tr><td>train_mnist_e8192_00002</td><td>TERMINATED</td><td>10.32.35.81:3109579</td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">            64</td><td style=\"text-align: right;\">0.763749  </td><td style=\"text-align: right;\">0.0788753 </td><td style=\"text-align: right;\">0.098 </td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         35.3228</td></tr>\n",
       "<tr><td>train_mnist_e8192_00003</td><td>TERMINATED</td><td>10.32.35.81:3111666</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">           256</td><td style=\"text-align: right;\">0.781244  </td><td style=\"text-align: right;\">0.00525434</td><td style=\"text-align: right;\">0.9839</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         58.1243</td></tr>\n",
       "<tr><td>train_mnist_e8192_00004</td><td>TERMINATED</td><td>10.32.35.81:3115598</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">            64</td><td style=\"text-align: right;\">0.550632  </td><td style=\"text-align: right;\">0.0263207 </td><td style=\"text-align: right;\">0.9527</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         54.4922</td></tr>\n",
       "<tr><td>train_mnist_e8192_00005</td><td>TERMINATED</td><td>10.32.35.81:3119875</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">           256</td><td style=\"text-align: right;\">0.52224   </td><td style=\"text-align: right;\">0.0551661 </td><td style=\"text-align: right;\">0.1009</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         58.0458</td></tr>\n",
       "<tr><td>train_mnist_e8192_00006</td><td>TERMINATED</td><td>10.32.35.81:3123659</td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">            64</td><td style=\"text-align: right;\">0.373677  </td><td style=\"text-align: right;\">0.00210428</td><td style=\"text-align: right;\">0.9888</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         35.4678</td></tr>\n",
       "<tr><td>train_mnist_e8192_00007</td><td>TERMINATED</td><td>10.32.35.81:3126529</td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\">            64</td><td style=\"text-align: right;\">0.739291  </td><td style=\"text-align: right;\">0.0239357 </td><td style=\"text-align: right;\">0.9447</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         26.2396</td></tr>\n",
       "<tr><td>train_mnist_e8192_00008</td><td>TERMINATED</td><td>10.32.35.81:3128058</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">           128</td><td style=\"text-align: right;\">0.293566  </td><td style=\"text-align: right;\">0.00765962</td><td style=\"text-align: right;\">0.984 </td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         54.5348</td></tr>\n",
       "<tr><td>train_mnist_e8192_00009</td><td>TERMINATED</td><td>10.32.35.81:3131728</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">           128</td><td style=\"text-align: right;\">0.343429  </td><td style=\"text-align: right;\">0.0293293 </td><td style=\"text-align: right;\">0.9528</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         54.5154</td></tr>\n",
       "<tr><td>train_mnist_e8192_00010</td><td>TERMINATED</td><td>10.32.35.81:3135254</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">           256</td><td style=\"text-align: right;\">0.583722  </td><td style=\"text-align: right;\">0.021504  </td><td style=\"text-align: right;\">0.9628</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         57.8154</td></tr>\n",
       "<tr><td>train_mnist_e8192_00011</td><td>TERMINATED</td><td>10.32.35.81:3139735</td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\">            64</td><td style=\"text-align: right;\">0.448344  </td><td style=\"text-align: right;\">0.0140608 </td><td style=\"text-align: right;\">0.9857</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         26.0361</td></tr>\n",
       "<tr><td>train_mnist_e8192_00012</td><td>TERMINATED</td><td>10.32.35.81:3141177</td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">           128</td><td style=\"text-align: right;\">0.328736  </td><td style=\"text-align: right;\">0.00206112</td><td style=\"text-align: right;\">0.9874</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         35.8685</td></tr>\n",
       "<tr><td>train_mnist_e8192_00013</td><td>TERMINATED</td><td>10.32.35.81:3143631</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">           128</td><td style=\"text-align: right;\">0.35838   </td><td style=\"text-align: right;\">0.0844879 </td><td style=\"text-align: right;\">0.1032</td><td style=\"text-align: right;\">     9</td><td style=\"text-align: right;\">         50.3587</td></tr>\n",
       "<tr><td>train_mnist_e8192_00014</td><td>TERMINATED</td><td>10.32.35.81:3164955</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">           256</td><td style=\"text-align: right;\">0.92917   </td><td style=\"text-align: right;\">0.00343921</td><td style=\"text-align: right;\">0.9708</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         58.0473</td></tr>\n",
       "<tr><td>train_mnist_e8192_00015</td><td>TERMINATED</td><td>10.32.35.81:3168818</td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\">           256</td><td style=\"text-align: right;\">0.834361  </td><td style=\"text-align: right;\">0.00350692</td><td style=\"text-align: right;\">0.9855</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         37.5897</td></tr>\n",
       "<tr><td>train_mnist_e8192_00016</td><td>TERMINATED</td><td>10.32.35.81:3171194</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">            64</td><td style=\"text-align: right;\">0.794142  </td><td style=\"text-align: right;\">0.00195595</td><td style=\"text-align: right;\">0.9863</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         54.3607</td></tr>\n",
       "<tr><td>train_mnist_e8192_00017</td><td>TERMINATED</td><td>10.32.35.81:3155816</td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">           256</td><td style=\"text-align: right;\">0.252692  </td><td style=\"text-align: right;\">0.0151896 </td><td style=\"text-align: right;\">0.9587</td><td style=\"text-align: right;\">     9</td><td style=\"text-align: right;\">         40.0835</td></tr>\n",
       "<tr><td>train_mnist_e8192_00018</td><td>TERMINATED</td><td>10.32.35.81:3174898</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">           128</td><td style=\"text-align: right;\">0.00637137</td><td style=\"text-align: right;\">0.0179813 </td><td style=\"text-align: right;\">0.9726</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         54.8992</td></tr>\n",
       "<tr><td>train_mnist_e8192_00019</td><td>TERMINATED</td><td>10.32.35.81:3161867</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">           256</td><td style=\"text-align: right;\">0.945807  </td><td style=\"text-align: right;\">0.00133311</td><td style=\"text-align: right;\">0.9781</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         58.059 </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3103815)\u001b[0m 2023-12-05 11:54:10.570377: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3103815)\u001b[0m 2023-12-05 11:54:10.609697: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3103815)\u001b[0m 2023-12-05 11:54:10.609721: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3103815)\u001b[0m 2023-12-05 11:54:10.610775: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3103815)\u001b[0m 2023-12-05 11:54:10.616713: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3103815)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3103815)\u001b[0m 2023-12-05 11:54:11.310153: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3103815)\u001b[0m 2023-12-05 11:54:15.149013: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3103815)\u001b[0m 2023-12-05 11:54:19.705107: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3103815)\u001b[0m 2023-12-05 11:54:31.079003: I external/local_xla/xla/service/service.cc:168] XLA service 0x14c444d98bd0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3103815)\u001b[0m 2023-12-05 11:54:31.079043: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3103815)\u001b[0m 2023-12-05 11:54:31.085997: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3103815)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3103815)\u001b[0m I0000 00:00:1701795271.516787 3103908 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"trialProgress\">\n",
       "  <h3>Trial Progress</h3>\n",
       "  <table>\n",
       "<thead>\n",
       "<tr><th>Trial name             </th><th style=\"text-align: right;\">  mean_accuracy</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_mnist_e8192_00000</td><td style=\"text-align: right;\">         0.9865</td></tr>\n",
       "<tr><td>train_mnist_e8192_00001</td><td style=\"text-align: right;\">         0.9887</td></tr>\n",
       "<tr><td>train_mnist_e8192_00002</td><td style=\"text-align: right;\">         0.098 </td></tr>\n",
       "<tr><td>train_mnist_e8192_00003</td><td style=\"text-align: right;\">         0.9839</td></tr>\n",
       "<tr><td>train_mnist_e8192_00004</td><td style=\"text-align: right;\">         0.9527</td></tr>\n",
       "<tr><td>train_mnist_e8192_00005</td><td style=\"text-align: right;\">         0.1009</td></tr>\n",
       "<tr><td>train_mnist_e8192_00006</td><td style=\"text-align: right;\">         0.9888</td></tr>\n",
       "<tr><td>train_mnist_e8192_00007</td><td style=\"text-align: right;\">         0.9447</td></tr>\n",
       "<tr><td>train_mnist_e8192_00008</td><td style=\"text-align: right;\">         0.984 </td></tr>\n",
       "<tr><td>train_mnist_e8192_00009</td><td style=\"text-align: right;\">         0.9528</td></tr>\n",
       "<tr><td>train_mnist_e8192_00010</td><td style=\"text-align: right;\">         0.9628</td></tr>\n",
       "<tr><td>train_mnist_e8192_00011</td><td style=\"text-align: right;\">         0.9857</td></tr>\n",
       "<tr><td>train_mnist_e8192_00012</td><td style=\"text-align: right;\">         0.9874</td></tr>\n",
       "<tr><td>train_mnist_e8192_00013</td><td style=\"text-align: right;\">         0.1032</td></tr>\n",
       "<tr><td>train_mnist_e8192_00014</td><td style=\"text-align: right;\">         0.9708</td></tr>\n",
       "<tr><td>train_mnist_e8192_00015</td><td style=\"text-align: right;\">         0.9855</td></tr>\n",
       "<tr><td>train_mnist_e8192_00016</td><td style=\"text-align: right;\">         0.9863</td></tr>\n",
       "<tr><td>train_mnist_e8192_00017</td><td style=\"text-align: right;\">         0.9587</td></tr>\n",
       "<tr><td>train_mnist_e8192_00018</td><td style=\"text-align: right;\">         0.9726</td></tr>\n",
       "<tr><td>train_mnist_e8192_00019</td><td style=\"text-align: right;\">         0.9781</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".trialProgress {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".trialProgress h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".trialProgress td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3106917)\u001b[0m 2023-12-05 11:55:03.970452: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3106917)\u001b[0m 2023-12-05 11:55:04.009390: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3106917)\u001b[0m 2023-12-05 11:55:04.009414: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3106917)\u001b[0m 2023-12-05 11:55:04.010430: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3106917)\u001b[0m 2023-12-05 11:55:04.016257: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3106917)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3106917)\u001b[0m 2023-12-05 11:55:04.702042: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3106917)\u001b[0m 2023-12-05 11:55:06.051017: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3106917)\u001b[0m 2023-12-05 11:55:07.742757: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3106917)\u001b[0m 2023-12-05 11:55:08.780921: I external/local_xla/xla/service/service.cc:168] XLA service 0x14c411cfca40 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3106917)\u001b[0m 2023-12-05 11:55:08.780951: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3106917)\u001b[0m 2023-12-05 11:55:08.786623: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3106917)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3106917)\u001b[0m I0000 00:00:1701795308.900710 3107001 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3109579)\u001b[0m 2023-12-05 11:55:44.992458: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3109579)\u001b[0m 2023-12-05 11:55:45.031664: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3109579)\u001b[0m 2023-12-05 11:55:45.031694: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3109579)\u001b[0m 2023-12-05 11:55:45.032744: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3109579)\u001b[0m 2023-12-05 11:55:45.038700: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3109579)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3109579)\u001b[0m 2023-12-05 11:55:45.728936: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3109579)\u001b[0m 2023-12-05 11:55:47.013515: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3109579)\u001b[0m 2023-12-05 11:55:48.683580: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3109579)\u001b[0m 2023-12-05 11:55:49.632266: I external/local_xla/xla/service/service.cc:168] XLA service 0x14a585b94320 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3109579)\u001b[0m 2023-12-05 11:55:49.632314: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3109579)\u001b[0m 2023-12-05 11:55:49.640929: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3109579)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3109579)\u001b[0m I0000 00:00:1701795349.754334 3109790 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3111666)\u001b[0m 2023-12-05 11:56:24.063069: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3111666)\u001b[0m 2023-12-05 11:56:24.102485: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3111666)\u001b[0m 2023-12-05 11:56:24.102516: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3111666)\u001b[0m 2023-12-05 11:56:24.103563: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3111666)\u001b[0m 2023-12-05 11:56:24.109624: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3111666)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3111666)\u001b[0m 2023-12-05 11:56:24.825072: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3111666)\u001b[0m 2023-12-05 11:56:26.419030: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3111666)\u001b[0m 2023-12-05 11:56:28.104928: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3111666)\u001b[0m 2023-12-05 11:56:29.071691: I external/local_xla/xla/service/service.cc:168] XLA service 0x1478806bb4f0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3111666)\u001b[0m 2023-12-05 11:56:29.071721: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3111666)\u001b[0m 2023-12-05 11:56:29.079219: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3111666)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3111666)\u001b[0m I0000 00:00:1701795389.198714 3111954 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3115598)\u001b[0m 2023-12-05 11:57:26.084605: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3115598)\u001b[0m 2023-12-05 11:57:26.123547: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3115598)\u001b[0m 2023-12-05 11:57:26.123575: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3115598)\u001b[0m 2023-12-05 11:57:26.124613: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3115598)\u001b[0m 2023-12-05 11:57:26.130507: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3115598)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3115598)\u001b[0m 2023-12-05 11:57:26.848666: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3115598)\u001b[0m 2023-12-05 11:57:28.179298: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3115598)\u001b[0m 2023-12-05 11:57:29.846523: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3115598)\u001b[0m 2023-12-05 11:57:30.800478: I external/local_xla/xla/service/service.cc:168] XLA service 0x14594030b720 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3115598)\u001b[0m 2023-12-05 11:57:30.800521: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3115598)\u001b[0m 2023-12-05 11:57:30.810860: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3115598)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3115598)\u001b[0m I0000 00:00:1701795450.935582 3115884 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3119875)\u001b[0m 2023-12-05 11:58:24.021363: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3119875)\u001b[0m 2023-12-05 11:58:24.060528: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3119875)\u001b[0m 2023-12-05 11:58:24.060552: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3119875)\u001b[0m 2023-12-05 11:58:24.061612: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3119875)\u001b[0m 2023-12-05 11:58:24.067538: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3119875)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3119875)\u001b[0m 2023-12-05 11:58:24.762241: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3119875)\u001b[0m 2023-12-05 11:58:26.069338: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3119875)\u001b[0m 2023-12-05 11:58:27.796448: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3119875)\u001b[0m 2023-12-05 11:58:28.764934: I external/local_xla/xla/service/service.cc:168] XLA service 0x14eb8c6d15a0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3119875)\u001b[0m 2023-12-05 11:58:28.764975: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3119875)\u001b[0m 2023-12-05 11:58:28.771979: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3119875)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3119875)\u001b[0m I0000 00:00:1701795508.886686 3120009 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3123659)\u001b[0m 2023-12-05 11:59:26.043234: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3123659)\u001b[0m 2023-12-05 11:59:26.082917: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3123659)\u001b[0m 2023-12-05 11:59:26.082942: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3123659)\u001b[0m 2023-12-05 11:59:26.083992: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3123659)\u001b[0m 2023-12-05 11:59:26.089964: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3123659)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3123659)\u001b[0m 2023-12-05 11:59:26.802039: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3123659)\u001b[0m 2023-12-05 11:59:28.112003: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3123659)\u001b[0m 2023-12-05 11:59:29.824678: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3123659)\u001b[0m 2023-12-05 11:59:30.795102: I external/local_xla/xla/service/service.cc:168] XLA service 0x14d98830b9c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3123659)\u001b[0m 2023-12-05 11:59:30.795127: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3123659)\u001b[0m 2023-12-05 11:59:30.800196: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3123659)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3123659)\u001b[0m I0000 00:00:1701795570.912662 3123746 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3126529)\u001b[0m 2023-12-05 12:00:05.040898: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3126529)\u001b[0m 2023-12-05 12:00:05.080571: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3126529)\u001b[0m 2023-12-05 12:00:05.080598: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3126529)\u001b[0m 2023-12-05 12:00:05.081650: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3126529)\u001b[0m 2023-12-05 12:00:05.087566: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3126529)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3126529)\u001b[0m 2023-12-05 12:00:05.807083: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3126529)\u001b[0m 2023-12-05 12:00:07.122708: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3126529)\u001b[0m 2023-12-05 12:00:08.828808: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3126529)\u001b[0m 2023-12-05 12:00:09.798744: I external/local_xla/xla/service/service.cc:168] XLA service 0x1529d95254c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3126529)\u001b[0m 2023-12-05 12:00:09.798771: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3126529)\u001b[0m 2023-12-05 12:00:09.804565: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3126529)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3126529)\u001b[0m I0000 00:00:1701795609.912251 3126818 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3128058)\u001b[0m 2023-12-05 12:00:35.074037: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3128058)\u001b[0m 2023-12-05 12:00:35.113186: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3128058)\u001b[0m 2023-12-05 12:00:35.113215: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3128058)\u001b[0m 2023-12-05 12:00:35.114260: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3128058)\u001b[0m 2023-12-05 12:00:35.120228: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3128058)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3128058)\u001b[0m 2023-12-05 12:00:35.823642: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3128058)\u001b[0m 2023-12-05 12:00:37.167454: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3128058)\u001b[0m 2023-12-05 12:00:38.884719: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3128058)\u001b[0m 2023-12-05 12:00:39.851426: I external/local_xla/xla/service/service.cc:168] XLA service 0x14ded86d0e60 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3128058)\u001b[0m 2023-12-05 12:00:39.851471: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3128058)\u001b[0m 2023-12-05 12:00:39.858336: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3128058)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3128058)\u001b[0m I0000 00:00:1701795639.980864 3128250 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3131728)\u001b[0m 2023-12-05 12:01:33.096418: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3131728)\u001b[0m 2023-12-05 12:01:33.135704: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3131728)\u001b[0m 2023-12-05 12:01:33.135730: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3131728)\u001b[0m 2023-12-05 12:01:33.136791: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3131728)\u001b[0m 2023-12-05 12:01:33.142807: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3131728)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3131728)\u001b[0m 2023-12-05 12:01:33.863164: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3131728)\u001b[0m 2023-12-05 12:01:35.187683: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3131728)\u001b[0m 2023-12-05 12:01:36.855716: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3131728)\u001b[0m 2023-12-05 12:01:37.783762: I external/local_xla/xla/service/service.cc:168] XLA service 0x14c6f430b630 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3131728)\u001b[0m 2023-12-05 12:01:37.783803: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3131728)\u001b[0m 2023-12-05 12:01:37.792605: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3131728)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3131728)\u001b[0m I0000 00:00:1701795697.906465 3132016 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3135254)\u001b[0m 2023-12-05 12:02:31.038532: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3135254)\u001b[0m 2023-12-05 12:02:31.077992: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3135254)\u001b[0m 2023-12-05 12:02:31.078020: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3135254)\u001b[0m 2023-12-05 12:02:31.079050: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3135254)\u001b[0m 2023-12-05 12:02:31.084932: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3135254)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3135254)\u001b[0m 2023-12-05 12:02:31.774085: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3135254)\u001b[0m 2023-12-05 12:02:33.064500: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3135254)\u001b[0m 2023-12-05 12:02:34.751709: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3135254)\u001b[0m 2023-12-05 12:02:35.699598: I external/local_xla/xla/service/service.cc:168] XLA service 0x14e341533680 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3135254)\u001b[0m 2023-12-05 12:02:35.699640: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3135254)\u001b[0m 2023-12-05 12:02:35.708655: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3135254)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3135254)\u001b[0m I0000 00:00:1701795755.832737 3135746 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3139735)\u001b[0m 2023-12-05 12:03:32.083310: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3139735)\u001b[0m 2023-12-05 12:03:32.083339: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3139735)\u001b[0m 2023-12-05 12:03:32.084391: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3139735)\u001b[0m 2023-12-05 12:03:32.044222: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3139735)\u001b[0m 2023-12-05 12:03:32.090336: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3139735)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3139735)\u001b[0m 2023-12-05 12:03:32.795647: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3139735)\u001b[0m 2023-12-05 12:03:34.099608: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3139735)\u001b[0m 2023-12-05 12:03:35.782493: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3139735)\u001b[0m 2023-12-05 12:03:36.736953: I external/local_xla/xla/service/service.cc:168] XLA service 0x1480b0d99910 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3139735)\u001b[0m 2023-12-05 12:03:36.736979: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3139735)\u001b[0m 2023-12-05 12:03:36.742438: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3139735)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3139735)\u001b[0m I0000 00:00:1701795816.851122 3139817 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3141177)\u001b[0m 2023-12-05 12:04:02.104398: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3141177)\u001b[0m 2023-12-05 12:04:02.150144: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3141177)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3141177)\u001b[0m 2023-12-05 12:04:02.143254: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3141177)\u001b[0m 2023-12-05 12:04:02.143282: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3141177)\u001b[0m 2023-12-05 12:04:02.144308: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3141177)\u001b[0m 2023-12-05 12:04:02.837082: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3141177)\u001b[0m 2023-12-05 12:04:04.131405: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3141177)\u001b[0m 2023-12-05 12:04:05.816783: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3141177)\u001b[0m 2023-12-05 12:04:06.756048: I external/local_xla/xla/service/service.cc:168] XLA service 0x14b0a17f2410 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3141177)\u001b[0m 2023-12-05 12:04:06.756089: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3141177)\u001b[0m 2023-12-05 12:04:06.766830: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3141177)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3141177)\u001b[0m I0000 00:00:1701795846.883197 3141671 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3143631)\u001b[0m 2023-12-05 12:04:41.131399: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3143631)\u001b[0m 2023-12-05 12:04:41.131426: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3143631)\u001b[0m 2023-12-05 12:04:41.132489: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3143631)\u001b[0m 2023-12-05 12:04:41.091008: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3143631)\u001b[0m 2023-12-05 12:04:41.138438: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3143631)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3143631)\u001b[0m 2023-12-05 12:04:41.834563: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3143631)\u001b[0m 2023-12-05 12:04:43.130610: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3143631)\u001b[0m 2023-12-05 12:04:44.798514: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3143631)\u001b[0m 2023-12-05 12:04:45.767585: I external/local_xla/xla/service/service.cc:168] XLA service 0x15024831d9e0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3143631)\u001b[0m 2023-12-05 12:04:45.767630: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3143631)\u001b[0m 2023-12-05 12:04:45.777382: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3143631)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3143631)\u001b[0m I0000 00:00:1701795885.892884 3143919 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3146866)\u001b[0m 2023-12-05 12:05:35.077795: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3146866)\u001b[0m 2023-12-05 12:05:35.117098: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3146866)\u001b[0m 2023-12-05 12:05:35.117124: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3146866)\u001b[0m 2023-12-05 12:05:35.118164: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3146866)\u001b[0m 2023-12-05 12:05:35.124052: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3146866)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3146866)\u001b[0m 2023-12-05 12:05:35.816255: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3146866)\u001b[0m 2023-12-05 12:05:37.105301: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3146866)\u001b[0m 2023-12-05 12:05:38.793475: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3146866)\u001b[0m 2023-12-05 12:05:39.759124: I external/local_xla/xla/service/service.cc:168] XLA service 0x14cb7d520950 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3146866)\u001b[0m 2023-12-05 12:05:39.759153: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3146866)\u001b[0m 2023-12-05 12:05:39.766204: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3146866)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3146866)\u001b[0m I0000 00:00:1701795939.887680 3146960 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3150328)\u001b[0m 2023-12-05 12:06:31.105967: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3150328)\u001b[0m 2023-12-05 12:06:31.105996: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3150328)\u001b[0m 2023-12-05 12:06:31.107081: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3150328)\u001b[0m 2023-12-05 12:06:31.113086: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3150328)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3150328)\u001b[0m 2023-12-05 12:06:31.066272: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3150328)\u001b[0m 2023-12-05 12:06:31.818505: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3150328)\u001b[0m 2023-12-05 12:06:33.111676: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3150328)\u001b[0m 2023-12-05 12:06:34.800527: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3150328)\u001b[0m 2023-12-05 12:06:35.822065: I external/local_xla/xla/service/service.cc:168] XLA service 0x14c40515e6a0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3150328)\u001b[0m 2023-12-05 12:06:35.822095: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3150328)\u001b[0m 2023-12-05 12:06:35.827924: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3150328)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3150328)\u001b[0m I0000 00:00:1701795995.954497 3150426 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3152787)\u001b[0m 2023-12-05 12:07:09.051563: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3152787)\u001b[0m 2023-12-05 12:07:09.090744: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3152787)\u001b[0m 2023-12-05 12:07:09.090769: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3152787)\u001b[0m 2023-12-05 12:07:09.091817: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3152787)\u001b[0m 2023-12-05 12:07:09.097690: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3152787)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3152787)\u001b[0m 2023-12-05 12:07:09.784172: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3152787)\u001b[0m 2023-12-05 12:07:11.077772: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3152787)\u001b[0m 2023-12-05 12:07:12.753568: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3152787)\u001b[0m 2023-12-05 12:07:13.722628: I external/local_xla/xla/service/service.cc:168] XLA service 0x14e6c980b8f0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3152787)\u001b[0m 2023-12-05 12:07:13.722657: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3152787)\u001b[0m 2023-12-05 12:07:13.728958: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3152787)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3152787)\u001b[0m I0000 00:00:1701796033.851607 3152871 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3155816)\u001b[0m 2023-12-05 12:08:02.183276: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3155816)\u001b[0m 2023-12-05 12:08:02.183298: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3155816)\u001b[0m 2023-12-05 12:08:02.184341: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3155816)\u001b[0m 2023-12-05 12:08:02.190245: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3155816)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3155816)\u001b[0m 2023-12-05 12:08:02.143798: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3155816)\u001b[0m 2023-12-05 12:08:02.909187: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3155816)\u001b[0m 2023-12-05 12:08:04.243163: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3155816)\u001b[0m 2023-12-05 12:08:05.965256: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3155816)\u001b[0m 2023-12-05 12:08:06.955924: I external/local_xla/xla/service/service.cc:168] XLA service 0x14886c30c4a0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3155816)\u001b[0m 2023-12-05 12:08:06.955969: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3155816)\u001b[0m 2023-12-05 12:08:06.965269: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3155816)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3155816)\u001b[0m I0000 00:00:1701796087.089441 3155901 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3158802)\u001b[0m 2023-12-05 12:08:46.135733: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3158802)\u001b[0m 2023-12-05 12:08:46.175202: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3158802)\u001b[0m 2023-12-05 12:08:46.175227: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3158802)\u001b[0m 2023-12-05 12:08:46.176299: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3158802)\u001b[0m 2023-12-05 12:08:46.182287: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3158802)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3158802)\u001b[0m 2023-12-05 12:08:46.885531: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3158802)\u001b[0m 2023-12-05 12:08:48.187690: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3158802)\u001b[0m 2023-12-05 12:08:49.870298: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3158802)\u001b[0m 2023-12-05 12:08:50.868870: I external/local_xla/xla/service/service.cc:168] XLA service 0x1447b06bb2c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3158802)\u001b[0m 2023-12-05 12:08:50.868902: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3158802)\u001b[0m 2023-12-05 12:08:50.877009: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3158802)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3158802)\u001b[0m I0000 00:00:1701796130.990041 3158937 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3161867)\u001b[0m 2023-12-05 12:09:39.144762: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3161867)\u001b[0m 2023-12-05 12:09:39.184512: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3161867)\u001b[0m 2023-12-05 12:09:39.184538: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3161867)\u001b[0m 2023-12-05 12:09:39.185600: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3161867)\u001b[0m 2023-12-05 12:09:39.191695: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3161867)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3161867)\u001b[0m 2023-12-05 12:09:39.910504: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3161867)\u001b[0m 2023-12-05 12:09:41.240105: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3161867)\u001b[0m 2023-12-05 12:09:42.934512: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3161867)\u001b[0m 2023-12-05 12:09:43.899404: I external/local_xla/xla/service/service.cc:168] XLA service 0x149d406e2c30 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3161867)\u001b[0m 2023-12-05 12:09:43.899447: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3161867)\u001b[0m 2023-12-05 12:09:43.907174: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3161867)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3161867)\u001b[0m I0000 00:00:1701796184.030224 3161952 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3164955)\u001b[0m 2023-12-05 12:10:41.196295: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3164955)\u001b[0m 2023-12-05 12:10:41.235483: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3164955)\u001b[0m 2023-12-05 12:10:41.235512: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3164955)\u001b[0m 2023-12-05 12:10:41.236558: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3164955)\u001b[0m 2023-12-05 12:10:41.242519: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3164955)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3164955)\u001b[0m 2023-12-05 12:10:41.967797: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3164955)\u001b[0m 2023-12-05 12:10:43.298829: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3164955)\u001b[0m 2023-12-05 12:10:44.989895: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3164955)\u001b[0m 2023-12-05 12:10:45.970573: I external/local_xla/xla/service/service.cc:168] XLA service 0x14f05430b340 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3164955)\u001b[0m 2023-12-05 12:10:45.970621: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3164955)\u001b[0m 2023-12-05 12:10:45.979830: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3164955)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3164955)\u001b[0m I0000 00:00:1701796246.102613 3165249 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2023-12-05 12:10:51,998\tINFO hyperband.py:543 -- Restoring from a previous point in time. Previous=9; Now=1\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3168818)\u001b[0m 2023-12-05 12:11:43.064847: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3168818)\u001b[0m 2023-12-05 12:11:43.104374: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3168818)\u001b[0m 2023-12-05 12:11:43.104397: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3168818)\u001b[0m 2023-12-05 12:11:43.105450: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3168818)\u001b[0m 2023-12-05 12:11:43.111379: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3168818)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3168818)\u001b[0m 2023-12-05 12:11:43.813775: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3168818)\u001b[0m 2023-12-05 12:11:45.133991: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3168818)\u001b[0m 2023-12-05 12:11:46.811124: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3168818)\u001b[0m 2023-12-05 12:11:47.829867: I external/local_xla/xla/service/service.cc:168] XLA service 0x150064d83540 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3168818)\u001b[0m 2023-12-05 12:11:47.829893: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3168818)\u001b[0m 2023-12-05 12:11:47.834900: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3168818)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3168818)\u001b[0m I0000 00:00:1701796307.958465 3169223 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2023-12-05 12:11:51,938\tINFO hyperband.py:543 -- Restoring from a previous point in time. Previous=9; Now=1\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3171194)\u001b[0m 2023-12-05 12:12:24.096129: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3171194)\u001b[0m 2023-12-05 12:12:24.135652: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3171194)\u001b[0m 2023-12-05 12:12:24.135678: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3171194)\u001b[0m 2023-12-05 12:12:24.136742: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3171194)\u001b[0m 2023-12-05 12:12:24.142703: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3171194)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3171194)\u001b[0m 2023-12-05 12:12:24.838993: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3171194)\u001b[0m 2023-12-05 12:12:26.144813: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3171194)\u001b[0m 2023-12-05 12:12:27.813668: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3171194)\u001b[0m 2023-12-05 12:12:28.770163: I external/local_xla/xla/service/service.cc:168] XLA service 0x14bc78307760 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3171194)\u001b[0m 2023-12-05 12:12:28.770208: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3171194)\u001b[0m 2023-12-05 12:12:28.779534: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3171194)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3171194)\u001b[0m I0000 00:00:1701796348.903284 3171481 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2023-12-05 12:12:34,389\tINFO hyperband.py:543 -- Restoring from a previous point in time. Previous=9; Now=1\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[33m(raylet)\u001b[0m Error processing line 3 of /home/gha2009/.local/lib/python3.11/site-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth:\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m   Traceback (most recent call last):\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen site>\", line 186, in addpackage\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<string>\", line 1, in <module>\n",
      "\u001b[33m(raylet)\u001b[0m     File \"<frozen importlib._bootstrap>\", line 570, in module_from_spec\n",
      "\u001b[33m(raylet)\u001b[0m   AttributeError: 'NoneType' object has no attribute 'loader'\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Remainder of file ignored\n",
      "\u001b[36m(pid=3174898)\u001b[0m 2023-12-05 12:13:22.163586: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=3174898)\u001b[0m 2023-12-05 12:13:22.202668: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=3174898)\u001b[0m 2023-12-05 12:13:22.202695: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=3174898)\u001b[0m 2023-12-05 12:13:22.203758: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=3174898)\u001b[0m 2023-12-05 12:13:22.209708: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=3174898)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=3174898)\u001b[0m 2023-12-05 12:13:22.909618: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_mnist pid=3174898)\u001b[0m 2023-12-05 12:13:24.228716: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 44333 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:86:00.0, compute capability: 7.5\n",
      "\u001b[36m(train_mnist pid=3174898)\u001b[0m 2023-12-05 12:13:25.959257: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "\u001b[36m(train_mnist pid=3174898)\u001b[0m 2023-12-05 12:13:26.905228: I external/local_xla/xla/service/service.cc:168] XLA service 0x144f3030bb20 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "\u001b[36m(train_mnist pid=3174898)\u001b[0m 2023-12-05 12:13:26.905270: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "\u001b[36m(train_mnist pid=3174898)\u001b[0m 2023-12-05 12:13:26.914125: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "\u001b[36m(train_mnist pid=3174898)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(train_mnist pid=3174898)\u001b[0m I0000 00:00:1701796407.028055 3175280 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2023-12-05 12:13:32,570\tINFO hyperband.py:543 -- Restoring from a previous point in time. Previous=9; Now=1\n",
      "2023-12-05 12:14:18,686\tINFO tune.py:1047 -- Total run time: 1210.33 seconds (1210.29 seconds for the tuning loop).\n"
     ]
    }
   ],
   "source": [
    "from ray.tune.schedulers import HyperBandScheduler\n",
    "\n",
    "# Initialize Ray\n",
    "ray.init(ignore_reinit_error=True)\n",
    "\n",
    "# Start time\n",
    "start_time = time()\n",
    "\n",
    "# Define the HyperBandScheduler with metric and mode\n",
    "hyperband_scheduler = HyperBandScheduler(metric=\"mean_accuracy\", mode=\"max\")\n",
    "\n",
    "# Run Hyperband optimization without metric and mode in tune.run()\n",
    "hyperband_analysis = tune.run(\n",
    "    train_mnist,\n",
    "    name=\"hyperband_exp\",\n",
    "    stop={\"mean_accuracy\": 0.99, \"training_iteration\": 10},\n",
    "    resources_per_trial={\"gpu\": 1},\n",
    "    config=hyperband_search_space,\n",
    "    num_samples=20,  # Number of different hyperparameter combinations to try\n",
    "    scheduler=hyperband_scheduler\n",
    ")\n",
    "\n",
    "# End time\n",
    "end_time = time()\n",
    "hyperband_time = end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial config: {'conv_filters': 64, 'lr': 0.0021042765420631734, 'batch_size': 128, 'dropout': 0.3736771928672201}\n",
      "Best trial final validation accuracy: 0.9887999892234802\n",
      "Time taken for Hyperband Search: 1210.3595538139343 seconds\n"
     ]
    }
   ],
   "source": [
    "best_trial = hyperband_analysis.get_best_trial(\"mean_accuracy\", \"max\", \"last\")\n",
    "best_config = best_trial.config\n",
    "\n",
    "print(\"Best trial config: {}\".format(best_config))\n",
    "print(\"Best trial final validation accuracy: {}\".format(\n",
    "    best_trial.last_result[\"mean_accuracy\"]))\n",
    "print(\"Time taken for Hyperband Search: {} seconds\".format(hyperband_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_results(analysis, technique_name, time_taken):\n",
    "    best_trial = analysis.get_best_trial(\"mean_accuracy\", \"max\", \"last\")\n",
    "    best_config = best_trial.config\n",
    "    best_accuracy = best_trial.last_result[\"mean_accuracy\"]\n",
    "\n",
    "    print(f\"{technique_name} Results:\")\n",
    "    print(f\"Time Taken: {time_taken:.2f} seconds\")\n",
    "    print(f\"Best Hyperparameters: {best_config}\")\n",
    "    print(f\"Best Validation Accuracy: {best_accuracy:.4f}\")\n",
    "    print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid Search Results:\n",
      "Time Taken: 7111.17 seconds\n",
      "Best Hyperparameters: {'conv_filters': 64, 'lr': 0.001, 'batch_size': 256, 'dropout': 0.25}\n",
      "Best Validation Accuracy: 0.9894\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Display results for Grid Search\n",
    "display_results(grid_analysis, \"Grid Search\", grid_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bayesian Search Results:\n",
      "Time Taken: 425.59 seconds\n",
      "Best Hyperparameters: {'conv_filters': 164.75323487338966, 'lr': 0.029831684879606152, 'batch_size': 0.6084844859190754, 'dropout': 0.43194501864211576}\n",
      "Best Validation Accuracy: 0.9727\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Display results for Bayesian Search\n",
    "display_results(bayes_analysis, \"Bayesian Search\", bayes_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperband Results:\n",
      "Time Taken: 1210.36 seconds\n",
      "Best Hyperparameters: {'conv_filters': 64, 'lr': 0.0021042765420631734, 'batch_size': 128, 'dropout': 0.3736771928672201}\n",
      "Best Validation Accuracy: 0.9888\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Display results for Hyperband\n",
    "display_results(hyperband_analysis, \"Hyperband\", hyperband_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "\n",
    "Analyzing your results, several key observations can be made regarding the time taken for hyperparameter optimization and the performance of the best model identified by each search method:\n",
    "\n",
    "Grid Search took the longest time (7111.17 seconds) among the three methods. This is expected as grid search exhaustively explores the defined hyperparameter space, which can be time-consuming, especially for large search spaces. The best model achieved a high validation accuracy of 0.9894. This indicates that despite its time-consuming nature, grid search can be effective in finding well-performing hyperparameters.\n",
    "\n",
    "Bayesian Search method was significantly faster (425.59 seconds), demonstrating Bayesian search's efficiency in navigating the hyperparameter space by building a probabilistic model and using it to select the most promising hyperparameters. The best model had a lower validation accuracy (0.9727) compared to grid search. This could be due to the Bayesian search exploring more diverse regions of the hyperparameter space, which might lead to finding good but not necessarily the best parameters within the limited number of trials.\n",
    "\n",
    "Hyperband was faster than grid search but slower than Bayesian search (1210.36 seconds). Hyperband, being a bandit-based approach, efficiently allocates resources to promising configurations and quickly discards poor-performing ones, which can lead to time savings. The best model identified by Hyperband achieved a validation accuracy of 0.9888, which is very close to Grid Search yet better than Bayesian Search. This suggests a good balance between exploration and exploitation in Hyperband's approach.\n",
    "\n",
    "In general, there is a clear trade-off between the time taken for hyperparameter optimization and the performance of the best model. Grid search, while time-consuming, found the most accurate model. Bayesian search, despite being much faster, compromised slightly on accuracy. Bayesian search and Hyperband offer more efficient hyperparameter tuning compared to grid search, though they may require careful tuning of their own parameters to achieve the best results. Overall, the choice of method depends on the specific requirements and constraints of the project goal. If computational resources and time are limited, Bayesian search or Hyperband might be more suitable. If the highest possible accuracy is paramount and resources are ample, grid search might be the better choice. Regardless, all accuracy scores are high and very close to each other, so the specific case in this scenario depends more. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "curlybaddie",
   "language": "python",
   "name": "my_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
