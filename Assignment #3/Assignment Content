Softmax Activation Function, Neural Network Training and Backpropagation, Weight Initialization, Dead Neurons, Leaky ReLU, Batch Normalization, Dropout, MNIST, Learning Rate, Batch Size, FashionMNIST
