{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NcDhlfqyBd6m"
      },
      "source": [
        "# Problem 3 - Which Algorithm is Better?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-id00ye6CNLB"
      },
      "source": [
        "## 3.1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4kineJbrfcg7"
      },
      "source": [
        "**Answer:**\n",
        "\n",
        "Retrieval Algorithm #1:\n",
        "\n",
        "|   | Actual <br> Positive  | Actual <br> Negative  |\n",
        "|:---:|:---:|:---:|\n",
        "| **Predicted <br> Positive** | 25 | 15 |\n",
        "| **Predicted <br> Negative** | 5 | 55 |\n",
        "\n",
        "\n",
        "Retrieval Algorithm #2:\n",
        "\n",
        "|   | Actual <br> Positive  | Actual <br> Negative  |\n",
        "|:---:|:---:|:---:|\n",
        "| **Predicted <br> Positive** | 20 | 10 |\n",
        "| **Predicted <br> Negative** | 10 | 60 |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1D_yfneCWqL"
      },
      "source": [
        "## 3.2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BX8Ns_Imf-BI"
      },
      "source": [
        "\n",
        "**Retrieval Algorithm #1**\n",
        "\n",
        "- Total Positive Samples (P) = TP + FN = 25 + 55 = 30\n",
        "\n",
        "- Total Negative Samples (N)  = FP + TN =  15 + 5 = 70\n",
        "\n",
        "- Sensitivity = TP / (TP + FN) = 25 / 30 = 0.833\n",
        "\n",
        "- Specificity = TN / (FP + TN) = 55 / 70 = 0.7857142857\n",
        "\n",
        "> **Accuracy = (TP + TN) / (P + N) = 80 / 100 = 0.80**\n",
        "\n",
        "> **Balanced Accuracy = (Sensitivity + Specificity) / 2 = 1.6187142857 / 2 = 0.8093571429**\n",
        "\n",
        "- Precision = TP / (TP + FP) = 25 / 40 = 0.625\n",
        "\n",
        "- Recall = Sensitivity = TP / (TP + FN) = 0.833\n",
        "\n",
        "> **F1-Score = 2 * (Precision * Recall) / (Precision + Recall) = 2 * (0.625 * 0.8333) / (0.625 + 0.8333) ≈ 0.7143**\n",
        "\n",
        "**Retrieval Algorithm #2**\n",
        "\n",
        "- Total Positive Samples (P) = TP + FN = 20 + 10 = 30\n",
        "\n",
        "- Total Negative Samples (N)  = FP + TN =  10 + 60 = 70\n",
        "\n",
        "- Sensitivity = TP / (TP + FN) = 20 / 30 = 0.6667\n",
        "\n",
        "- Specificity = TN / (FP + TN) = 60 / 70 = 0.857\n",
        "\n",
        "> **Accuracy = (TP + TN) / (P + N) = 80 / 100 = 0.80**\n",
        "\n",
        "> **Balanced Accuracy = (Sensitivity + Specificity) / 2 = 1.5237 / 2 ≈ 0.76185**\n",
        "\n",
        "- Precision = TP / (TP + FP) = 20 / 30 = 0.6667\n",
        "\n",
        "- Recall = Sensitivity = TP / (TP + FN) = 0.6667\n",
        "\n",
        "> **F1-Score = 2 * (Precision * Recall) / (Precision + Recall) = 2 * (0.6667*0.6667) / (0.6667 + 0.6667) = 0.88897778 / 1.3334 = 0.6667**\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "*Balanced Accuracy* ➡ Considering that it takes into account both Sensitivity (True Positive Rate) and Specificity (True Negative Rate), it is useful when classes are imbalanced. It gives equal weight to the performance of the classifier on both the positive and negative classes.\n",
        "\n",
        "The balanced accuracy for each algorithm is as follows:\n",
        "\n",
        "- Algorithm #1: 0.8093571429\n",
        "- Algorithm #2: 0.76185\n",
        "\n",
        "> **Algorithm #1 has a higher balanced accuracy than Algorithm #2**\n",
        "\n",
        "*F-1 Score* ➡ F-1 Score mainly focuses on the positive class performance, and it does not directly consider the True Negative Rate or Specificity, which is critical when evaluating performance on negative classes.\n",
        "\n",
        "The F-1 score for each algorithm is as follows:\n",
        "\n",
        "- Algorithm #1: 0.7143\n",
        "- Algorithm #2: 0.6667\n",
        "\n",
        "> **Algorithm #1 has a higher F-1 Score than Algorithm #2**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**Conclusion**\n",
        "\n",
        "- In this case, F-1 Score is less suitable as it does not account for True Negative Rate.\n",
        "- Balanced Accuracy would be the right metric to consider, as it takes into consideration both Sensitivity (True Positive Rate) and Specificity (True Negative Rate). Therefore, the friend is correct, in which Algorithm #1 performs better than Algorithm #2 where 0.8093571429 > 0.76185, respectfully.\n",
        "---\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TpMHZDOECjD3"
      },
      "source": [
        "## 3.3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GRo9fm0tf-ga"
      },
      "source": [
        "**Answer:**\n",
        "\n",
        "- Although using Balanced Accuracy is a more appropriate choice for obtaining a more holistic view of the model's performance on both classes - where Algorithm #1 performed better than Algorithm #2 (0.8093571429 > 0.76185) - taking the friend's advice to use Balanced Accuracy helped us identify and calculate the Specificty, which is the metric that explicitly and directly focuses on the performance of the negative class, as it measures the proportion of actual negatives that are correctly identified.\n",
        "- When explicitly focusing on the performance on the negative class, Specificity would be the most direct measure to observe, and based on this measure, Algorithm #2 outperforms Algorithm #1, where 0.857 > 0.7857142857, respectfully.\n",
        "- While F1 Score is primarily a measure that conveys the balance between the precision and the recall, it can still be useful. It may not directly consider the true negative rate or specificity, but a high F1 Score still indicates a balanced classification in cases where both classes are of equal concern, in which Algorithm #1 outperforms Algorithm #2 where 0.7143 > 0.667, respectfully."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YdDLYruzClXn"
      },
      "source": [
        "## 3.4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RdaMp6ZBf_DF"
      },
      "source": [
        "**Answer:**\n",
        "1.  Specificity (True Negative Rate): Directly measures how well the model is\n",
        "performing on negative classes.\n",
        "2.  Balanced Accuracy: It is crucial when the classes are imbalanced and one wants a balance between sensitivity and specificity. This therefore includes calculating Recall, as well.\n",
        "3. F1-Score: It may not directly consider the True Negative Rate or Specificity, but a high F1 Score still indicates a balanced classification in cases where both classes are of equal concern. This therefore includes calculating Recall and Precision."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
